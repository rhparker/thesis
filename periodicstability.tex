\documentclass[thesis.tex]{subfiles}

\begin{document}

\iffulldocument\else
	\chapter{KdV5}
\fi

\section{Proof of stability theorems} 

% proof of nu lambda lemma
\subsection{Proof of Lemma \ref{nulambdalemma}}

Using \eqref{defAphi} and \eqref{fpartials0},
\begin{equation}\label{Alambdaform}
A(\lambda) = 
\begin{pmatrix}
0 & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 1 & \dots & 0 & 0 & 0\\
& \vdots && \vdots \\
0 & 0 & 0 & \dots & 0 & 1 & 0 \\
- c & 0 & c_3 & \dots & c_{2m-1} & 0 & 1 \\
\lambda & 0 & 0 & \dots & 0 & 0 & 0
\end{pmatrix}
\end{equation}
which has characteristic polynomial
\begin{equation}\label{charpolyA0lambda}
p(\nu; \lambda) = \lambda = -\nu^{2m+1} + c_{2m-1} \nu^{2m-1} + \dots + c_3 \nu^3 - c \nu + \lambda
\end{equation}
When $\lambda = 0$, $p(0; \nu)$ has a root at $\nu = 0$. From Lemma \ref{nondegenlemma}, $\nu = 0$ is simple root and is located a distance $\sqrt{\alpha_0^2 + \beta_0^2}$ from the next smallest roots. 

Since $p(0; 0) = 0$ and $\partial_\nu p(0; 0) = -c \neq 0$, we can use the IFT to can solve for $\nu$ in terms of $\lambda$ near $\lambda = 0$. In other words, there exists $\delta_0 > 0$ and a smooth function $\nu(\lambda)$ such that $\nu(0) = 0$ and for $|\lambda| < \delta$, $p(\nu(\lambda)$ is the unique solution to $p(\nu; \lambda) = 0$. Using the IFT to differentiate $\nu(\lambda)$ at $\lambda = 0$,
\begin{align*}
\nu'(0) &= -\frac{1}{\partial_\nu p_2(\nu(\lambda); \lambda) } \partial_\lambda p ( \nu(\lambda); \lambda ) \Big|_{\lambda = 0}\\
&= -\frac{1}{\partial_\nu p(\nu(0); 0) } \\
&= \frac{1}{c}
\end{align*}
By reversibility, $p(\nu; \lambda)$ only involves odd powers of $\nu$, thus $p(\nu; \lambda) = 0$ implies $p(-\nu; -\lambda) = 0$. Uniqueness of the solution $\nu(\lambda)$ from the IFT implies that $\nu(-\lambda) = -\nu(\lambda)$, i.e. $\nu(\lambda)$ is an odd function of $\lambda$. Since $\nu(\lambda)$ is the root of a polynomial which is smooth in $\lambda$, we can expand $\nu(\lambda)$ in a Taylor series about $\lambda = 0$. Since $\nu(\lambda)$ is an odd function, the Taylor series involves only odd powers of $\lambda$ and is given by
\begin{align*}
\nu(\lambda) = \frac{1}{c} \lambda + \mathcal{O}(|\lambda|^3)
\end{align*}

Next, we consider the case when $\lambda$ is pure imaginary. Take $\lambda = i \gamma$ and $\nu = i s$ in $p(\nu; \lambda)$ to get
\begin{align*}
p(i s; i \gamma) = (-1)^{m+1} i s^{2m+1} + c_{2m-2} (-1)^m i s^{2m-1} + \dots - c_2 i s^3 - c i s + i \gamma
\end{align*}
Since we want to solve $p(i s; i \gamma) = 0$, we can divide by $i$ to get the equilvent problem
\begin{align*}
\tilde{p}(s; \gamma) = (-1)^{m+1} s^{2m+1} + c_{2m-2} (-1)^m s^{2m-1} + \dots - c_2 s^3 - c s + \gamma = 0
\end{align*}
Since $\tilde{p}(0; 0) = 0$ and $\partial_s \tilde{p}(0; 0) = -c \neq 0$, we can use the IFT again to solve for $s$ in terms of $\gamma$. Thus we can find a smooth function $s(\gamma)$ such that $s(0) = 0$, $s(\gamma)$ is real, and $s(\gamma)$ is the unique solution to $\tilde{p}(s; \gamma) = 0$ for sufficiently small $\gamma$. Undoing these substitutions, this implies that $p(\lambda, i s(-i \lambda)) = 0$. By uniqueness of the IFT solution $\nu(\lambda)$, we conclude that $\nu(\lambda) = \nu(i \gamma) = i s(-i \lambda)$, which is pure imaginary.

Finally, let $V_0(\lambda)$ be an eigenvector of $A(\lambda)$ corresponding to $\nu(\lambda)$. This is only unique up to scalar multiple, but since $V_0(\lambda)$ is smooth in $\lambda$, scale $V_0(\lambda)$ so that $V(0) = V_0$. Next, we can verify by direct calculation that 
\[
A(\lambda) - \nu(\lambda) I = -R(A(-\lambda) + \nu(\lambda) I)R,
\]
where $R$ is the standard reversor operator. Then
\begin{align*}
[A(\lambda) - \nu(\lambda) I]V = 0 &\iff
-R(A(-\lambda) + \nu(\lambda) I)RV = 0 \\
&\iff (A(-\lambda) + \nu(\lambda) I)RV
\end{align*}
Thus $RV_0(\lambda)$ is an eigenvector of $A(-\lambda)$ corresponding to $-\nu(\lambda)$. Since $V_0(0) = RV_0(0)$, we conclude that $V_0(-\lambda) = R V_0(\lambda)$. Expanding $V_0(\lambda)$ in a Taylor series about $\lambda = 0$, we have
\[
V_0(\lambda) = V_0 + \lambda \tilde{V}_0 + \mathcal{O}(\lambda^2),
\]
where $\tilde{V}_0 = -R \tilde{V}_0$.

We can follow the same procedure with the adjoint asymptotic matrix $-A(\lambda)^*$. This has eigenvalue $-\overline{\nu(\lambda)}$ which is smooth in $\overline{\lambda}$. We can similarly find an corresponding eigenvector $W(\overline{\lambda})$ with $W_0(-\overline{\lambda}) = R V_0(\overline{\lambda})$ and Taylor expansion
\[
W_0(\lambda) = W_0 + \overline{\lambda} \tilde{W}_0 + \mathcal{O}(\overline{\lambda}^2),
\]
where $\tilde{W}_0 = -R \tilde{W}_0$

\subsection{Piecewise Formulation}

In this section we set up the eigenvalue problem we wish to solve and write it in a piecewise form similar to \cite{Sandstede1998}. Let $q_{np}(x)$ be a periodic $n-$pulse solution to \eqref{genODE} constructed according to Theorem \ref{perexist}, and let $Q_{np}(x) \in \R^{2m+1}$ be
\[
Q_{np}(x) = ( q_{np}(x), \partial_x q_{np}(x), \dots, \partial_x^{2m-1} q_{np}(x), 0 )
\]
From Theorem \ref{perexist}, we can write $Q_{np}(x)$ piecewise as
\begin{equation}\label{Qnppiece}
\begin{aligned}
Q_i^-(x) &= Q^-(x; \beta_i^-) + \tilde{Q}_i^-(x) && x \in [-X_{i-1}, 0] \\
Q_i^+(x) &= Q^+(x; \beta_i^+) + \tilde{Q}_i^+(x) && x \in [0, X_i]
\end{aligned}
\end{equation}

Recall from \cref{sec:PDEeig} that the PDE eigenvalue problem associated with $q_{np}(x)$ is given by 
\begin{equation}\label{PDEeig4}
V'(x) = A(Q_{np}(x))V(x) + \lambda B V(x),
\end{equation}
which we obtained by writing the PDE eigenvalue problem $\partial_x (\calE''(q_{np}(x)) + c )v(x) = \lambda v(x)$ as a first-order system. We can verify directly that $\partial_x (E''(q_{np}(x) + c) \partial_x q_{np}(x) = 0$. By a similar argument to Theorem \ref{transverseint}, $q_{np}(x)$ is differentiable in $c$, and $\partial_x E''(q_{np}(x)) (-\partial_c q_{np}(x)) = \partial_x q_{np}(x)$. Similarly to \eqref{Qprimevarsol} and \eqref{Qcvarsol}, we have
\begin{equation}\label{Arelations}
\begin{aligned}
(\partial_x Q_{np}(x))' &= A(Q_{np}(x)) (\partial_x Q_{np}(x)) \\
(\partial_c Q_{np}(x))' &= A(Q_{np}(x)) (\partial_c Q_{np}(x)) + B (\partial_x Q_{np}(x)) 
\end{aligned}
\end{equation}

To exploit the relations \eqref{Arelations}, we take the following piecewise ansatz for the eigenfunction $V(x)$
\begin{equation}\label{Vpiecewise}
\begin{aligned}
V_i^-(x) &= d_i (\partial_x Q_i^-(x) + \lambda \partial_c Q_i^-(x)) + W_i^-(x) && x \in [-X_{i-1}, 0] \\
V_i^+(x) &= d_i (\partial_x Q_i^+(x) + \lambda \partial_x Q_i^+(x)) + W_i^+(x) && x \in [0, X_i] 
\end{aligned}
\end{equation}
where $d_i \in \C$ are arbitrary constants. Substituting this ansatz into \eqref{PDEeig4}, we have
\begin{align*}
d_i [\partial_x Q_i^\pm(x)]' &+ \lambda d_i [\partial_c Q_i^\pm(x)] + (W_i^\pm)'(x) \\
&= d_i A(Q_i^\pm(x))(\partial_x Q_i^\pm(x)) + \lambda d_i A(Q_i^\pm(x)) (\partial_c Q_i^\pm(x)) + A(Q_i^\pm(x)) W_i^\pm(x) \\
&+ \lambda d_i B (\partial_x Q_i^\pm(x)) + d_i \lambda^2 B (\partial_c Q_i^\pm(x)) + \lambda B W_i^\pm(x)
\end{align*}
Using \eqref{Arelations}, this simplifies to
\begin{equation}\label{Wipm1}
(W_i^\pm)'(x) = A(Q_i^\pm(x)) W_i^\pm(x) + \lambda B W_i^\pm(x) + d_i \lambda^2 B (\partial_c Q_i^\pm(x))
\end{equation}
Since $A(Q(x))$ is smooth in $Q(x)$, let 
\begin{align*}
G_i^\pm(x) = A(Q_i^\pm(x)) - A(Q(x))
\end{align*}
Finally, let
\begin{align*}
A(Q(x); \lambda) &= A(Q(x)) + \lambda B \\
\tilde{H}_i^\pm(x) &= \partial_c Q_i^\pm(x) \\ 
H(x) &= \partial_c Q(x)
\end{align*}
Using these, equation \eqref{Wipm1} simplifies to
\begin{align}\label{Wipm2}
(W_i^\pm)'(x) &= A(Q(x); \lambda) W_i^\pm(x) + G_i^\pm(x) W_i^\pm(x) + d_i \lambda^2 \tilde{H}_i^\pm(x)
\end{align}

In order to have a solution to \eqref{PDEeig4}, the eigenfunction $V(x)$ must be continuous. In other words, the $n$ jumps at $\pm X_i$ and the $n$ jumps at $0$ must be 0. Thus a solution to \eqref{PDEeig4} must solve the system of equations
\begin{align*}
(W_i^\pm)'(x) &= A(Q(x); \lambda) W_i^\pm(x) + G_i^\pm(x) W_i^\pm(x) + d_i \lambda^2 \tilde{H}_i^\pm(x) \\
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d && i = 0, \dots, n-1 \\
W_i^-(0) &= W_i^+(0) && i = 0, \dots, n-1  \\
\end{align*}
where
\begin{align}\label{defDid}
D_i d &= d_{i+1}[\partial_x Q_{i+1}^-(-X_i) + \lambda \partial_c Q_{i+1}^-(-X_i)]
- d_i [ \partial_x Q_i^+(X_i) + \lambda \partial_c Q_i^+(X_i) ] \\
\end{align}

As in \cite{Sandstede1998}, we will not be able to find a solution to this system for arbitrary $\lambda$. Thus we will instead consider the system
\begin{equation}\label{eigsystem}
\begin{aligned}
(W_i^\pm)'(x) &= A(Q(x); \lambda) W_i^\pm(x) + G_i^\pm(x) W_i^\pm(x) + d_i \lambda^2 \tilde{H}_i^\pm(x) \\
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d && i = 0, \dots, n-1 \\
W_i^\pm(0) &\in \R \Psi(0) \oplus \R \Psi^c(0) \oplus Y^+ \oplus Y^- && i = 0, \dots, n-1  \\
W_i^+(0) - W_i^-(0) &\in \R \Psi(0) \oplus \R \Psi^c(0) && i = 0, \dots, n-1 
\end{aligned}
\end{equation}
where the center matching condition $W_i^-(0) = W_i^+(0)$ is relaxed to the requirement that the jumps $W_i^+(0) - W_i^-(0)$ can only be in the directions of $\Psi^c(0)$ and $\Psi(0)$. We do not need to include a component in $Q'(0)$ in the third equation since that is handled by the term $d_i (Q_i^\pm)'(x)$ in the ansatz \eqref{Vpiecewise}. A solution to \eqref{eigsystem} solves \eqref{PDEeig4}, i.e. is an eigenfunction corresponding to eigenvalue $\lambda$, if and only if the $n$ jumps at $x = 0$ in the direction of $\Psi(0) \oplus \R \Psi^c(0)$ are 0, i.e.  
\begin{equation}\label{jumpxi}
\begin{aligned}
\xi_i &= \langle \Psi(0), W_i^+(0) - W_i^-(0) \rangle = 0  \\
\xi_i^c &= \langle \Psi^c(0), W_i^+(0) - W_i^-(0) \rangle = 0 
\end{aligned}
\end{equation}
for $i = 0, \dots, n-1$.

Before we continue, we will need estimates on terms involved in \eqref{eigsystem}, which we collect in the following lemma.

\begin{lemma}\label{stabestimateslemma}
Let $\Delta H_i^\pm(x) = \tilde{H}_i^\pm(x) - H(x)$. Then for any $\alpha_1$ with $0 < \alpha_1 < \alpha_0$, we have the following estimates
\begin{enumerate}[(i)]
\item $|H(x)|, |\tilde{H}_i^\pm(x)| \leq C e^{-\alpha_1 |x|}$
\item $|\Delta H_i^-(x)| \leq C e^{-\alpha_1 X_{i-1}} e^{-\alpha_1(X_{i-1} + x) } + e^{-2 \alpha_1 X_i} e^{\alpha_1 x}$
\item $|\Delta H_i^+(x)| \leq C e^{-\alpha_1 X_i} e^{-\alpha_1(X_i - x) } + e^{-2 \alpha_1 X_{i-1}} e^{-\alpha_1 x}$
\item $||\Delta H_i^\pm|| \leq C(e^{-\alpha_1 X_i} + e^{-\alpha_1 X_{i-1}} )$
\item $|G_i^-(x)| \leq C e^{-\alpha_0 X_{i-1}} e^{-\alpha_0(X_{i-1} + x) } + e^{-2 \alpha_0 X_i} e^{\alpha_0 x}$
\item $|G_i^+(x)| \leq C e^{-\alpha_0 X_i} e^{-\alpha_0(X_i - x) } + e^{-2 \alpha_0 X_{i-1}} e^{-\alpha_0 x}$
\item $||G|| \leq C e^{-\alpha_0 X_m}$
\item $D_i d = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} ( e^{-\alpha_1 X_i} (e^{-\alpha_0 X_m} + |\lambda| )$
\end{enumerate}
\begin{proof}
Recall that $H(x) = \partial_c Q(x)$ and $\tilde{H}(x) = \partial_c Q_i^\pm(x)$. For (i), by Theorem \ref{transverseint} and the discussion following \eqref{PDEeig4}, $H(x)$ and $\tilde{H}(x)$ are exponentially localized for any $\alpha_1$ with $0 < \alpha_1 < \alpha_0$. The bounds (ii) and (iii) follow from an adaptation of Lemma \ref{solvewithjumps} to derivative with respect to $c$. The bound (iv) follows from (ii) and (iii). Since $A(Q(x))$ is smooth in $Q(x)$, the bounds (v), (vi), and (vii) come from Lemma \ref{solvewithjumps}.

For estimate (viii), we use \eqref{VQpm} in Lemma \ref{solvewithjumps} and \eqref{Vpiecewise} (with $\tilde{Q}$ in place of $V$) to get
\begin{align*}
Q_{i+1}^-(-X_i) &= Q^-(-X_i; \beta_{i+1}^-) + \tilde{Q}_{i+1}^-(-X_i) \\
&= Q^-(-X_i; \beta_{i+1} ^-) + Q^+(X_i; \beta_i^+) + \mathcal{O}(e^{-2 \alpha_0 X_i}) \\
&= Q(-X_i) + Q(X_i) 
+ \mathcal{O}(e^{-\alpha_0 X_i}(e^{-\alpha_0 X_{i-1}}+e^{-\alpha_0 X_i}+e^{-\alpha_0 X_{i+1}}))
\end{align*}
Since the bounds \ref{solvewithjumps} also apply to derivatives with respect to $x$, we have
\begin{align*}
(Q_{i+1}^-)'(-X_i) &= Q'(-X_i) + Q'(X_i) + \mathcal{O}(e^{-\alpha_0 X_i}e^{-\alpha_0 X_m})
\end{align*}
Similarly,
\begin{align*}
(Q_i^+)'(X_i)' &= Q'(-X_i) + Q'(X_i) + \mathcal{O}(e^{-\alpha_0 X_i}e^{-\alpha_0 X_m})
\end{align*}
To get the estimate (v), we substitute these into \eqref{Did2} and use estimate (i) for $\partial_c Q_i^\pm(x)$.
\end{proof}
\end{lemma}

\subsection{Conjugation}

To simplify the system, we would like to apply a change of coordinates so that the linear operator $A(Q(x); \lambda)$ is transformed into a constant coefficient matrix. To do this we will use the Conjugation Lemma. For all $\lambda$, $A^\pm(x; \lambda)$ decays exponentially to the constant-coefficient matrix $A(0; \lambda)$ which, for convenience, we will write as $A(0; \lambda)$. Specifically,
\[
|A(Q(x); \lambda) - A(\lambda)| \leq C e^{\alpha_0 |x|}
\]

Using the conjugation lemma on $\R^+$ with $\Lambda = \lambda$ and $\lambda_0 = 0$, there exists $\delta_1 > 0$ and an invertible linear transformation 
\[
P_+(x; \lambda) = I + \Theta_+(x; \Lambda)
\]
such that for all $|\lambda| < \delta_1$, the change of coordinates $W_i^+ = P_+(x; \lambda) Z_i^+$ conjugates \eqref{Wipm2} into the equation
\begin{align*}\label{Zplus1}
(Z_i^+)'(x) &= A(\lambda) Z_i^+(x) + P_+(x; \lambda)^{-1} G_i^+(x) P_+(x; \lambda) Z_i^+(x) + d_i \lambda^2 P_+(x; \lambda)^{-1} \tilde{H}_i^+
(x)
\end{align*}

We would also like to perform the conjugation on $\R^-$. Rather than using the conjugation lemma again on $\R^-$, we will use the symmetries of our system to define the conjugation operator on $\R^-$ in terms of the conjugation operator on $\R^+$. We do this in a series of lemmas. First we prove a symmetry relation for $A(Q(x); \lambda)$.

\begin{lemma}\label{AQxsymmetrylemma}
Let $R$ be the standard reversor operator. Then
\begin{enumerate}[(i)]
\item $A(Q(x); \lambda) = -R A(Q(-x); -\lambda)R$
\item If $V(x)$ is a solution to $V'(x) = A(Q(x); \lambda) V(x)$ on $\R^+$. Then $R V(-x)$ is a solution to $V'(x) = A(Q(x); -\lambda) V(x)$ on $\R^-$.
\end{enumerate}
\begin{proof}
Since we will be dealing with reversor operators on two difference spaces, let $R_{n}$ be the matrix for the standard reversor operator on $\R^n$. For part (i), using the symmetry relations $DF(RU) = -RDF(U)R$ and $Q(-x) = RQ(X)$, we have
\begin{align*}
-R_{2m+1} &A(Q(-x); -\lambda) R_{2m+1}
= \begin{pmatrix}-R_{2m} & 0 \\ 0 & -1 \end{pmatrix} 
\begin{pmatrix}
DF(Q(-x)) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} -\lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \begin{pmatrix}R_{2m} & 0 \\ 0 & 1 \end{pmatrix} \\
&= \begin{pmatrix}
-R_{2m} DF(Q(-x)) R_{2m} & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} 
= \begin{pmatrix}
DF(R_{2m}(Q(-x))) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \\
&= \begin{pmatrix}
DF(Q(x)) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \\ 
&= A(Q(x); \lambda)
\end{align*}

For part (ii), for $x \in \R^-$,
\begin{align*}
\frac{d}{dx} &\left[ R_{2m+1} V(-x) \right] = -R_{2m+1} V'(-x) \\
&= -R_{2m+1} A(Q(-x); \lambda) V(-x) \\
&= -R_{2m+1} A(Q(-x); \lambda) R_{2m+1} [ R_{2m+1} V(-x)] \\
&= A(Q(x); -\lambda) [R_{2m+1} V(-x)]
\end{align*}
\end{proof}
\end{lemma}

In the next lemma, we define the conjuation operator on $\R^-$ in terms of the conjugation operator on $\R^+$.

\begin{lemma}\label{conjRminuslemma}
For $x \in \R^-$ and $|\lambda| < \delta_1$, define $P_-(x; \lambda)$ by
\begin{equation}\label{defPminus}
P_-(x; \lambda) = RP_+(-x; -\lambda)R
\end{equation}
Then the substitutiton $V(x) = P_-(x; \lambda) Z(x)$ conjugates the ODE 
\begin{equation}\label{Veqminus}
V'(x) = A(Q(x); \lambda) V(x)
\end{equation}
into the constant-coefficient ODE 
\begin{equation}\label{Zeqminus}
Z'(x) = A(\lambda)Z(x).
\end{equation}
\begin{proof}
We substitute $V(x) = P_-(x; \lambda) Z(x)$ into \eqref{Veqminus}. For the LHS, we have
\begin{align*}
\frac{d}{dx}[P_-(x; \lambda) Z(x)] &= \frac{d}{dx}[RP_+(-x; -\lambda)R Z(x)] \\
&= -RP'_+(-x; -\lambda)R Z(x) + RP_+(-x; -\lambda)R Z'(x)
\end{align*}
For the RHS, using part (i) of Lemma \ref{AQxsymmetrylemma} and $R^2 = I$, we have
\begin{align*}
A(Q(x); \lambda)P_-(x; \lambda) Z(x) &= A(Q(x); \lambda)RP_+(-x; -\lambda)R Z(x) \\
&= -R[ -R A(Q(x); \lambda)R ]P_+(-x; -\lambda)R Z(x) 
\end{align*}
which simplifies to
\begin{align}\label{Zeqminus1}
A(Q(x); \lambda)P_-(x; \lambda) Z(x) &= -R A(Q(-x); -\lambda) P_+(-x; -\lambda)R Z(x). 
\end{align}
From the proof of the conjugation lemma,
\begin{align*}
P'_+(x; \lambda) = A(Q(x); \lambda)P_+(x; \lambda) - P_+(x; \lambda) A(\lambda)
\end{align*}
Rearranging this and evaluating it at $-x$ and $-\lambda$, 
\begin{align*}
 A(Q(-x); -\lambda)P_+(-x; -\lambda) = P'_+(-x; -\lambda) + P_+(-x; -\lambda) A(-\lambda)
\end{align*}
Substituting this into \eqref{Zeqminus1}, we have
\begin{align*}
A(Q(x); \lambda)&P_-(x; \lambda) Z(x) = -R [ P'_+(-x; -\lambda) + P_+(-x; -\lambda) A(-\lambda) ] R Z(x) \\
&= -R P'_+(-x; -\lambda) R Z(x) - R P_+(-x; -\lambda) R [ R A(-\lambda) R]Z(x) \\
&= -R P'_+(-x; -\lambda) R Z(x) + R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align*}
where in the last line we used $-R A(-\lambda) R = A(\lambda)$, which we can either show directly or take $x \rightarrow \infty$ in part (i) of Lemma \ref{AQxsymmetrylemma}. Equating the LHS and RHS, we have
\begin{align*}
-RP'_+(-x; -\lambda)&R Z(x) + RP_+(-x; -\lambda)R Z'(x) \\
&= -R P'_+(-x; -\lambda) R Z(x) + R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align*}
which simplifies to
\begin{align*}
RP_+(-x; -\lambda)R Z'(x) = R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align*}
Since $R$ and $P_+(-x; -\lambda)$ are invertible, this finally reduces to 
\begin{align*}
Z'(x) = A(\lambda) Z(x)
\end{align*}
which is the equation we want.
\end{proof}
\end{lemma}

Let $P_-(x; \lambda) = RP_+(-x; -\lambda)R$. Then by Lemma \ref{conjRminuslemma}, the change of coordinates $W_i^- = P_-(x; \lambda) Z_i^-$ conjugates \eqref{Wipm2} into the equation
\begin{align}\label{Zminus1}
(Z_i^-)'(x) &= A(\lambda) Z_i^-(x) + P_-(x; \lambda)^{-1} G_i^-(x) P_-(x; \lambda) Z_i^-(x) + d_i \lambda^2 P_-(x; \lambda)^{-1} \tilde{H}_i^-
(x)
\end{align}

Using the projections $P_\pm(x; \lambda)$ and making the substitution $W_i^\pm(x) = P_\pm(x; \lambda) Z_i^\pm(x)$ in \eqref{eigsystem}, we obtain the conjugated system
\begin{subequations}
\begin{align}
(Z_i^\pm(x))' = A(\lambda) Z_i^\pm(x) &+ P_\pm(x; \lambda)^{-1} G_i^\pm(x) P_\pm(x; \lambda) Z_i^\pm(x) + \lambda^2 d_i P_\pm(x; \lambda)^{-1} \tilde{H}_i^\pm(x) \label{systemZ} \\
P_+(X_i; \lambda) Z_i^+(X_i) &- P_-(-X_i; \lambda) Z_{i+1}^-(-X_i; \lambda) = D_i d \label{systemmiddle} \\
P_\pm(0; \lambda) Z_i^\pm(0) &\in Y^+ \oplus Y^- \oplus \C \Psi(0) \oplus \C \Psi^c(0) \label{systemcenter1} \\
P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) &\in \C \Psi(0) \oplus \C \Psi^c(0) \label{systemcenter2}
\end{align}
\end{subequations}
and the jump conditions \eqref{jumpxi} become
\begin{equation}\label{jumpcondZ}
\begin{aligned}
\langle \Psi(0), P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) \rangle &= 0 \\
\langle \Psi^c(0), P_-(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) \rangle &= 0
\end{aligned}
\end{equation}

Before we continue, we define the following constants, which we will use throughout. Recall that by Lemma \ref{eigA0lemma}, $A(0)$ has a simple eigenvalue at 0, a quartet of eigenvalues $\pm \alpha_0 \pm \beta_0 i$, and for all other eigenvalues $\nu$ of $A(0)$, $|\Re \nu| > \alpha_0$. Our results will require that $\lambda$ is sufficiently small. The upper bound on the magnitude of $\lambda$ will depend on $\alpha_0$.

\begin{enumerate}
	\item Choose $\eta > 0$ sufficiently small so that $\alpha_0 - 5 \eta > 0$.
	\item Choose $\alpha_1 = \alpha_0 - \eta$

	\item Let
	\begin{align*}
	\alpha &= \alpha_0 - 2 \eta \\
	\tilde{\alpha} &= \alpha - 2 \eta 
	\end{align*}

	\item Choose $\delta < \min\{\delta_0, \delta_1\}$ sufficiently small so that for all $|\lambda| < \delta$
	\begin{enumerate}
		\item $|\nu(\lambda)| < \eta$, where $\nu(\lambda)$ is the small eigenvalue of $A(\lambda)$ defined in Lemma \ref{nulambdalemma}.
		\item The real part of any other eigenvalue of $A(\lambda)$ lies outside the interval $[-\alpha, \alpha]$. This is possible since the eigenvalues of $A(\lambda)$ are smooth functions of $\lambda$.
	\end{enumerate}

	\item Choose $X_m$ sufficiently large so that
	\begin{equation}
	e^{-\tilde{\alpha} X_m} < \delta
	\end{equation}
	where $X_m = \min\{X_0, \dots, X_{n-1}\}$.

	We can always choose a smaller $\delta$ later if needed.
\end{enumerate}

Finally, the conjugation lemma gives us the following expansions for the projections $P_\pm(x; \lambda)$.
\begin{equation}\label{projTheta}
P_\pm(x; \lambda) = I + \Theta_\pm(x; \lambda)
\end{equation}
where $\Theta_-(x; \lambda) = R \Theta_+(-x; -\lambda) R$ and we have the decay rates
\begin{equation}\label{Thetadecay}
|\Theta_\pm(x; \lambda)| \leq C e^{-\alpha_1 |x|} \\
\end{equation}
By the Conjugation Lemma, these decay rates also apply to derivatives with respect to $x$ and $\lambda$. Expanding $\Theta_\pm(x; \lambda)$ in a Taylor series about $\lambda = 0$, we have
\begin{align}\label{ThetaTaylor}
\Theta_\pm(x; \lambda) &= \Theta_\pm(x; 0) + [\partial_\lambda \Theta_\pm(x; 0)] \lambda + \calO(|\lambda|^2)
\end{align}
where $\partial_\lambda \Theta_\pm(x; 0) = \calO(e^{-\alpha_1 |x|})$.

\subsection{Exponential Trichotomy}

Since $A(\lambda)$ is a constant coefficient matrix, we know exactly how solutions of the constant coefficient ODE $Z' = A(\lambda)Z$ evolve. Let $E^{u/s/c}(0)$ be the stable, unstable, and center eigenspaces of $A(0)$. $E^s(0)$ and $E^u(0)$ are $m-$dimensional, and $E^c(0)$ is 1-dimensional. For $|\lambda| < \delta$, let $E^{u/s/c}(\lambda)$ be the corresponding eigenspaces of $A(\lambda)$, which have the same dimension since $\lambda$ is small. In particular, 
\[
E^c(\lambda) = \spn\{ V_0(\lambda) \},
\]
where $V_0(\lambda)$ is the eigenvector of $A(\lambda)$ corresponding to $\nu(\lambda)$, as defined in Lemma \ref{nulambdalemma}. Although $E^c(\lambda)$ is not a true center eigenspace if $\Re \nu(\lambda) \neq 0$, we retain this notation for convenience. Let $P^{u/s/c}(\lambda)$ be the projections on the eigenspaces $E^{u/s/c}(\lambda)$. These are smooth in $\lambda$. 

Let $\Phi(x, y; \lambda) = e^{A(\lambda)(x-y)}$ be the evolution of the constant-coefficient ODE
\[
Z' = A(\lambda) Z
\]
and let $\Phi^{u/s/c}(x, y; \lambda) = \Phi(x, y; \lambda)P^{u/s/c}(\lambda)$ be the evolutions on the respective eigenspaces. For $|\lambda| < \delta$, $|\nu(\lambda)| < \eta$, and we have bounds
\begin{equation}\label{Zevolbounds}
\begin{aligned}
|\Phi^s(x, y; \lambda)| &\leq C e^{-\alpha(x - y)} \\
|\Phi^u(x, y; \lambda)| &\leq C e^{-\alpha(y - x)} \\
|\Phi^c(x, y; \lambda)| &\leq C e^{\eta|x - y|} 
\end{aligned}
\end{equation}
which is an exponential trichotomy on $\R$. Since $E^c(\lambda)$ is one-dimensional, the center evolution $\Phi^c(x, y; \lambda)$ is given by
\begin{align}\label{centerevol}
\Phi^c(x, y; \lambda) v &= e^{\nu(\lambda)(x - y)} P^c(\lambda)v
\end{align}

Finally, we look at the variational and adjoint variational equations for the linearization of the PDE about the primary pulse $Q(x)$. Recall that these are given by 
\begin{align*}
V'(x) &= A(Q(x); 0) V(x) \\
W'(x) &= -A(Q(x); 0)^* W(x)
\end{align*}
Let $\tilde{\Phi}(y, x)$ be the evolution operator for the variational equation. Then by Lemma \ref{eigadjoint}, $\tilde{\Phi}(x, y)^*$ is the evolution operator for the adjoint variational equation. From the conjugation lemma, we have the following relationship between $\tilde{\Phi}(y, x)$ and $\Phi(y, x; 0)$.
\begin{align*}
\tilde{\Phi}(y, x) &= P_+(y; 0) \Phi(y, x; 0) P_+(x; 0)^{-1} && x, y \geq 0 \\
\tilde{\Phi}(y, x) &= P_-(y; 0) \Phi(y, x; 0) P_-(x; 0)^{-1} && x, y \leq 0
\end{align*}

The conjugation operator induces exponential trichotomies on $\R^\pm$ for the variational equation. The stable, unstable, and center projections are given by
\begin{equation}\label{trichotomyprojunconj}
\tilde{P}^{s/u/c}_\pm(x) = P_\pm(x; 0) P^{s/u/c}(0) P_\pm(x, 0)^{-1}
\end{equation}
We note that the center subspaces on $\R^+$ and $\R^-$ are both one-dimensional and are given by $\C V^c(x)$. 

We can easily derive an expression for the center projection.
\begin{align*}
\tilde{P}^c_\pm(x) u &= P_\pm(x; 0) P^c(0) P_\pm(x, 0)^{-1} u \\
&= P_\pm(x; 0) \langle W_0, P_\pm(x, 0)^{-1} u \rangle V_0 \\
&= \langle W_0, P_\pm(x, 0)^{-1} u \rangle P_\pm(x; 0) V_0\\
&= \langle W_0, P_\pm(x, 0)^{-1} u \rangle V^c(x)
\end{align*}

In fact, since $\Psi^(x) = W_0$ is a constant solution to the adjoint variational equation, we have a nicer form for the center projection, i.e. we can remove the term $P_\pm(x, 0)^{-1}$. THIS MIGHT NOT BE TRUE BUT IT SHOULD BE.

\begin{lemma}\label{centerprojlemma}
For the trichotomies on $\R^\pm$, the center projection is given by 
\begin{align}
\tilde{P}^c_\pm(x) U &= \langle W_0, U \rangle V^c(x)
\end{align}
\begin{proof}
We will show this on $\R^+$. The result on $\R^-$ is similar. First, we show that it acts as the identity on $\C V^c(x)$. Since $\Psi^c(x) = W_0$ is a solution to the adjoint variational equation and $V^c(x)$ is solution to the variational equation, by Lemma \ref{eigadjoint}(i), the inner product $\langle \Psi^c(x), V^c(x) \rangle = \langle W_0, V^c(x) \rangle$ is constant. Sending $x \rightarrow \infty$ and using the continuity of the inner product, we have
\[
\langle W_0, V^c(x) \rangle = \langle W_0, V_0 \rangle = 1
\]
Thus for $a \in \C$,
\begin{align*}
\langle W_0, a V^c(x) \rangle V^c(x) 
&= a \langle W_0, V^c(x) \rangle V^c(x) \\
&= a V^c(x)
\end{align*}

Next, we show that $W_0$ is perpendicular to any element of the stable or unstable subspaces at $x$. Let $\tilde{V}^s$ be any element of the stable subspace at $x$. Then $\tilde{V}^s = P_+(x, 0) V^s$ for some $V^s \in E^s(0)$. Let $V^s(y)$ be the unique solution to the variational equation with initial condition $V^s(x) = \tilde{V}^s$. This solution is given by
\begin{align*}
V^s(y) &= \tilde{\Phi}(y,x)\tilde{V}^s \\
&= P_+(y; 0) \Phi(y, x; 0) P_+(x; 0)^{-1} P_+(x, 0) V^s \\
&= P_+(y; 0) \Phi(y, x; 0) V^s
\end{align*}
Since $V^s \in E^s$, $\Phi(y, x; 0) V^s \rightarrow 0$ as $y \rightarrow \infty$, thus $V^s(y) \rightarrow 0$ as $ \rightarrow \infty$. By Lemma \ref{eigadjoint}(ii), $\langle \Psi^c(y), V^s(y) \rangle = \langle W_0, \tilde{V}^s \rangle = 0$.
\end{proof}
\end{lemma}

We can use this to derive expansions which will be useful later.

\begin{lemma}\label{W0projlemma}
For all $U \in \R^{2m+1}$, we have the following.
\begin{enumerate}[(i)]
	\item $\langle W_0, P_\pm(x, 0) P^{s/u}(0) U \rangle = 0$
	\item $\langle W_0, \Theta_\pm(x, 0) P^{s/u}(0) U \rangle = 0$
	\item $\langle W_0(\lambda), \Theta_\pm(x, \lambda) P^{s/u}(\lambda) U \rangle  = \mathcal{O}(|\lambda|( e^{-\alpha_1 |x|} + |\lambda|)|U|)$
	\item $\langle W_0, P_\pm(0; \lambda)P^{s/u}(0) U \rangle = \mathcal{O}(|\lambda||U|)$
	\item $P^c(0) G_i^\pm(x) U = \langle W_0, G_i^\pm(x) U\rangle = 0$
\end{enumerate}
\begin{proof}
By Lemma \ref{centerprojlemma}, the projection on the center subspace when $\lambda = 0$ is given by $\tilde{P}_\pm^c(x)U = \langle W_0, U \rangle V^c(x)$, thus $\langle W_0, U \rangle = 0$ for all $U$ in the range of the stable and unstable projections of the trichotomy, which are given by $P_\pm(x, 0) E^{s/u}(0)$. This proves (i). For (ii), 
\begin{align*}
\langle W_0, \Theta_\pm(x, 0) P^{s/u}(0) U\rangle &=
\langle W_0, (I - P_\pm(x, 0)) P^{s/u}(0) U\rangle \\
&= \langle W_0, P^{s/u}(0) U \rangle - \langle P_\pm(x, 0)P^{s/u}(0) U \rangle \\
&= 0
\end{align*}
by part (i) and the fact that $\langle W_0, \cdot \rangle$ is the projection on $E^c(0)$. For (iii), we first note that the eigenprojections $P^{s/u}(\lambda)$ are matrices which are smooth in $\lambda$, thus we can expand them in a Taylor series to get $P^{s/u}(\lambda) = P^{s/u}(0) + \mathcal{O}(\lambda)$. From Lemma \ref{nulambdalemma}, we have the expansion $W_0(\lambda) = W_0 + \mathcal{O}(\overline{\lambda})$. From the Conjugation lemma, we have the expansion $\Theta_\pm(x; \lambda) = \Theta_\pm(x; 0) + \mathcal{O}(e^{-\alpha_1 |x|}|\lambda|)$. Using all of these expansions, we have
\begin{align*}
\langle &W_0(\lambda), \Theta_\pm(x; \lambda) P^{s/u}(\lambda) U \rangle = \langle W_0 + \mathcal{O}(\overline{\lambda}), \Theta_\pm(x; 0) + \mathcal{O}(e^{-\alpha_1 |x|}|\lambda|))(P^{s/u}(0) + \mathcal{O}(\lambda)) U \rangle \\
&= \langle W_0, (I + \Theta_\pm(x, 0))P^{s/u}(0)U \rangle +
\mathcal{O}(|\lambda||U|) \\
&= \langle W_0, P_\pm(x, 0)P^{s/u}(0)U \rangle +
\mathcal{O}(|\lambda|( e^{-\alpha_1 |x|} + |\lambda|)|U|)\\
&= \mathcal{O}(|\lambda|( e^{-\alpha_1 |x|} + |\lambda|)|U|) \\
\end{align*}
where for the last equality we used part (ii). For (iv), we expand in $\lambda$ to get
\begin{align*}
\langle W_0, &P_\pm(0; \lambda)P^{s/u}(\lambda) U \rangle =
\langle W_0, (P_\pm(0; 0) + \mathcal{O}(|\lambda|))(P^{s/u}(0) + \mathcal{O}(|\lambda|)) U) \\
&= \langle W_0, P_\pm(0; 0) P^{s/u}(0)U \rangle + \mathcal{O}(|\lambda||U|) \\
&= \langle W_0, \tilde{P}_\pm(0) U \rangle + \mathcal{O}(|\lambda||U|) \\
&= \mathcal{O}(|\lambda||U|) 
\end{align*}
where in the last line we used Lemma \ref{centerprojlemma}. For (v), since the bottom row of $G_i^\pm(x)$ is all zeros, the last component of $G_i^\pm(x) U$ is 0 for all $U$. It follows that $\langle W_0, G_i^\pm(x) U\rangle = 0$.
\end{proof}
\end{lemma}

\subsection{Solutions in center subspace}\label{sec:centersol}

In this section we construct specific solutions to the equation
\begin{align}
V'(x) = A(Q(x); \lambda) V(x) \label{Veqlambda}
\end{align}
When $\lambda = 0$, this is the variational equation. By the conjugation lemma, we can find solutions to this on $\R^\pm$ which are of the form $V^\pm(x) = P_\pm(x; \lambda)Z(x)$, where $Z(x)$ solves the constant coefficient equation $Z'(x) = A(\lambda)Z$.

In the next lemma, we construct specific solutions to \eqref{Veqlambda} on $\R^\pm$ which evolve in the center subspace. We could obtain these results via the Gap Lemma, but this is much easier.

\begin{lemma}\label{centersolutionslemma}
For sufficiently small $\lambda$, we can find solutions $V^\pm(x; \lambda)$ to \eqref{Veqlambda} on $\R^\pm$ which are given by
\begin{align}\label{Vpmlambda}
V^\pm(x; \lambda) &= e^{\nu(\lambda)x}(V_0(\lambda) + V_1^\pm(x; \lambda)),
\end{align}
where
\begin{equation}\label{Vpmdecay}
|V_1^\pm(x; \lambda)| \leq C e^{-\alpha_1 |x|}
\end{equation}
and we have the symmetry relationship
\begin{equation}\label{Vpmsymmetry}
V^-(x; \lambda) = R V^+(-x; -\lambda)
\end{equation}

\begin{proof}
Let $Z(x) = e^{\nu(\lambda)x}V_0(\lambda)$, which is a solution to $Z'(x) = A(\lambda)Z$ contained in the center subspace $E^c(\lambda)$. Let
\[
V^+(x; \lambda) = P_+(x; \lambda) Z(x) = e^{\nu(\lambda)x}P_+(x; \lambda)V_0(\lambda)
\]
Then by the expansion \eqref{conjlemmaP} from the Conjugation Lemma,
\begin{align*}
V^+(x; \lambda) &= e^{\nu(\lambda)x}(I + \Theta_+(x; \lambda))V_0(\lambda) \\
&= e^{\nu(\lambda)x}( V_0(\lambda) + V_1^+(x; \lambda))
\end{align*}
where $V_1^+(x; \lambda) = \Theta_+(x; \lambda) V_0(\lambda)$. This is \eqref{Vpmlambda}, and the decay result \eqref{Vpmdecay} comes from \eqref{conjlemmathetadecay} in the Conjugation Lemma.

Similarly, we define 
\begin{align*}
V^-(x; \lambda) &= P_-(x; \lambda) Z(x) \\
&= RP_+(-x; -\lambda)R e^{\nu(\lambda)x} V_0(\lambda) \\
&= e^{\nu(\lambda)x} R(I + \Theta_+(-x; -\lambda))R V_0(\lambda) \\
&= e^{\nu(\lambda)x}( V_0(\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) )
\end{align*}
Letting $V_1^-(x; \lambda) = R\Theta_+(-x; -\lambda) V_0(-\lambda)$, we have
\begin{align*}
V^-(x; \lambda) &= e^{\nu(\lambda)x}( V_0(\lambda) + V_1^-(x; \lambda))
\end{align*}
For the symmetry relation, using Lemma \ref{nulambdalemma}, we also have
\begin{align*}
V^-(x; \lambda) &= e^{\nu(\lambda)x}( V_0(\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= e^{\nu(\lambda)x}( R V_0(-\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R e^{-\nu(\lambda)(-x)}( V_0(-\lambda) + \Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R e^{\nu(-\lambda)(-x)}( V_0(-\lambda) + \Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R V^+(-x; -\lambda)
\end{align*}
\end{proof}
\end{lemma}

As a corollary, the next lemma provides the proof for part (i) of Lemma \ref{varadjsolutions}.
 
\begin{lemma}\label{varsolutions}
There exists a bounded solution $V^c(x)$ to \eqref{vareq2} such that 
\begin{equation*}
V^c(x) \rightarrow V_0 \text{ as }|x| \rightarrow \infty
\end{equation*}
$V^c$ is symmetric with respect to the standard reversor operator $R$, i.e. $V^c(-x) = R V^c(x)$, and we can write
\[
V^c(x) = V_0 + V^c_1(x)
\]
where $V^c_1(x) = \mathcal{O}(e^{-\alpha_1 |x|})$.
\begin{proof}
We employ the following dimension counting argument. Recall that $\dim W^{s/u}(0) = m$ and $\dim W^c(0) = 1$, thus $\dim W^{cs}(0) = m + 1$, and $\dim W^{cu}(0) = m + 1$. $\Psi(0) \perp T_{Q(0)}W^{cs}(0) + T_{Q(0)}W^{cu}(0)$, so $\dim T_{Q(0)}W^{cs}(0) + T_{Q(0)}W^{cu}(0) \leq 2m$. By counting dimensions, this implies that $\dim T_{Q(0)}W^{cs}(0) \cap T_{Q(0)}W^{cu}(0) = 2$. Since $\dim T_{Q(0)}W^s(0) \cap T_{Q(0)}W^s(0) = 1$ by Lemma \ref{nondegenlemma}, we conclude that there exists $Y_0 \in T_{Q(0)}W^{cs}(0) \cap T_{Q(0)}W^{cu}(0)$ which is linearly independent from $Q'(0)$, and $Y^0 \notin T_{Q(0)}W^s(0) \cap T_{Q(0)}W^s(0)$.

Using Lemma \ref{centersolutionslemma}, let
\[
V^\pm(x) = V^\pm(x; 0) = V_0 + V_1^\pm(x)
\]
where $V_1^\pm(x) = \mathcal{O}(e^{-\alpha_0 |x|})$. From the construction in \ref{centersolutionslemma},
\[
V^\pm(x) = P_\pm(x; 0) V_0,
\]
and we also have the symmetry relation $V^-(x) = R V^+(-x)$. We will show that $V^+(0) = V^-(0)$.

By the trichotomy for the variational equation, at $x = 0$ there is a one-dimensional center subspace for $\R^+$ and a one-dimensional center subspace for $\R^-$. By the dimension counting argument above, both of the center subspaces must be spanned by $Y^0$, thus they are the same subspace. Using the projections \eqref{trichotomyprojunconj}, $V^\pm(0)$ are in these center subspaces, thus $V^\pm(0) \in \Span \{Y^0 \}$. In particular, this implies that $V^+(0)$ and $V^-(0)$ are scalar multiples of each other. 

From Lemma \ref{varadjsolutions}, $\Psi^c(x) = W_0$ is a solution to the adjoint variational equation on $\R$. By Lemma \ref{eigadjoint}(i), the inner product $\langle W_0, V^\pm(x) \rangle$ is constant in $x$. Sending $x \rightarrow \pm \infty$ and recalling that $V_0 = (1/c, 0, \dots, 0, 1)^T $ and $W_0 = (0, \dots, 0, 1)^T$,
\[
\langle W_0, V^+(0) \rangle = \langle W_0, V^-(0) \rangle
= \langle W_0, V(0) \rangle = 1
\]
This implies that the last component of $V^+(0)$ and $V^-(0)$ is 1. Since $V^+(0)$ and $V^-(0)$ are scalar multiples of each other, they must in fact be equal. Let
\[
V^c(x) = \begin{cases}
V^+(x) & x \geq 0 \\
V^-(-x) & x \leq 0 
\end{cases}
\]
which is well-defined since $V^+(0) = V^-(0)$ and has the properties stated in the lemma.
\end{proof}
\end{lemma}

As a corollary, we evaluate the following inner products, which will be important in the stability analysis.

\begin{corollary}\label{VpmPsiIPcorr}
\begin{equation}\label{VpmIPs}
\begin{aligned}
\langle \Psi^c(0), V^\pm(0; \lambda) \rangle &= 1 + \mathcal{O}(|\lambda|) \\
\langle \Psi(0), V^\pm(0; \lambda) \rangle &= \pm p_1 \lambda + \mathcal{O}(|\lambda|^2)
\end{aligned}
\end{equation}
where $p_1 = \langle \Psi(0), \partial_\lambda V^+(0; 0) \rangle$.
\begin{proof}
Using Lemma \ref{centersolutionslemma} and Lemma \ref{varsolutions}, we can expand $V^+(0; \lambda)$ in a Taylor series about $\lambda = 0$ to get
\begin{align*}
V^+(0; \lambda) &= V^+(0; 0) + \partial_\lambda V^+(0; 0) + \mathcal{O}(|\lambda|^2) \\
&= V^c(0) + \partial_\lambda V^+(0; 0) \lambda + \mathcal{O}(|\lambda|^2) 
\end{align*}
For the inner product with $\Psi^c(0)$,
\begin{align*}
\langle \Psi^c(0), V^\pm(0; \lambda) \rangle &= 
\langle \Psi^c(0), V^c(0) \rangle + \mathcal{O}(|\lambda|) \\
&= \langle \Psi^c(0), V^c(0) \rangle + \mathcal{O}(|\lambda|) \\
&= 1 + \mathcal{O}(|\lambda|)
\end{align*}
For the inner product $\langle \Psi(0), V^+(0; \lambda) \rangle$, we have
\begin{align*}
\langle \Psi(0), V^+(0; \lambda) \rangle 
&= \langle \Psi(0), V^c(0) \rangle + \langle \Psi(0), \partial_\lambda V^+(0; 0) \lambda \rangle + \mathcal{O}(|\lambda|^2) \\
&= (\partial_\lambda V^+(0; 0)) \lambda + \mathcal{O}(|\lambda|^2) \\
&= p_1 \lambda + \mathcal{O}(|\lambda|^2)
\end{align*}
For the inner product $\langle \Psi(0), V^-(0; \lambda) \rangle$, using Lemma \ref{centersolutionslemma},
\begin{align*}
\langle \Psi(0), V^-(0; \lambda) \rangle &= 
\langle \Psi(0), R V^+(0; -\lambda) \rangle \\
&= \langle R \Psi(0), -\partial_\lambda V^+(0; 0) \lambda \rangle + \mathcal{O}(|\lambda|^2) \\
&= -\langle \Psi(0), \partial_\lambda V^+(0; 0) \lambda \rangle + \mathcal{O}(|\lambda|^2) \\
&= -p_1 + \mathcal{O}(|\lambda|^2)
\end{align*}
\end{proof}
\end{corollary}

\subsection{Inversion}

Define the spaces
\begin{align*}
V_Z &= \bigoplus_{i=0}^{n-1} C_b([-X_{i-1},0]:\C^{2m+1}) \oplus C_b([0,X_i]:\C^{2m+1})  \\
V_a &= \bigoplus_{i=0}^{n-1} E^u(\lambda) \oplus E^s(\lambda) \\
V_b &= \bigoplus_{i=0}^{n-1} E^u(0) \oplus E^s(0) \\
V_c, V_{\tilde{c}} &= \bigoplus_{i=0}^{n-1} E^c(\lambda) = \bigoplus_{i=0}^{n-1} \C V_0(\lambda) \\
V_d &= \bigoplus_{i=0}^{n-1} \C \\
V_\lambda &= B_\delta(0) \subset \C
\end{align*}
where the subscripts are all taken $\Mod n$, since we are on a periodic domain. All the product spaces are endowed with the maximum norm, e.g. for $V_b$, 
\[
|b| = \max(|b_0^-|, \dots, |b_{n-1}^-|, |b_0^+|, \dots, |b_{n-1}^+|)
\]
In addition, we take the following notational convention. If we eliminate a subscript or superscript, we are taking the maximum over the eliminated subscript or superscript. For example,
\begin{enumerate}
	\item $|b_i| = \max(|b_i^+|, |b_i^-|)$ 
	\item $|b^+| = \max(|b_0^+|, \dots, |b_{n-1}^+|)$
\end{enumerate}

As in \cite{Sandstede1998}, we will write \eqref{systemZ} in integrated form as a set of fixed point equations. This is similar to \cite[(3.14)]{Sandstede1998}, except we are on a periodic domain and there is an additional center subspace. Using the variation of constants formula and the eigenprojections for $A(\lambda)$, we write \eqref{systemZ} as the set of fixed point equations
\begin{equation}\label{Zfpeq}
\begin{aligned}
Z_i^-(x) &= \Phi^s(x, -X_{i-1}; \lambda) a_{i-1}^- + \Phi^u(x, 0; \lambda) b_i^- + \Phi^c(x, -X_{i-1}; \lambda) c_{i-1} \\
&+ \int_0^x \Phi^u(x, y; \lambda)[P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ \int_{-X_{i-1}}^x \Phi^s(x, y; \lambda)[P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ \int_{-X_{i-1}}^x \Phi^c(x, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy  \\ 
Z_i^+(x) &= \Phi^u(x, X_i; \lambda) a_i^+ + \Phi^s(x, 0; \lambda) b_i^+ + \Phi^c(x, X_i; \lambda)(c_i + \tilde{c}_i) \\
&+ \int_0^x \Phi^s(x, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ \int_{X_i}^x \Phi^u(x, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ \int_{X_i}^x \Phi^c(x, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
\end{aligned}
\end{equation}
where $i = 0, \dots, n-1$. 

As in \cite{Sandstede1998}, we will solve the eigenvalue problem in a series of inversion steps. First, we will solve equation \eqref{systemZ} for $Z_i^\pm$. To do this, we rewrite \eqref{Zfpeq} as
\begin{equation}\label{L1L2eq}
[I - L_1(\lambda)]Z = L_2(\lambda)(a,b,c,\tilde{c},d)Z
\end{equation}
where $L_1(\lambda)$ is the linear operator consisting of the terms from the RHS of \eqref{Zfpeq} involving $Z_i^\pm$ and $L_2(\lambda)(a,b,c,\tilde{c},d)$ is the linear operator consisting of the terms from the RHS of \eqref{Zfpeq} which do not involve $Z_i^\pm$. Specifically,
\begin{align*}
[L_1&(\lambda)_i^- Z](x) 
= \int_0^x \Phi^u(x, y; \lambda)P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda) Z_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x \Phi^s(x, y; \lambda) P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda) Z_i^-(y) dy \\
&+ \int_{-X_{i-1}}^x \Phi^c(x, y; \lambda) P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda) Z_i^-(y) dy  \\ 
[L_1&(\lambda)_i^+ Z](x) = \int_0^x \Phi^s(x, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \\
&+ \int_{X_i}^x \Phi^u(x, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \\
&+ \int_{X_i}^x \Phi^c(x, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \\
\end{align*}
and
\begin{align*}
[L_2&(\lambda)_i^-(a,b,c,\tilde{c},d)](x) = \Phi^s(x, -X_{i-1}; \lambda) a_{i-1}^- + \Phi^u(x, 0; \lambda) b_i^- + \Phi^c(x, -X_{i-1}; \lambda) c_{i-1} \\
&+ \lambda^2 d_i \left( 
\int_0^x \Phi^u(x, y; \lambda) P_-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy 
+ \int_{-X_{i-1}}^x \Phi^s(x, y; \lambda) P_-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy \right. \\
&+ \left. \int_{-X_{i-1}}^x \Phi^c(x, y; \lambda) P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \right) \\
[L_2&(\lambda)_i^+(a,b,c,\tilde{c},d)](x) = \Phi^u(x, X_i; \lambda) a_i^+ + \Phi^s(x, 0; \lambda) b_i^+ + \Phi^c(x, X_i; \lambda)(c_i + \tilde{c}_i) \\
&+ \lambda^2 d_i \left( \int_0^x \Phi^s(x, y; \lambda) P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy 
+ \int_{X_i}^x \Phi^u(x, y; \lambda) P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \right. \\
&+ \left. \int_{X_i}^x \Phi^c(x, y; \lambda) P_+(y; \lambda)^{-1} \tilde{H}_i^+(y) dy \right)
\end{align*}

We obtain bounds for $L_1$ and $L_2$ in the next two lemmas.

\begin{lemma}\label{L1boundlemma}
For the linear operator $L_1$, we have uniform bound
\begin{equation}\label{L1uniformbound}
\|L_1(\lambda)Z\| \leq C e^{-\alpha_1 X_m}\|Z\|
\end{equation}
\begin{proof}
The bound on $L_1$ will depend on the integral involving the center subspace, since there is potential growth in that subspace. For the ``minus'' piece, using the bound for $G_i^\pm(x)$ from Lemma \ref{stabestimateslemma}
\begin{align*}
\left| \int_{-X_{i-1}}^x \right.&\left.\Phi^c(x, y; \lambda) P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda) Z_i^-(y) dy \right| \\ 
&\leq C \| Z_i^-\|\int_{-X_{i-1}}^x e^{\eta (x - y)} \left( e^{-\alpha_0 X_{i-1}} e^{-\alpha_0(X_{i-1} + y) } + e^{-2 \alpha_0 X_i} e^{\alpha_0 y} \right) dy \\
&\leq C \| Z_i^-\|\int_{-X_{i-1}}^x e^{\eta X_{i-1}} e^{-\alpha_0 X_{i-1}} \left( e^{-\alpha_0(X_{i-1} + y) } + e^{-\alpha_0 X_i} e^{\alpha_0 y} \right) dy \\
&\leq C e^{-\alpha_1 X_{i-1}} \| Z_i^-\| \int_{-X_{i-1}}^0 \left( e^{-\alpha_0(X_{i-1} + y) } + e^{-\alpha_0 X_i} e^{\alpha_0 y} \right) dy \\
&\leq C e^{-\alpha_1 X_{i-1}} \| Z_i^-\| 
\end{align*}
For the ``plus'' piece, 
\begin{align*}
\left| \int_{X_i}^x \Phi^c(x, y; \lambda) P_+(y; \lambda)^{-1} \tilde{H}_i^+(y) dy \right| \leq C e^{-\alpha_1 X_i} \| Z_i^+\| 
\end{align*}
Since the integrals involving the stable and unstable subspaces have stronger bounds, we have the uniform bound \eqref{L1uniformbound}.
\end{proof}
\end{lemma}

\begin{lemma}\label{L2boundlemma}
For the linear operator $L_1$, we have piecewise bound
\begin{equation}\label{L2bound}
\begin{aligned}
\| L_2(\lambda)_i^-(a,b,c,\tilde{c},d) \| &\leq C(|a_{i-1}^-| + |b_i^-| + |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}| + e^{-\alpha X_{i-1}}|\lambda|^2|d|)\\
\| L_2(\lambda)_i^+(a,b,c,\tilde{c},d) \| &\leq C(|a_i^+| + |b_i^+| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{\eta X_i}|\tilde{c}_i| + e^{-\alpha X_i}|\lambda|^2|d|)
\end{aligned}
\end{equation}
\begin{proof}
We will bound the ``minus'' piece first. For the term involving $c_{i-1}^-$, 
\begin{align*}
\Phi^c(x, -X_{i-1}; \lambda) c_{i-1}
&= e^{\nu(\lambda)(x + X_{i-1})}
\end{align*}
Since we do not know whether this term will grow or decay, we will bound it by
\begin{align*}
|\Phi^c(x, -X_{i-1}; \lambda) c_{i-1}|
&\leq |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}|
\end{align*}
For the other terms not involving integrals,
\[
\left| \Phi^s(x, -X_{i-1}; \lambda) a_{i-1}^- + \Phi^u(x, 0; \lambda) b_i^- \right| \leq C(|a_{i-1}^-| + |b_i^-|)
\]
For the integral terms, the bound is again determined by the integral involving the center subspace. This is similar to the corresponding integral in Lemma \ref{L1boundlemma}, except the bound for $\tilde{H}$ involves the decay constant $\alpha_1$; this gives us a similar bound for the center integral term, except it involves the decay constant $\alpha$. Putting all of this together,
\[
\| L_2(\lambda)_i^-(a,b,c,\tilde{c},d) \| \leq C(|a_{i-1}^-| + |b_i^-| + |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}| + e^{-\alpha X_{i-1}}|\lambda|^2|d|)
\]

For the ``plus'' piece, 
\begin{align*}
\Phi^c(x, X_i; \lambda) c_i
&= e^{\nu(\lambda)(x - X_i)}
\end{align*}
which we will bound by 
\begin{align*}
|\Phi^c(x, X_i; \lambda) c_i|
&\leq |e^{-\nu(\lambda)X_i}c_i| + |c_i|
\end{align*}
We bound the piece involving $\tilde{c}_i$ by
\[
|\Phi^c(x, X_i; \lambda) \tilde{c}_i|
\leq e^{\eta X_i}|\tilde{c}_i|
\]
Combining all of these, we have the bound
\[
\| L_2(\lambda)_i^+(a,b,c,\tilde{c},d) \| \leq C(|a_i^+| + |b_i^+| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{\eta X_i}|\tilde{c}_i| + e^{-\alpha X_i}|\lambda|^2|d|)
\]
\end{proof}
\end{lemma}

We can now solve equation \eqref{systemZ} for $Z$, which we do in the following lemma.

\begin{lemma}\label{Zinv0}
There exists an operator $Z_1: V_\lambda \times V_a \times V_b \times V_c \times V_{\tilde{c}} \times V_d \rightarrow V_z$ such that $Z = Z_1(\lambda)(a,b,c,\tilde{c},d)$ solves \eqref{systemZ}. The operator $Z_1$ is analytic in $\lambda$ and linear in $(a,b,c,\tilde{c},d)$, and we have the piecewise estimates
\begin{equation}\label{Z1bound}
\begin{aligned}
\| Z_1(\lambda)_i^-(a,b,c,\tilde{c},d) \| &\leq C(|a_{i-1}^-| + |b_i^-| + |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}| + e^{-\alpha X_{i-1}}|\lambda|^2|d|) \\
\| Z_1(\lambda)_i^+(a,b,c,\tilde{c},d) \| &\leq C(|a_i^+| + |b_i^+| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{\eta X_i}|\tilde{c}_i| + e^{-\alpha X_i}|\lambda|^2|d|)
\end{aligned}
\end{equation}
\begin{proof}

Using the bound on $L_1$ from Lemma \ref{L1boundlemma}, 
\[
\|L_1(\lambda)Z\| \leq C e^{-\alpha_1 X_m}\|Z\|
\]
Since we have chosen $X_m$ sufficiently large so that
$e^{-\alpha_1 X_m} \leq e^{-\tilde{\alpha} X_m} < \delta$, we have
\[
\|L_1(\lambda)Z\| \leq C \delta \|Z\|
\]
Thus, for sufficiently small $\delta$, $I - L_1(\lambda)$ is invertible on $V_Z$. The inverse $(I - L_1(\lambda))^{-1}$ is analytic in $\lambda$, thus we have the solution
\begin{equation}\label{L1L2eq}
Z = (I - L_1(\lambda)^{-1}L_2(\lambda)(a,b,c,\tilde{c},d)
\end{equation}
The bounds \eqref{Z1bound} follow by using the bounds \eqref{L2bound} from Lemma \ref{L2boundlemma} on the appropriate pieces of $Z$.
\end{proof}
\end{lemma}

In the next lemma, we solve equation \eqref{systemmiddle}, which are the matching conditions at $\pm X_i$.
\begin{align*}
P_i^+(X_i; \lambda) Z_i^+(X_i) - P_{i+1}^-(-X_i; \lambda) Z_{i+1}^-(-X_i) &= D_i d && i = 0, \dots, n-1
\end{align*}

% first inversion lemma : match at \pm X_i
\begin{lemma}\label{Zinv1}
There exists operators
\begin{align*}
A_1: &V_\lambda \times V_b \times V_c \times V_d \rightarrow V_a \times V_{\tilde{c}} \\
Z_2: &V_\lambda \times V_b \times V_c \times V_d \rightarrow V_Z
\end{align*}
such that 
\[
((a, \tilde{c}), Z) = (A_1(\lambda)(b, c, d), Z_2(\lambda)(b,c,d))
\]
solves \eqref{systemZ} and \eqref{systemmiddle} for any $(b, c, d)$ and $\lambda$. These operator are analytic in $\lambda$ and linear in $(b, c, d)$. Piecewise bounds for $A_1$ and $Z_2$ are given by
\begin{align}\label{A1bound}
|A_1&(\lambda)_i(b, c, d)|
\leq C \Big( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda^2||d|) + |D_i||d| \Big)
\end{align} 
and
\begin{equation}\label{Z2bound}
\begin{aligned}
\| Z_2(\lambda)_i^-(b,c,d) \| &\leq C(|b_i^-| + e^{-\alpha X_{i-1}}|b_{i-1}^+| + |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_{i-1})|d| \\
\| Z_2(\lambda)_i^+(b,c,d) \| &\leq C(|b_i^+| + e^{-\alpha X_i}|b_{i+1}^-| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|)
\end{aligned}
\end{equation}

\begin{proof}
At $\pm X_i$, the fixed point equations \eqref{Zfpeq} are
\begin{align*}
Z_{i+1}^-&(-X_i) = a_i^- + \Phi^u(-X_i, 0; \lambda) b_{i+1}^- + c_i \\ 
&+ \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) [P_-(y; \lambda)^{-1} G_{i+1}^-(y) P_-(y; \lambda)Z_{i+1}^-(y) + \lambda^2 d_{i+1} P_-(y; \lambda)^{-1} \tilde{H}_{i+1}^-(y)] dy \\
Z_i^+&(X_i) = a_i^+ + \Phi^s(X_i, 0; \lambda) b_i^+ + c_i + \tilde{c}_i \\
&+ \int_0^{X_i} [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] \Phi^s(X_i, y; \lambda) dy
\end{align*}
To obtain these, we used the fact that, for example, $a_i^- \in E^s(\lambda)$ and $\Phi^s(-X_{i-1}, -X_{i-1}; \lambda)$ is the identity on $E^s(\lambda)$. Applying the appropriate projections, subtracting, and using equation \eqref{projTheta}, we obtain the equation 
\begin{align*}
D_i &d = (I + \Theta_+(X_i; \lambda))a_i^+ + (I + \Theta_+(X_i; \lambda))(c_i + \tilde{c}_i) + P_+(X_i; \lambda)\Phi^s(X_i, 0; \lambda) b_i^+ \\
&+ P_+(X_i; \lambda) \int_0^{X_i} \Phi^s(X_i, y; \lambda)[P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&- (I + \Theta_-(-X_i; \lambda))a_i^- - (I + \Theta_-(-X_i; \lambda))c_i - P_-(-X_i; \lambda)\Phi^u(-X_i, 0; \lambda) b_{i+1}^- \\ 
&- P_-(-X_i; \lambda) \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) [P_-(y; \lambda)^{-1} G_{i+1}^-(y) P_-(y; \lambda)Z_{i+1}^-(y) + \lambda^2 d_{i+1} P_-(y; \lambda)^{-1} \tilde{H}_{i+1}^-(y)] dy
\end{align*}
which simplifies to
\begin{equation}\label{Didexpansion}
\begin{aligned}
D_i &d = a_i^+ - a_i^- + \tilde{c}_i^- \\
&+ \Theta_+(X_i; \lambda)a_i^+ - \Theta_-(-X_i; \lambda))a_i^- + \Theta_+(X_i; \lambda)\tilde{c}_i \\
&+ P_+(X_i; \lambda)\Phi^s(X_i, 0; \lambda) b_i^+ - P_-(-X_i; \lambda)\Phi^u(-X_i, 0; \lambda) b_{i+1}^- + \Theta_+(X_i; \lambda) c_i  - \Theta_-(-X_i; \lambda))c_i \\
&+ P_+(X_i; \lambda) \int_0^{X_i} \Phi^s(X_i, y; \lambda)[P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\ 
&- P_-(-X_i; \lambda) \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) [P_-(y; \lambda)^{-1} G_{i+1}^-(y) P_-(y; \lambda)Z_{i+1}^-(y) + \lambda^2 d_{i+1} P_-(y; \lambda)^{-1} \tilde{H}_{i+1}^-(y)] dy
\end{aligned}
\end{equation}
This is of the form
\begin{align}\label{Dideq1}
D_i d &= a_i^+ - a_i^- + \tilde{c}_i + L_3(\lambda)_i(a, b, c, \tilde{c}, d)
\end{align}
where the linear operator $L_3(\lambda)_i(a, b, c, \tilde{c}, d)$ is linear in $a,b,c,\tilde{c}$ and $d$, analytic in $\lambda$, and $L_3(\lambda)_i(a, b, c, \tilde{c}, d)$ is defined by the RHS of \cref{Didexpansion}. To get a bound on $L_3$, we will bound the individual terms. 
\begin{enumerate}
\item For the terms involving $a_i^\pm$, we use \eqref{conjthetadecay} to get
\[
|\Theta_+(X_i; \lambda)a_i^+ - \Theta_-(-X_i; \lambda)a_i^-| \leq C e^{-\alpha X_i}(|a_i^+| + |a_i^-|)
\]
\item For the terms involving $c_i$, and $\tilde{c}_i$, we use \eqref{conjthetadecay} to get
\[
|\Theta_+(X_i; \lambda)c_i + \Theta_+(X_i; \lambda)\tilde{c}_i - \Theta_-(-X_i; \lambda)c_i| \leq 
C e^{-\alpha X_i} (|c_i| + |\tilde{c}_i|)
\]

\item For the terms involving $b$, we use \eqref{Zevolbounds} to get
\[
| P_+(X_i; \lambda)\Phi^s(X_i, 0; \lambda) b_i^+ - P_-(-X_i; \lambda) \Phi^u(-X_i, 0; \lambda) b_{i+1}^-| \leq C e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|)
\]

\item For the integral terms involving $Z$, we use the bound $Z_1$ from Lemma \ref{Zinv0} to get
\begin{align*}
&\left|
P^+(X_i; \beta_i^+, \lambda) \int_0^{X_i} \Phi^s(X_i, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \right| \\
&\leq \int_0^{X_i} e^{-\alpha(X_i - y)} |G_i^+(y)| |Z_i^+(y)| dy \\
&\leq C \left(|a_i^+| + |b_i^+| + e^{\eta X_i}(|c_i| + |\tilde{c}_i|) + e^{-\alpha X_i}|\lambda|^2|d| \right) \int_0^{X_i} e^{-\alpha(X_i - y)} |G_i^+(y)| dy \\
&\leq C \left(|a_i^+| + |b_i^+| + |c_i| + |\tilde{c}_i| + e^{-\alpha X_i}|\lambda|^2|d| \right) \int_0^{X_i}  e^{\eta X_i} e^{-\alpha(X_i - y)} |G_i^+(y)| dy
\end{align*}
To evaluate the integral, we use the estimates on $G$ from Lemma \ref{stabestimateslemma} to get
\begin{align*}
\int_0^{X_i} &e^{\eta X_i} e^{-\alpha(X_i - y)} |G_i^+(y)| dy \leq \int_0^{X_i} e^{\eta X_i} e^{-\alpha(X_i - y)} \left(e^{-\alpha_0(X_i - y)}e^{-\alpha_0 X_i} + e^{-2 \alpha_0 X_{i-1}} e^{-\alpha_0 y} \right) dy \\
&\leq e^{-\alpha X_i} \int_0^{X_i} e^{-(\alpha + \alpha_0)(X_i - y)} dy + e^{-2 \alpha X_{i-1}} \int_0^{X_i} e^{-(\alpha - 2 \eta)(X_i - y)}e^{-2 \eta(X_i - y)}e^{\eta X_i}e^{-\alpha_0 y} dy \\
&\leq e^{-\alpha X_i} \int_0^{X_i} e^{-(\alpha + \alpha_0)(X_i - y)} dy + e^{-2 \alpha X_{i-1}} \int_0^{X_i} e^{-(\alpha - 2\eta)(X_i - y)}e^{-(\alpha_0 - 2 \eta)y} dy \\
&\leq C (e^{-\alpha X_i} + e^{-\eta X_i} e^{-2 \alpha X_{i-1}})
\end{align*}
where we extracted an extra $e^{-\eta X_i}$ in the second integral to cancel a term later on. Putting this all together,
\begin{align*}
&\left|
P^+(X_i; \beta_i^+, \lambda) \int_0^{X_i} \Phi^s(X_i, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \right| \\
&\leq C (e^{-\alpha X_i} + e^{-\eta X_i} e^{-2 \alpha X_{i-1}}) \left(|a_i^+| + |b_i^+| + |c_i| + |\tilde{c}_i| + e^{-\alpha X_i}|\lambda|^2|d| \right)
\end{align*}
The other integral is similar, except we have a term in $e^{-2 \alpha X_{i+1}}$.
\begin{align*}
&\left|
P^+(X_i; \beta_i^+, \lambda) \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) P_-(y; \lambda)^{-1} G_{i+1}^-(y) P_-(y; \lambda)Z_{i+1}^-(y) \right| \\
&\leq C (e^{-\alpha X_i} + e^{-\eta X_i} e^{-2 \alpha X_{i+1}}) \left(|a_i^-| + |b_{i+1}^-| + |c_i| + e^{-\alpha X_i}|\lambda|^2|d| \right)
\end{align*}

\item For the integral terms not involving $Z$, we use \eqref{Zevolbounds} and the estimates from Lemma \ref{stabestimates} to get
\begin{align*}
&\left|
P_+(X_i; \lambda) \int_0^{X_i} \Phi^s(X_i, y; \lambda) P_+(X_i; \lambda)^{-1} \tilde{H}_i^+(y) dy \right| \\
&\leq C \int_0^{X_i} e^{-\alpha(X_i - y)}e^{-\alpha_1 y} dy \\
&\leq C e^{-\alpha X_i} \int_0^{X_i} e^{-(\alpha_1 - \alpha)y} dy \\
&= C e^{-\alpha X_i} \int_0^{X_i} e^{-\eta y} dy \\ 
&= C e^{-\alpha X_i}
\end{align*}
The other integral is similar.
\end{enumerate}

Putting all of these together, we have the following bound for $L_3$.
\begin{equation}\label{L3bound}
|L_3(\lambda)_i(a, b, c, \tilde{c}, d)| \leq C (e^{-\alpha X_i} + e^{-\eta X_i}e^{-2\alpha X_m}) \left( |a_i| + |b_i^+| + |b_{i+1}^-| + |c_i| + |\tilde{c}_i| + |\lambda^2| |d| \right)
\end{equation}
Since $e^{-\alpha X_m} < \delta$, this becomes
\begin{align*}
|L_3(\lambda)_i(a, b, c, \tilde{c}, d)| \leq C \delta ( |a_i| + |\tilde{c}| ) + C e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda^2| |d| \right)
\end{align*}
Let 
\[
J_1: \bigoplus_{j=1}^n (E^s(\lambda) \times E^u(
\lambda) \times E^c(\lambda) ) \rightarrow \bigoplus_{j=1}^n \rightarrow \C^{2m+1}
\]
be defined by $(J_1)_i(a_i^+, a_i^-, \tilde{c}_i) = (a_i^+ - a_i^-, \tilde{c}_i)$. The map $J_i$ is a linear isomorphism since $E^s(\lambda) \oplus E^u(\lambda) \oplus E^c(\lambda) = \C^{2m+1}$. Consider the map
\[
S_1(a, \tilde{c}) = J_1 (a, \tilde{c}) + L_3(\lambda)(a, 0, c, 0, 0) = J_1( I + J_1^{-1} L_3(\lambda)(a, 0, c, 0, 0))
\]
For sufficiently small $\delta$, $||J_1^{-1} L_3(\lambda)(a, 0, \tilde{c}, 0, 0)|| < 1$, thus the operator $S_1(a, \tilde{c})$ is invertible. We can then solve for $(a, \tilde{c})$ to get
\[
(a, \tilde{c}) = A_1(\lambda)(b, c, d) = S_i^{-1}(-D d + L_3(\lambda)(0, b, 0, c, d)
\]
Using the bound on $L_3$ and noting which pieces are involved, $A_1$ has piecewise bounds
\begin{align*}
|A_1&(\lambda)_i(b, c, d)|
\leq C \Big( (e^{-\alpha X_i} + e^{-\eta X_i}e^{-2\alpha X_m}) (|b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda^2||d|) + |D_i||d| \Big)
\end{align*} 
We can plug this into the bound $Z_1$ from Lemma \ref{Zinv0} to get $Z_2(\lambda)(b,c,d)$, which has bound
\begin{align*}
\| Z_2(\lambda)_i^-(b,c,d) \| &\leq C(|b_i^-| + e^{-\alpha X_{i-1}}|b_{i-1}^+| + |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |c_{i-1}| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_{i-1})|d| \\
\| Z_2(\lambda)_i^+(b,c,d) \| &\leq C(|b_i^+| + e^{-\alpha X_i}|b_{i+1}^-| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|)
\end{align*}
\end{proof}
\end{lemma}

In the next two lemmas, we derive expressions for $a_i^\pm$ and $\tilde{c}_i$ which we will use in evaluating the jump conditions. First, we have the following expressions for $a_i^\pm$.

\begin{lemma}\label{lemma:aipm}
For the initial conditions $a_i^\pm$, we have the expressions
\begin{equation}\label{aipmexp1}
\begin{aligned}
a_i^+ &= P_i^+(X_i; \lambda)^{-1} P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c, d) \\
a_i^- &= -P_i^-(-X_i; \lambda)^{-1} P_0^s(\lambda) D_i d + A_2(\lambda)_i^-(b, c, d)
\end{aligned}
\end{equation}
$A_2$ is linear in $(b, c, d)$, and has piecewise bounds
\begin{align}
|A_2(\lambda)_i(b, c, d)|
&\leq C e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda|^2|d| + |D_i||d| \right) \label{A2bound}
\end{align}

\begin{proof}
We apply the projections $P_0^{s/u}(\lambda)$ on the eigenspaces $E^{s/u}(\lambda)$ to \eqref{Dideq1} to obtain the expressions
\begin{align*}
a_i^+ &= P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c^-, d) \\
a_i^- &= -P_0^s(\lambda) D_i d + A_2(\lambda)_i^-(b, c^-, d) \\
\end{align*}
The bound on the remainder term $A_2(\lambda)_i(b, c^-, d)$ is found by substituting the bound for $A_1$ into the bound for $L_3$ and simplifying. 
\begin{align*}
|A_2&(\lambda)_i(b, c^-, d)|
\leq C (e^{-\alpha X_i} + e^{-\eta X_i}e^{-2\alpha X_m}) \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda|^2|d| + |D_i||d| \right)
\end{align*} 

Anticipating what we will need at the end, we will modify the expressions for $a_i^+$ and $a_i^-$ to involve the conjugation projections. Using the conjugation operator $P_+(X_i; \lambda)$, we write $a_i^+$ as
\begin{align*}
a_i^+ &= P_+(X_i; \lambda)a_i^+ + (I - P_+(X_i; \lambda))a_i^+ \\
&= P_+(X_i; \lambda)a_i^+ - \Theta_+(X_i; \lambda))a_i^+
\end{align*}
Rearranging this and substituting the expression above for $a_i^+$, we get
\begin{align*}
P_+(&X_i; \lambda) a_i^+ = P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c^-, d) + \Theta_+(X_i; \lambda))a_i^+ \\
&= P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c^-, d) + \mathcal{O}\Big( e^{-\alpha X_i} ( e^{-\alpha X_i} (|b_i^+| + |b_{i+1}^-|) + |c_i| + e^{-\alpha X_i} |\lambda^2||d| + |D_i||d| )\Big)
\end{align*}
where we used the bound $A_1$ and the estimate \eqref{Thetadecay}. The last term on the RHS is the same (or higher) order as $A_2$, so we incorporate that into the bound on $A_2(\lambda)_i^+(b, c^-, d)$ to get
\begin{align*}
P_+(X_i; \lambda)a_i^+ &= P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c^-, d)
\end{align*}
Finally, apply the operator $P_+(X_i; \lambda)^{-1}$ on the left on both sides to solve for $a_i^+$. Since $P_+(X_i; \lambda)^{-1}$ a bounded operator, we will also incorporate this into $A_2(\lambda)_i^+(b, c^-, d)$, which will leave the bound unchanged. Thus we have
\begin{align*}
a_i^+ &= P_+(X_i; \lambda)^{-1} P_0^u(\lambda) D_i d + A_2(\lambda)_i^+(b, c^-, d)
\end{align*}
We do the same thing for $a_i^-$, which gives us
\begin{align*}
a_i^- &= -P_-(-X_i; \lambda)^{-1} P_0^s(\lambda) D_i d + A_2(\lambda)_i^-(b, c^-, d)
\end{align*}
\end{proof}
\end{lemma}

Next, we derive an expression for $\tilde{c}_i$.

\begin{lemma}\label{lemma:tildec1}
For the $\tilde{c}$, we have the expression
\begin{align}\label{tildeciexp1}
\tilde{c}_i &= 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + C_2(\lambda)_i(b, c, d)
\end{align}
$C_2$ is linear in $(b, c, d)$ and has piecewise bounds
\begin{align}
|C_2(\lambda)_i(b, c, d)| &\leq C |\lambda| e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + (|D_i| + |\lambda|)|d| \right) \label{C2bound}
\end{align}
\begin{proof}
We apply the projection $P^c(\lambda)$ on $E^c(
\lambda)$ to \eqref{Dideq1}, and write the resulting equation as
\begin{equation}\label{PcDid}
P^c(\lambda)D_i d = P^c(\lambda) P_+(X_i; \lambda)\tilde{c}_i + P^c(\lambda) \tilde{L}_3(
\lambda)_i(a,b,\tilde{c},c,d)
\end{equation}
where $\tilde{L}_3(\lambda)(a,b,\tilde{c},c,d)$ is the linear operator defined by
\begin{align*}
\tilde{L}_3&(\lambda)_i(a,b,\tilde{c},c,d) = (I + \Theta_+(X_i; \lambda))P_0^u(\lambda) a_i^+ - (I + \Theta_-(-X_i; \lambda))P_0^s(\lambda)a_i^- \\
&+ (I + \Theta_+(X_i; \lambda))\Phi^s(X_i, 0; \lambda) b_i^+ - (I + \Theta_-(-X_i; \lambda))\Phi^u(-X_i, 0; \lambda) b_{i+1}^- \\
&+ (\Theta_+(X_i; \lambda) - \Theta_-(-X_i; \lambda))c_i  \\
&+ (I + \Theta_+(X_i; \lambda)) \int_0^{X_i} \Phi^s(X_i, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \\
&+ \lambda^2 d_i (I + \Theta_+(X_i; \lambda))  \int_0^{X_i} \Phi^s(X_i, y; \lambda) P_+(y; \lambda)^{-1} \tilde{H}_i^+(y) dy \\ 
&- (I + \Theta_-(-X_i; \lambda)) \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) P_-(y; \lambda)^{-1} G_{i+1}^-(y) P_-(y; \lambda)Z_{i+1}^-(y) dy \\
&- \lambda^2 d_{i+1} (I + \Theta_-(-X_i; \lambda)) \int_0^{-X_i} \Phi^u(-X_i, y; \lambda) P_-(y; \lambda)^{-1} \tilde{H}_{i+1}^-(y) dy
\end{align*}

First, we use the expansion for $W_0(\lambda)$ from Lemma \ref{nulambdalemma} to evaluate $P^c(\lambda)D_i d$.
\begin{align*}
P^c(&\lambda)D_i d = \langle W_0(\lambda), D_i d \rangle \\
&= \langle W_0 + \overline{\lambda} \tilde{W}_0 + \mathcal{O}(\overline{\lambda}^2), D_i d \rangle \\
&= \langle W_0, D_i d \rangle + \langle \overline{\lambda} \tilde{W}_0, (Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) \rangle + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|) \\
&= \lambda \langle \tilde{W}_0, (Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) \rangle + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|) \\
&= \lambda ( \langle \tilde{W}_0, Q'(X_i) \rangle + \langle \tilde{W}_0, -R Q'(X_i)\rangle )(d_{i+1} - d_i ) \rangle + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|)\\
&= \lambda ( \langle \tilde{W}_0, Q'(X_i) \rangle + \langle -R \tilde{W}_0, Q'(X_i)\rangle )(d_{i+1} - d_i ) \rangle + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|)
\end{align*}
Using the symmetry relation $\tilde{W}_0 = -R \tilde{W}_0$ from Lemma \ref{nulambdalemma}, this becomes
\begin{equation}\label{PcDid2}
P^c(\lambda)D_i d = 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|)
\end{equation}

Next, we obtain a bound for $P^c(\lambda)\tilde{L}_3(\lambda)$. We note that applying the projection $P^c(\lambda)$ is equivalent to taking the inner product with $W_0(\lambda)$. When we do this, all of the terms in $\tilde{L}_3(\lambda)$ which are in $E^s(\lambda)$ or $E^u(\lambda)$ are eliminated outright. For the term involving $c_i$, we use a symmetry argument to get
\begin{align*}
\langle &W_0(\lambda), (\Theta_+(X_i; \lambda) - \Theta_-(-X_i; \lambda))c_i\rangle = \langle W_0 + \mathcal{O}(\lambda), (\Theta_+(X_i; \lambda) - \Theta_-(-X_i; \lambda) c_i \rangle \\
&= \langle W_0 + \mathcal{O}(\lambda), (\Theta_+(X_i; 0) - R \Theta_+(X_i; 0)R + \mathcal{O}(|\lambda|e^{-\alpha X_i} ))c_i \rangle \\
&= \langle W_0, \Theta_+(X_i; 0) - R \Theta_+(X_i; 0)R \rangle c_i + \mathcal{O}(|\lambda|e^{-\alpha X_i} |c_i|) \\
&= (\langle W_0, \Theta_+(X_i; 0) \rangle - \langle R W_0 R, \Theta_+(X_i; 0) \rangle) c_i + \mathcal{O}(|\lambda|e^{-\alpha X_i} |c_i|) \\
&= (\langle W_0, \Theta_+(X_i; 0) \rangle - \langle W_0, \Theta_+(X_i; 0) \rangle) c_i + \mathcal{O}(|\lambda|e^{-\alpha X_i} |c_i|) \\
&= \mathcal{O}(|\lambda|e^{-\alpha X_i} |c_i|) 
\end{align*}
since $W_0 R = R W_0 = W_0$. For the remaining terms, we use Lemma \ref{trichotomyprojunconj}(iii) and the bounds on the individual terms from Lemma \ref{Zinv1} to get
\begin{align*}
|P^c(\lambda)\tilde{L}_3&(\lambda)_i(a,b,\tilde{c},c,d)| \leq C |\lambda| e^{-\alpha X_i} \left( |a_i^+| + |a_i^-| + |b_i^+| + |b_{i+1}^-| + |c_i| + e^{-\alpha X_i} |\lambda^2| |d| \right)
\end{align*}
Substituting the bound $A_1$ for $|a_i^+|$ and $|a_i^-|$, this becomes
\begin{align*}
|P^c(\lambda)\tilde{L}_3&(\lambda)_i(a,b,\tilde{c},c,d)| \leq C |\lambda| e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |D_i||d| + e^{-\alpha X_i} |\lambda^2| |d| \right)
\end{align*}

Rearranging equation \eqref{PcDid} and substituting \eqref{PcDid2}, we get
\begin{equation}\label{PcDid3}
\begin{aligned}
P^c(\lambda)&(I + \Theta_+(X_i; \lambda)) \tilde{c}_i = 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + |\lambda|)|d|) + P^c(\lambda) \tilde{L}_3(\lambda)_i(a,b,\tilde{c},c,d) \\
&+\mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{\alpha_0 X_i} + |\lambda|)|d|)
\end{aligned}
\end{equation}
Looking at the bound for $\tilde{L}_3$, we see that if $\lambda = 0$, $\tilde{c}_i = 0$ as well. We want our expression for $\tilde{c}_i$ to capture that. We also want to ensure that the lowest order term is $\langle \tilde{W}_0, Q'(X_i) \rangle$. In order to do that, we first need to obtain an improved bound for $\tilde{c}_i$. Expanding the conjugation operator $P_+(X_i; \lambda)$ and recalling that $P^c(\lambda)$ is the identity on $E^c(\lambda)$, we write \eqref{PcDid2} as
\begin{align*}
P^c(\lambda)(I + \Theta_+(X_i; \lambda)) \tilde{c}_i &= P^c(\lambda)D_i d + P^c(\lambda) \tilde{L}_3(
\lambda)_i(a,b,\tilde{c},c,d) \\
\tilde{c}_i &= P^c(\lambda)D_i d - \Theta_+(X_i; \lambda))\tilde{c}_i + P^c(\lambda) \tilde{L}_3(
\lambda)_i(a,b,\tilde{c},c,d)
\end{align*}
Using the bound $A_1$ for $\tilde{c}$ on the RHS, the bound for $\tilde{L}_3$, and equation \eqref{PcDid2} for $P^c(\lambda)D_i d$, we obtain the estimate
\begin{equation}\label{tildecest}
|\tilde{c}_i| \leq C \left( e^{-\alpha X_i}(|\lambda| + e^{-\alpha X_m} )(|b_i^+| + |b_{i+1}^-| + |c_i| + |d|) \right)
\end{equation}

Finally, we solve equation \eqref{PcDid} for $\tilde{c}_i$. Expanding the LHS of \eqref{PcDid} in $\lambda$ and writing $\tilde{c}_i \in E^c(\lambda)$ as $\tilde{c}_i V_0(\lambda)$, we get
\begin{align*}
P^c&(\lambda)P_+(X_i; \lambda)) \tilde{c}_i
= (P^c(0) + \mathcal{O}(\lambda))(P_+(X_i; 0) + \mathcal{O}(\lambda))(V_0 + \mathcal{O}(\lambda))\tilde{c}_i \\
&= P^c(0)P_+(X_i; 0)V_0 \tilde{c}_i + \mathcal{O}(|\lambda||\tilde{c}_i|) \\
&= \langle W_0, V^c(X_i) \rangle \tilde{c}_0 + \mathcal{O}(|\lambda||\tilde{c}_i|) \\
&= \tilde{c}_0 + \mathcal{O}(|\lambda||\tilde{c}_i|)
\end{align*}
since $\langle W_0, V^c(X_i) \rangle = \langle \Psi^c(X_i), V^c(X_i) \rangle = 1$. Using this, \eqref{PcDid2} becomes
\begin{align*}
\tilde{c}_i &= 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + P^c(\lambda) \tilde{L}_3(
\lambda)_i(a,b,\tilde{c},c,d) + \mathcal{O}(e^{-\alpha_1 X_i} |\lambda|(e^{-\alpha_0 X_i} + |\lambda|)|d|) + \mathcal{O}(|\lambda||\tilde{c}_i|) \\
&= 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + C_2(\lambda)_i(b, c, d)
\end{align*}
Using the estimate for $\tilde{L}_3$ and the estimate \eqref{tildecest} for $\tilde{c}_i$, we have the bound
\begin{align*}
|C_2(\lambda)(b, c, d)_i| \leq C |\lambda| e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + (|D_i| + |\lambda|)|d| \right)
\end{align*}
\end{proof}
\end{lemma}

In the next lemma, we solve for the conditions at $x = 0$, which are
\begin{equation}\label{centercond}
\begin{aligned}
P_\pm(0; \lambda) Z_i^\pm(0) &\in \oplus Y^+ \oplus Y^- \oplus \C \Psi(0) \oplus \C \Psi^c(0) \\
P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) &\in \C \Psi(0) \oplus \C \Psi^c(0)
\end{aligned}
\end{equation}
Recall that we have the decomposition
\begin{equation}\label{DSdecomp}
\C^{2m+1} = \C Q'(0) \oplus Y^+ \oplus Y^- \oplus \C \Psi(0) \oplus \C \Psi^c(0)
\end{equation}
Thus \eqref{centercond} is equivalent to the three projections
\begin{equation}\label{centercond2}
\begin{aligned}
P(\C Q'(0) ) P_-(0; \lambda) Z_i^-(0) &= 0 \\
P(\C Q'(0) ) P_+(0; \lambda) Z_i^+(0) &= 0 \\
P(Y_i^+ \oplus Y_i^-) ( P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) ) &= 0
\end{aligned}
\end{equation}
where the kernel of each projection is the remaining spaces in the direct sum decomposition \eqref{DSdecomp}. We do not need to include $\C Q'(0)$ in the third equation of \eqref{centercond2} since we eliminated any component in $\C Q'(0)$ in the first two equations.

% second inversion lemma
\begin{lemma}\label{Zinv2}
There exist operators
\begin{align*}
B_1: &V_\lambda \times V_c \times V_d \rightarrow V_b \\
A_3: &V_\lambda \times V_c \times V_d \rightarrow V_a \times V_{\tilde{c}} \\
Z_3: &V_\lambda \times V_c \times V_d \rightarrow V_Z
\end{align*}
such that $( (a, \tilde{c}) , b, Z ) = ( A_3(\lambda)(c, d), B_1(\lambda)(c, d), Z_3(\lambda)(c, d) )$ solves \eqref{systemZ}, \eqref{systemmiddle}, \eqref{systemcenter1}, and \eqref{systemcenter2} for any $(c, d)$. These operators are analytic in $\lambda$ and linear in $(c, d)$. Bounds for $B_1$ and $A_3$ are given by
\begin{align}
|B_1&(\lambda)_i(c, d)| \leq C \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|) \nonumber \\
&+ e^{-\alpha X_m}(|c_{i-1}| + |c_i|) + (|\lambda| + e^{-\alpha X_m})^2 |d|  \Big)\label{B1bound} \\
|A_3&(\lambda)_i(c, d)|
\leq C \Big(  
e^{-\alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \nonumber \\
&+ e^{-(\alpha - \eta)X_i}|c_i| + e^{-\alpha X_i} e^{-\alpha X_m}(|c_{i-1}| + |c_{i+1}|) + e^{-\alpha X_i} |\lambda^2||d| + |D_i||d| \Big) \label{A3bound}
\end{align} 
Piecewise bounds for $Z_3$ are given by
\begin{equation}\label{Z3bound}
\begin{aligned}
\| Z_3&(\lambda)_i^-(b,c,d) \| \leq C\Big(|c_{i-1}| + e^{-\alpha X_m}(|c_i| + e^{-\alpha X_i} |c_{i-2}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_{i-1})|d| \\
&+ |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + (|\lambda| + e^{-\alpha X_m})(|e^{-\nu(\lambda)X_i} c_i| + e^{-\alpha X_i} |e^{\nu(\lambda)X_{i-2}} c_{i-2}|)\Big) \\
\| Z_3&(\lambda)_i^+(b,c,d) \| \leq C\Big(|c_i| + e^{-\alpha X_m}(|c_{i-1}| + e^{-\alpha X_i} |c_{i+1}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|) \\
&+ |e^{-\nu(\lambda)X_i} c_i| + (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + e^{-\alpha X_i} |e^{-\nu(\lambda)X_{i+1}} c_{i+1}|)\Big)
\end{aligned}
\end{equation}
In addition, we can write
\begin{align*}
a_i^+ &= P_i^+(X_i; \lambda) P_0^u(\lambda) D_i d + A_4(\lambda)_i^+(c, d) \\
a_i^- &= -P_i^-(-X_i; \lambda) P_0^s(\lambda) D_i d + A_4(\lambda)_i^-(c, d) \\
\tilde{c}_i &= 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) + C_4(\lambda)_i(c, d) )
\end{align*}
where $A_4$ and $C_4$ are linear in $(c, d)$, and have piecewise bounds
\begin{align}
|A_4&(\lambda)_i(c, d)|
\leq C \Big(  
e^{-\alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \nonumber \\
&+ e^{-(\alpha - \eta)X_i}|c_i| + e^{-\alpha X_i} e^{-\alpha X_m}(|c_{i-1}| + |c_{i+1}|) + e^{-\alpha X_i} |\lambda^2||d| + e^{-\alpha X_i}|D||d| \Big) \label{A4bound} \\
|C_4&(\lambda)_i(c, d)| \leq C |\lambda| e^{-\alpha X_i} \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \nonumber \\
&+ |c_i| + (|D_i| + |\lambda|)|d| \Big) \label{C4bound}
\end{align}

\begin{proof}
At $x = 0$, the fixed point equations \eqref{Zfpeq} become
\begin{align*}
Z_i^-(0) &= \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- + \Phi^u(0, 0; \lambda) b_i^- + \Phi^c(0, -X_{i-1}; \lambda) c_{i-1} \\
&+ \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda)[P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\ 
Z_i^+(0) &= \Phi^u(0, X_i; \lambda) a_i^+ + \Phi^s(0, 0; \lambda) b_i^+ + \Phi^c(0, X_i; \lambda) c_i + \Phi^c(0, X_i; \lambda) \tilde{c}_i \\
&+ \int_{X_i}^0 \Phi^u(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ \int_{X_i}^0 \Phi^c(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
\end{align*}

First, recall that at $Q(0)$, the tangent spaces to the stable and unstable manifold are given by
\begin{align*}
T_{Q(0)} W^u(0) &= \R Q'(0) \oplus Y^- \\
T_{Q(0)} W^s(0) &= \R Q'(0) \oplus Y^+
\end{align*}
Thus we have
\begin{align*}
P^-(0)^{-1} Q'(0) &= V^- \in E^u(0) \\
P^+(0)^{-1} Q'(0) &= V^+ \in E^s(0)
\end{align*}
Let
\begin{align*}
E^u(0) &= \C V^- \oplus E^- \\
E^s(0) &= \C V^+ \oplus E^+ \\
\end{align*}
Then we have
\begin{align*}
P^-(0)^{-1} Y^- = E^- \\
P^+(0)^{-1} Y^+ = E^+ \\
\end{align*}
We will use this to decompose $b_i^\pm$ uniquely as $b_i^\pm = x_i^\pm + y_i^\pm$, where $x_i^\pm \in \C V^\pm$ and $y_i^\pm \in E^\pm$. Since the evolution operators $\Phi(0, 0; \lambda)$ involve $\lambda$ but the projections we will be taking are for $\lambda = 0$, we make the following substitutions.
\begin{align*}
\Phi^u(0, 0; \lambda) = P_0^u(\lambda) &= P_0^u(0) + (P_0^u(\lambda) - P_0^u(0)) \\
P_0^c(\lambda) &= P_0^c(0) + (P_0^c(\lambda) - P_0^c(0))
\end{align*}
Using these together with equation \eqref{centerevol} for the evolution $\Phi^c$ on $E^c(\lambda)$, we have
\begin{align*}
Z_i^-&(0) = \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- + x_i^- + y_i^- + (P_0^u(\lambda) - P_0^u(0))b_i^- \\
&+ P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} + (P_0^c(\lambda) - P_0^c(0)) e^{\nu(\lambda) X_{i-1}} c_{i-1} \\
&+ \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy  \\ 
Z_i^+&(0) = \Phi^u(0, X_i; \lambda) a_i^+ + x_i^+ + y_i^+ + (P_0^s(\lambda) - P_0^s(0)) b_i^+ \\
&+ P_0^c(0) e^{-\nu(\lambda)X_i} c_i + (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} c_i \\
&+ P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i + (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} \tilde{c}_i \\
&+ \int_{X_i}^0 \Phi^u(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ \int_{X_i}^0 \Phi^c(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy 
\end{align*}
Finally, we apply the conjugation operators $P_\pm(0; \lambda)$ in \eqref{centercond2}. For the $c$, $\tilde{c}$, and $b$ terms, we expand the conjugations operators in $\lambda$ as
\[
P_\pm(0; \lambda) = P_\pm(0; 0) + (P_\pm(0; \lambda) - P_\pm(0; 0))
\]
to obtain the expressions
\begin{align*}
P_-&(0; \lambda) Z_i^-(0) = P_-(0; 0)( x_i^- + y_i^- + P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} ) \\
&+ P_-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- + (P_-(0; \lambda) - P_-(0; 0))b_i^- + P_-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^- \\
&+ (P_-(0; \lambda) - P_-(0; 0)) P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} + P_-(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{\nu(\lambda) X_{i-1}} c_{i-1} \\
&+ P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy 
\end{align*}
and
\begin{align*}
P_+&(0; \lambda) Z_i^+(0) = P_+(0; 0)( x_i^+ + y_i^+ + P_0^c(0) e^{-\nu(\lambda)X_i} c_i + P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i )\\
&+ P_+(0; \lambda) \Phi^u(0, X_i; \lambda) a_i^+ + (P_+(0; \lambda) - P_+(0; 0)) b_i^+ + P_+(0; \lambda) (P_0^s(\lambda) - P_0^s(0)) b_i^+ \\
&+ (P_+(0; \lambda) - P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} c_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} c_i \\
&+ (P_+(0; \lambda) - P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} \tilde{c}_i \\
&+ P_+(0; \lambda) \int_{X_i}^0 \Phi^u(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ P_+(0; \lambda) \int_{X_i}^0 \Phi^c(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
\end{align*}

With this setup, the projections on $Q'(0)$ and $Y^+ \oplus Y^-$ will either eliminate or act as the identity on the terms in the first lines of $P_i^-(0; \lambda) Z_i^-(0)$ and $P_i^+(0; \lambda) Z_i^+(0)$. Thus, applying the projections in \eqref{centercond2}, we obtain an expression of the form
\begin{equation}\label{projxy}
\begin{pmatrix}x_i^- \\ x_i^+ \\ 
y_i^+ - y_i^- \end{pmatrix} + L_4(\lambda)_i(b, c, d) = 0
\end{equation}
To get a bound on $L_4$, we will bound the individual terms involved. 

\begin{enumerate}
\item For the $a_i$ terms, we substitute $A_1$ from Lemma \ref{Zinv1} and use the bound \eqref{A1bound} to get
\begin{align*}
|P_-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^-| 
&\leq C \left( e^{-2 \alpha X_{i-1}} (|b_{i-1}^+| + |b_i^-| + |c_{i-1}| + |\lambda^2||d|) + e^{- \alpha X_{i-1}} |D_{i-1}||d| \right)\\
|P_+(0; \lambda) \Phi^u(0, X_i; \lambda) a_i^+| 
&\leq C \left( e^{-2 \alpha X_i} (|b_i^+| + |b_{i+1}^-| + |c_i| + |\lambda|^2|d|) + e^{-\alpha X_i}|D_i||d| \right)
\end{align*}

\item For the $b_i$ and $c_i$ terms, since the conjugation operators $P_\pm(x; \lambda)$ and eigenprojections $P_0^{s/u}(\lambda)$ are smooth in $\lambda$, we have
\begin{align*}
|(P_-(0; \lambda) &- P_-(0; 0))b_i^- + P_-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^-| \\
&\leq C |\lambda| |b_i^-|
\end{align*}
The $b_i^+$ is similar. For the $c_i$ terms, we similarly have
\begin{align*}
|(P_-(0; \lambda) &- P_-(0; 0)) P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} + P_-(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{\nu(\lambda) X_{i-1}} c_{i-1} | \leq C|\lambda||e^{\nu(\lambda) X_{i-1}} c_{i-1}|
\end{align*}
and
\begin{align*}
|(P_+(0; \lambda) &- P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} c_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} c_i| \leq C |\lambda||e^{-\nu(\lambda)X_i} c_i|
\end{align*}

\item For the $\tilde{c}_i$ terms, we use the expression for $\tilde{c}_i$ from Lemma \ref{lemma:tildec1} and the bounds on $C_2$ from that lemma, to get
\begin{align*}
|(P_+&(0; \lambda) - P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} \tilde{c}_i| \\
&\leq C |\lambda| e^{-|\nu(\lambda)|X_i} |\lambda| e^{-\alpha X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |d| \right) \\
&\leq C |\lambda|^2 e^{-(\alpha - \eta)X_i} \left( |b_i^+| + |b_{i+1}^-| + |c_i| + |d| \right) 
\end{align*}

\item The bound on the integral terms is determined by the integrals involving the center subspace, since the other integrals will have stronger bounds. For the integrals involving $Z$, we use $Z_2$ from Lemma \ref{Zinv2} and the bound on $G_i^\pm$ from Lemma \ref{stabestimateslemma} to get
\begin{align*}
&\left| P_i^+(0; \lambda) \int_{X_i}^0 \Phi^c(0, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \right| \\
&\leq C \| Z_i^+(y) \| \int_0^{X_i} e^{\eta y} \left( e^{-\alpha_0 X_i} e^{-\alpha_0(X_i - y) } + e^{-2 \alpha_0 X_{i-1}} e^{-\alpha_0 y} \right) dy \\
&\leq C \| Z_i^+(y) \| \left( e^{-\alpha X_i} \int_0^{X_i} e^{-\alpha_0(X_i - y) } dy + e^{-2 \alpha_0 X_{i-1}} \int_0^{X_i} e^{-(\alpha_0 - \eta) y}dy \right) \\
&\leq C e^{-\alpha X_m} (|b| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|)
\end{align*}
Similarly,
\begin{align*}
&\left| \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) dy \right| \\
&\leq C e^{-\alpha X_m} (|b| + |e^{-\nu(\lambda)X_i} c_i| + |c_i| + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|)
\end{align*}

\item For the integrals not involving $Z$, we have
\begin{align*}
\left| \lambda^2 d_i P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy \right| &\leq C |\lambda|^2 |d| \int_{-X_{i-1}}^0 e^{-\eta y} e^{\alpha_1 y} dy \\
&\leq C |\lambda|^2 |d|
\end{align*}
The other term is similar.
\end{enumerate}

Combining all of these individual bounds together, using the fact that $D_i = \mathcal{O}(e^{-\alpha X_m})$, and simplifying, we obtain the bound for $L_4(\lambda)_i(b, c, d)$.
\begin{align*}
L_4(\lambda)_i&(b, c, d) \leq 
C\Big( (|\lambda| + e^{-\alpha X_m})|b|  
+ e^{-\alpha X_m}(|c_{i-1}| + |c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|) + (|\lambda| + e^{-\alpha X_m})^2 |d|  \Big) 
\end{align*}
Since $|\lambda|, e^{-\alpha X_m} < \delta$, this becomes
\begin{align*}
L_4(\lambda)_i&(b, c, d) \leq 
C \delta |b| + C \Big( (|\lambda| + e^{-\alpha X_m})|b|  
+ e^{-\alpha X_m}(|c_{i-1}| + |c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|) + (|\lambda| + e^{-\alpha X_m})^2 |d|  \Big) 
\end{align*}
which is uniform in $|b|$. Define the map
\[
J_2: \left( \bigoplus_{j=1}^n \C V^+ \oplus \C V^- \right) \oplus
\left( \bigoplus_{j=1}^n E^+ \oplus E^- \right) 
\rightarrow \bigoplus_{j=1}^n \C V^+ \oplus \C V^- \oplus (E^+ \oplus E^-)
\]
by 
\[
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i = ( x_i^+, x_i^-, y_i^+ - y_i^- )
\]
Since $\C^{2m} = E^s(0) \oplus E^u(0) = \C V^+ \oplus \C V^- \oplus (E^+ \oplus E^-)$, $J_2$ is an isomorphism. Using this as the fact that $b_i = (x_i^- + y_i^-, x_i^+ + y_i^+)$, we can write \eqref{projxy} as
\begin{equation}\label{projxy2}
J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i 
+ L_4(\lambda)_i(b_i, 0, 0) + L_4(\lambda)_i(0, c, d) = 0
\end{equation}
Consider the map
\begin{align*}
S_2(b)_i &= J_2( (x_i^+, x_i^-),(y_i^+, y_i^-))_i 
+ L_4(\lambda)_i(b_i, 0, 0) 
\end{align*}
Substituting this in \eqref{projxy2}, we have
\begin{align*}
S_2(b) &= -L_4(\lambda)(0, c, d)
\end{align*}

For sufficiently small $\delta$, the operator $S_2(b)$ is invertible. Thus we can solve for $b$ to get
\begin{align}
b = B_1(\lambda)(c,d) 
= -S_2^{-1} L_4(\lambda)(0, c, d)
\end{align}
The bound on $B_1$ is given by the bound on $L_4$, where we note which piece is involved.
\begin{align*}
|B_1(\lambda)_i&(c, d)| \leq C \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|) \\
&+ e^{-\alpha X_m}(|c_{i-1}| + |c_i|) + (|\lambda| + e^{-\alpha X_m})^2 |d|  \Big)
\end{align*}
We now plug $B_1$ into all of the previous bounds. Plugging $B_1$ into the bound \eqref{A1bound} for $A_1$, we get $A_3$ with bound
\begin{align*}
|A_3&(\lambda)_i(c, d)|
\leq C \Big(  
e^{-\alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \\
&+ e^{-(\alpha - \eta)X_i}|c_i| + e^{-\alpha X_i} e^{-\alpha X_m}(|c_{i-1}| + |c_{i+1}|) + e^{-\alpha X_i} |\lambda^2||d| + |D_i||d| \Big)
\end{align*} 
Next, we plug $B_1$ into the bound $Z_2$ to get $Z_3$ with bounds
\begin{align*}
\| Z_3&(\lambda)_i^-(b,c,d) \| \leq C\Big(|c_{i-1}| + e^{-\alpha X_m}(|c_i| + e^{-\alpha X_i} |c_{i-2}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_{i-1})|d| \\
&+ |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + (|\lambda| + e^{-\alpha X_m})(|e^{-\nu(\lambda)X_i} c_i| + e^{-\alpha X_i} |e^{\nu(\lambda)X_{i-2}} c_{i-2}|)\Big) \\
\| Z_3&(\lambda)_i^+(b,c,d) \| \leq C\Big(|c_i| + e^{-\alpha X_m}(|c_{i-1}| + e^{-\alpha X_i} |c_{i+1}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|) \\
&+ |e^{-\nu(\lambda)X_i} c_i| + (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + e^{-\alpha X_i} |e^{-\nu(\lambda)X_{i+1}} c_{i+1}|)\Big)
\end{align*}
We can also plug $B_1$ into the bound \eqref{A2bound} for $A_2$ to get $A_4$ with bound
\begin{align*}
|A_4&(\lambda)_i(c, d)|
\leq C \Big(  
e^{-\alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \\
&+ e^{-(\alpha - \eta)X_i}|c_i| + e^{-\alpha X_i} e^{-\alpha X_m}(|c_{i-1}| + |c_{i+1}|) + e^{-\alpha X_i} |\lambda^2||d| + e^{-\alpha X_i}|D||d| \Big)
\end{align*} 
Finally, we plug in $B_1$ into the bound for $C_2$ to get $C_4$ with bound
\begin{align*}
|C_4(\lambda)&(c, d)_i| \leq C |\lambda| e^{-\alpha X_i} \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|)\\
&+ |c_i| + (|D_i| + |\lambda|)|d| \Big)
\end{align*} 

\end{proof}
\end{lemma}

\subsection{Jump Conditions}

Up to this point, we have solved uniquely for $a$, $b$, and $\tilde{c}$. We will not be able to obtain a unique solution for $c$ and $d$. We will instead compute jump conditions in the direction of $\Psi(0)$ and $\Psi^c(0)$. Obtaining a nontrivial solution for $c_i$ and $d$ will be equivalent to these jump conditions being 0.

First, we compute the jump in the direction of $\Psi^c(0)$. Before we do that, we prove the following lemma regarding inner products with $\Psi^c(0)$ and $\Psi(0)$.

% lemma : inner products with Psi and Psi^c
\begin{lemma}\label{PsiIP}
We have the following expressions involving the inner product with $\Psi^c(0)$.
\begin{enumerate}[(i)]
	\item $\langle \Phi^c(0), P^\pm(0) V \rangle = V$ for all $V \in E^c(0)$.
	\item $\langle \Phi(0), P^\pm(0) V \rangle = 0$ for all $V \in E^c(0)$.
	\item $\langle \Phi^c(0), P^-(0) V \rangle = 0$ and $\langle \Phi(0), P^-(0) V \rangle = 0$ for all $V \in E^u(0)$.
	\item $\langle \Phi^c(0), P^+(0) V \rangle = 0$ and $\langle \Phi(0), P^+(0) V \rangle = 0$ for all $V \in E^s(0)$.
\end{enumerate}
\begin{proof}
For (i), recall that $E^c(0) = \Span\{ V_0 \}$, where $V_0$ is the eigenvector of $A(0)$ corresponding to the eigenvalue 0. Furthermore, the constant function $Z(x) = V_0$ solves $Z' = A(0) Z$ with initial condition $V_0$. Let $W^-(x) = P^-(x) Z(x) = P^-(x) V_0$. By the conjugation lemma, we can write
\[
W^-(x) = V_0 + \mathcal{O}({e^{-\tilde{\alpha}|x|}})
\]
Since the inner product $\langle \Phi^c(x), W^-(x) \rangle$ is constant in $x$, sending $x \rightarrow -\infty$, we conclude by the continuity of the inner product that
\[
\langle \Phi^c(0), W^-(0) \rangle = \langle W_0, V_0 \rangle = 1 
\]
Thus $\langle \Phi^c(0), P^-(0) V \rangle = V$ for all $V \in E^c(0)$. The same holds for $\langle \Phi^c(0), P^+(0) V \rangle$.

For (ii), we use the same argument as in (i), except we look at the inner product $\langle \Phi(x), W^-(x) \rangle$. Since this is constant in $x$, we send $x \rightarrow \infty$. This time, $W^-(x)$ remains bounded, but $\Phi(x)$ decays to 0, thus by the continuity of the inner product, we conclude that $\langle \Phi(0), W^-(0) \rangle = 0$, from which (ii) follows.

For (iii) and (iv), we note that $P^-(0)E^u = \C Q'(0) \oplus Y^-$ and $P^+(0)E^u = \C Q'(0) \oplus Y^+$. The result follows since $\Psi^c(0), \Psi(0) \perp \C Q'(0) \oplus Y^+ \oplus Y^-$.
\end{proof}
\end{lemma}

We can now compute the jump in the direction of $\Psi^c(0)$.

% jump lemma : center adjoint
\begin{lemma}\label{jumpcenteradj}
The jumps in the direction of $\Psi^c(0)$ are given by
\begin{equation}\label{xic}
\begin{aligned}
\xi^c_i = e^{-\nu(\lambda) X_i} c_i^- - e^{\nu(\lambda) X_{i-1}} c_{i-1}^- + 2 \lambda e^{-\nu(\lambda)X_i} \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i )  + R^c(\lambda)_i(c, d)
\end{aligned}
\end{equation}
The remainder term $R^c_i(c, d)$ is analytic in $\lambda$, linear in $(c, d)$, and has bound
\begin{align*}
||R^c&(c, d)_i|| \leq C |\lambda| \Big(
(|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |e^{-\nu(\lambda)X_i}c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})( e^{-\alpha X_{i-1}} |e^{\nu(\lambda)X_{i-2}}c_{i-2}| + e^{-\alpha X_i} |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|)  \\
&+ e^{-\alpha X_m}(|c_{i+1}|+|c_{i-2}|) + e^{-2 \alpha X_m}(|c_i|+|c_{i-1}|) + (|\lambda| + e^{-\alpha X_m}|\lambda| + e^{-(2 \alpha - \eta) X_m })|d|
\Big)
\end{align*}

The jump conditions can be written as the matrix equation
\begin{equation}\label{matrixjumpc}
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda) + C_2) c + (\tilde{A} + D_1) d = 0
\end{equation}
where
\begin{align*}
K(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & -e^{\nu(\lambda)X_0} \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& -e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & -e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0}
\end{pmatrix}
\end{align*}
and
\begin{align*}
\tilde{A} &= \begin{pmatrix}
-e^{-\nu(\lambda)X_1} k_1 & e^{-\nu(\lambda)X_1} k_1 \\
& -e^{-\nu(\lambda)X_2} k_2 & e^{-\nu(\lambda)X_2} k_2 \\
& & \ddots & \ddots \\
& &  & -e^{-\nu(\lambda)X_0} k_0 & e^{-\nu(\lambda)X_0} k_0
\end{pmatrix}
\end{align*}
where 
\begin{equation}\label{defki}
k_i = 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle
\end{equation}
The matrices have uniform bounds
\begin{align*}
\tilde{A} &= \mathcal{O}(|\lambda| e^{-\alpha X_m}) \\
C_1 &= \mathcal{O}(|\lambda|e^{-\alpha X_m}(|\lambda| + e^{-\alpha X_m})) \\
C_2 &= \mathcal{O}(|\lambda|e^{-\alpha X_m}) \\
D_1 &= \mathcal{O}(|\lambda|(|\lambda| + e^{-\alpha X_m}|\lambda| + e^{-(2 \alpha - \eta) X_m })|d|)
\end{align*}
$K_1(\lambda)$ has the same form as $K(\lambda)$, but each term in $K(\lambda)$ has been multiplied by a factor of order $\mathcal{O}(|\lambda|(|\lambda| + e^{-\alpha X_m}))$. The specific forms of $K_1(\lambda)$ and $C_1$ are given in the proof.

\begin{proof}
Recall that $\Psi^c(0) = W_0$. From Lemma \ref{Zinv2}, $P_i^\pm(0; \lambda) Z_i^\pm(0)$ are given by\begin{align*}
P_-&(0; \lambda) Z_i^-(0) = P_-(0; 0)( b_i^- + P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} ) \\
&+ P_-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- + (P_-(0; \lambda) - P_-(0; 0))b_i^- + P_-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^- \\
&+ (P_-(0; \lambda) - P_-(0; 0)) P_0^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} + P_-(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{\nu(\lambda) X_{i-1}} c_{i-1} \\
&+ P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy \\
&+ P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) [P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) + \lambda^2 d_i P_-(y; \lambda)^{-1} \tilde{H}_i^-(y)] dy
\end{align*}
and
\begin{align*}
P_+&(0; \lambda) Z_i^+(0) = P_+(0; 0)( b_i^+ + P_0^c(0) e^{-\nu(\lambda)X_i} c_i + P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i )\\
&+ P_+(0; \lambda) \Phi^u(0, X_i; \lambda) a_i^+ + (P_+(0; \lambda) - P_+(0; 0)) b_i^+ + P_+(0; \lambda) (P_0^s(\lambda) - P_0^s(0)) b_i^+ \\
&+ (P_+(0; \lambda) - P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} c_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} c_i \\
&+ (P_+(0; \lambda) - P_+(0; 0))P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i + P_+(0; \lambda) (P_0^c(\lambda) - P_0^c(0)) e^{-\nu(\lambda)X_i} \tilde{c}_i \\
&+ P_+(0; \lambda) \int_{X_i}^0 \Phi^u(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
&+ P_+(0; \lambda) \int_{X_i}^0 \Phi^c(0, y; \lambda) [P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \lambda^2 d_i P_+(y; \lambda)^{-1} \tilde{H}_i^+(y)] dy \\
\end{align*}

The leading order terms are those involving $c$ and $\tilde{c}$. For the leading order terms involving $c$, 
\begin{align*}
\langle W_0, P_-(0; 0) P_0^c e^{\nu(\lambda) X_{i-1}} c_{i-1} \rangle &= \langle W_0, V^c(0) e^{\nu(\lambda) X_{i-1}} c_{i-1} \rangle \\
&= e^{\nu(\lambda) X_{i-1}} c_{i-1}
\end{align*}
Similarly,
\begin{align*}
\langle W_0, P_+(0; 0) P^c(0) e^{-\nu(\lambda) X_i} c_i \rangle &= e^{-\nu(\lambda) X_i} c_i 
\end{align*}
For the term involving $\tilde{c}$, using the expression from Lemma \ref{Zinv2}, we have
\begin{align*}
\langle &\Psi^c(0), P_i^+(0; 0) P_0^c(0) e^{-\nu(\lambda)X_i} \tilde{c}_i \rangle
= 2 \lambda e^{-\nu(\lambda)X_i} \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i ) \\
&+ \mathcal{O}\Big( |\lambda| e^{-(\alpha - \eta) X_i} \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) + |c_i| + (|D_i| + |\lambda|)|d| \Big)
\end{align*}

The rest of the terms are higher order.
\begin{enumerate}

\item For the terms involving $a$, we use the bound $A_3$ together with Lemma \ref{centerprojlemma}(iv) and the exponential dichotomy evolution bounds to get
\begin{align*}
|P_-(0; \lambda) &\Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^-| \\
&\leq C |\lambda| e^{-\alpha X_{i-1}} \Big(  
e^{-\alpha X_{i-1}} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-2}} c_{i-2}| + |e^{-\nu(\lambda)X_i} c_i |) \\
&+ e^{-(\alpha - \eta)X_i}|c_{i-1}| + e^{-\alpha X_{i-1}} e^{-\alpha X_m}(|c_{i-2}| + |c_i|) + e^{-\alpha X_{i-1}} |\lambda^2||d| + |D_{i-1}||d| \Big)
\end{align*} 
and
\begin{align*}
|P_+(0; \lambda) &\Phi^u(0, X_i; \lambda) a_i^+| \\
&\leq C |\lambda| e^{-\alpha X_i} \Big( e^{-\alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \\
&+ e^{-(\alpha - \eta)X_i}|c_i| + e^{-\alpha X_i} e^{-\alpha X_m}(|c_{i-1}| + |c_{i+1}|) + e^{-\alpha X_i} |\lambda^2||d| + |D_i||d| \Big)
\end{align*}

\item For the terms involving $b$, the terms $P_-(0; 0) b_i^-$ and $P_+(0, 0)b_i^+$ are eliminated outright when we take the inner product with $W_0$. For the other terms, we use the estimate for $B_1$ from Lemma \ref{Zinv2}.
\begin{align*}
|(P_-&(0; \lambda) - P_-(0; 0))b_i^- + P_-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^-| \\
&\leq C |\lambda| \Big( (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|) \\
&+ e^{-\alpha X_m}(|c_{i-1}| + |c_i|) + (|\lambda| + e^{-\alpha X_m})^2 |d|  \Big)
\end{align*}

\item For the integral terms, we only need to bound the integrals involving the center subspace, since these will have weaker bounds than the integrals involving the stable and unstable subspaces. For the integrals involving $Z$, 
\begin{align*}
P_+(0; \lambda) &\Phi^c(0, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) \\
&= P_+(0; 0) \Phi^c(0, y; 0) P_+(y; 0)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \mathcal{O}(e^{\eta y}|\lambda||G_i^+(y) Z_i^+(y)|) \\
&= e^{-\nu(\lambda) y} P_+(0; 0) P_+(y; 0)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \mathcal{O}(e^{\eta y}|\lambda||G_i^+(y) Z_i^+(y)|) \\
&= e^{-\nu(\lambda) y} G_i^+(y) P_+(y; \lambda) Z_i^+(y) + \mathcal{O}(e^{\eta y}|\lambda||G_i^+(y) Z_i^+(y)|)
\end{align*}
By Lemma \ref{W0projlemma}, 
\[
\langle W_0, e^{-\nu(\lambda) y} G_i^+(y) P_+(y; \lambda) Z_i^+(y) \rangle = 0
\]
Using this together with the estimate $Z_3$ and the estimate of the integral from Lemma \ref{Zinv2},
\begin{align*}
&\left| \langle W_0, P_+(0; \lambda) \int_{X_i}^0 \Phi^c(0, y; \lambda) P_+(y; \lambda)^{-1} G_i^+(y) P_+(y; \lambda) Z_i^+(y) dy \rangle \right| \\
&\leq C |\lambda| e^{-\alpha X_m}\Big(|c_i| + e^{-\alpha X_m}(|c_{i-1}| + e^{-\alpha X_i} |c_{i+1}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_i||d|) \\
&+ |e^{-\nu(\lambda)X_i} c_i| + (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + e^{-\alpha X_i} |e^{-\nu(\lambda)X_{i+1}} c_{i+1}|)\Big)
\end{align*}
Similarly,
\begin{align*}
&\left| \langle W_0, P_-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_-(y; \lambda)^{-1} G_i^-(y) P_-(y; \lambda)Z_i^-(y) dy \rangle \right| \\
&\leq C |\lambda| e^{-\alpha X_m} \Big(|c_{i-1}| + e^{-\alpha X_m}(|c_i| + e^{-\alpha X_i} |c_{i-2}|) + e^{-(\alpha - \eta) X_m}|\lambda|^2|d| + |D_{i-1})|d| \\
&+ |e^{\nu(\lambda)X_{i-1}}c_{i-1}| + (|\lambda| + e^{-\alpha X_m})(|e^{-\nu(\lambda)X_i} c_i| + e^{-\alpha X_i} |e^{\nu(\lambda)X_{i-2}} c_{i-2}|)\Big)
\end{align*}

For the integrals not involving $Z$, we use the estimate we derived in Lemma \ref{Zinv2} to get 
\begin{align*}
\left| \langle W_0, P_-(0; \lambda) \lambda^2 d_i \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_-(y; \lambda) \tilde{H}_i^-(y) dy \rangle \right| 
&\leq C |\lambda|^2 |d|
\end{align*}
The other one is similar.

\end{enumerate}

Putting all of this together, we obtain the center jump expressions
\begin{align*}
\xi^c_i = e^{-\nu(\lambda) X_i} c_i^- - e^{\nu(\lambda) X_{i-1}} c_{i-1}^- + 2 \lambda e^{-\nu(\lambda)X_i} \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i )  + R^c(\lambda)_i(c, d)
\end{align*}
The remainder term $R^c_i(c, d)$ has bound
\begin{align*}
||R^c&(c, d)_i|| \leq C |\lambda| \Big(
(|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |e^{-\nu(\lambda)X_i}c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})( e^{-\alpha X_{i-1}} |e^{\nu(\lambda)X_{i-2}}c_{i-2}| + e^{-\alpha X_i} |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|)  \\
&+ e^{-\alpha X_m}(|c_{i+1}|+|c_{i-2}|) + e^{-2 \alpha X_m}(|c_i|+|c_{i-1}|) + (|\lambda| + e^{-\alpha X_m}|\lambda| + e^{-(2 \alpha - \eta) X_m })|d|
\Big)
\end{align*}

To write this in matrix form, let
\begin{align*}
K(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & -e^{\nu(\lambda)X_0} \\
-e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& -e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & -e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0}
\end{pmatrix}
\end{align*}
The leading order terms in the center jump expression involving $c$ are given by $K(\lambda)c$, where $c = (c_1, \dots, c_{n-1}, c_0)^T$. We will organize the remainder terms into three groups.

\begin{enumerate}
\item Let $G_i$ be the sum of the remainder terms of the form $e^{\pm \nu(\lambda) X_i} c_i$. Then 
\[
G_i = \gamma_{i,i-1} e^{\nu(\lambda)X_{i-1}}c_{i-1} + \gamma_{i,i} e^{-\nu(\lambda)X_i}c_i + \gamma_{i,i-2} e^{\nu(\lambda)X_{i-2}}c_{i-2} + \gamma_{i,i+1} e^{-\nu(\lambda)X_{i+1}}c_{i+1}
\] 
where from the remainder bound we have for the coefficients $\gamma_{i, j}$
\begin{align*}
\gamma_{i,i-1}, \gamma_{i,i} &= \mathcal{O}(|\lambda|(|\lambda| + e^{-\alpha X_m})) \\
\gamma_{i,i-2} &= \mathcal{O}(e^{-\alpha X_{i-1}}|\lambda|(|\lambda| + e^{-\alpha X_m})) \\
\gamma_{i,i+1} &= \mathcal{O}(e^{-\alpha X_i}|\lambda|(|\lambda| + e^{-\alpha X_m}))
\end{align*}
Adding and subtracting $e^{\nu(\lambda)X_i}c_i$ and $e^{-\nu(\lambda)X_{i-1}}c_{i-1}$, this becomes
\begin{align*}
G_i &= \gamma_{i,i-1} e^{\nu(\lambda)X_{i-1}}c_{i-1} + \gamma_{i,i} e^{-\nu(\lambda)X_i}c_i + \gamma_{i,i-2} ( e^{\nu(\lambda)X_{i-2}}c_{i-2} - e^{-\nu(\lambda)X_{i-1}}c_{i-1}) \\
&+ \gamma_{i,i-2} e^{-\nu(\lambda)X_{i-1}}c_{i-1} + \gamma_{i,i+1} (e^{-\nu(\lambda)X_{i+1}}c_{i+1} - e^{\nu(\lambda)X_i}c_i) + \gamma_{i,i+1} e^{\nu(\lambda)X_i}c_i
\end{align*}
Next, we note that
\begin{align*}
\gamma_{i,i-2} e^{-\nu(\lambda)X_{i-1}}c_{i-1} &= \mathcal{O}(e^{-(\alpha - 3 \eta) X_{i-1}}|\lambda|(|\lambda| + e^{-\alpha X_m})e^{\nu(\lambda)X_{i-1}}c_{i-1} \\
\gamma_{i,i+1} e^{\nu(\lambda)X_i}c_i &= \mathcal{O}(e^{-(\alpha - 3 \eta) X_i}|\lambda|(|\lambda| + e^{-\alpha X_m})e^{-\nu(\lambda)X_i}c_i
\end{align*}
Both of these coefficients are higher order than $\gamma_{i,i-1}$ and $\gamma_{i,i}$. Substituting these into $G_i$, collecting terms, and keeping the notation $\gamma_{i,j}$ for the resulting coefficients, we have
\begin{align*}
G_i(&\lambda) = \gamma_{i,i-1} e^{\nu(\lambda)X_{i-1}}c_{i-1} + \gamma_{i,i} e^{-\nu(\lambda)X_i}c_i \\
&+ \gamma_{i,i-2} ( e^{\nu(\lambda)X_{i-2}}c_{i-2} - e^{-\nu(\lambda)X_{i-1}}c_{i-1}) + \gamma_{i,i+1} (e^{-\nu(\lambda)X_{i+1}}c_{i+1} - e^{\nu(\lambda)X_i}c_i)
\end{align*}
where we have the same bounds on the coefficients $\gamma_{i,j}$. Using these, we can write the terms of the form $e^{\pm \nu(\lambda) X_i} c_i$ in matrix form as
\[
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda)) c
\]
where $K_1(\lambda)$ is ``$\gamma-$perturbation'' of $K(\lambda)$ given by
\begin{align*}
K_1(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} \gamma_{1,1} & & & & & e^{\nu(\lambda)X_0}\gamma_{1,0} \\
e^{\nu(\lambda)X_1}\gamma_{2,1} & e^{-\nu(\lambda)X_2}\gamma_{2,2} \\
& e^{\nu(\lambda)X_2}\gamma_{3,2} & e^{-\nu(\lambda)X_3}\gamma_{3,3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & e^{\nu(\lambda)X_{n-1}}\gamma_{0,n-1} & e^{-\nu(\lambda)X_0}\gamma_{0,0} 
\end{pmatrix}
\end{align*}
with 
\[
\gamma_{i,i-1}, \gamma_{i,i} = \mathcal{O}(|\lambda|(|\lambda| + e^{-\alpha X_m}))
\] 
and $C_1$ is the periodic, banded matrix
\begin{align*}
C_1 &= \begin{pmatrix}
0 & \gamma_{1,2} & 0 & 0 & \dots & 0 & -\gamma_{n-1,0} & 0 \\
0 & 0 & \gamma_{2,3} & 0 & \dots & 0 & 0 & -\gamma_{2,1} \\
-\gamma_{3,1} & 0 & 0 & \gamma_{3,4} & \dots & 0 & 0 & 0 \\
&  & & \ddots  \\
0 & 0 & 0 & 0 & \dots & 0 & 0 & \gamma_{n-1,0} \\
\gamma_{0,1} & 0 & 0 & 0 & \dots & -\gamma_{0, n-2} & 0 & 0 
\end{pmatrix}
\end{align*}
which has uniform bound
\begin{align*}
||C_1|| &= 
\mathcal{O}(e^{-\alpha X_m}|\lambda|(|\lambda| + e^{-\alpha X_m}))
\end{align*}

\item For the terms involving $c$ without the exponential, we write them in matrix form as $C_2 c$, where
\[
C_2 = \mathcal{O}(|\lambda|e^{-\alpha X_m})
\]

\item For the terms involving $D$, we first separate out leading order terms $2 \lambda e^{-\nu(\lambda)X_i} \langle \tilde{W}_0, Q'(X_i) \rangle (d_{i+1} - d_i )$, and place them in a matrix $\tilde{A}$, defined by
\begin{align*}
\tilde{A} &= \begin{pmatrix}
-e^{-\nu(\lambda)X_1} k_1 & e^{-\nu(\lambda)X_1} k_1 \\
& -e^{-\nu(\lambda)X_2} k_2 & e^{-\nu(\lambda)X_2} k_2 \\
& & \ddots & \ddots \\
& &  & -e^{-\nu(\lambda)X_0} k_0 & e^{-\nu(\lambda)X_0} k_0
\end{pmatrix}
\end{align*}
where
\[
k_i = 2 \lambda \langle \tilde{W}_0, Q'(X_i) \rangle
\]
Since $Q'(X_i) = \mathcal{O}(e^{-\alpha_0 X_i})$, $e^{-\nu(\lambda)X_i} k_i = \mathcal{O}(|\lambda|e^{-\alpha X_i})$, thus we have the uniform bound
\[
\tilde{A} = \mathcal{O}(|\lambda|e^{-\alpha X_m})
\]

Let $D_1$ be the matrix we get from the terms involving $d$ in $R^c(\lambda)_i(c, d)$. Then $D_1$ has uniform bound
\begin{align*}
D_1 &= \mathcal{O}(|\lambda|(|\lambda| + e^{-\alpha X_m}|\lambda| + e^{-(2 \alpha - \eta) X_m })|d|)
\end{align*}
\end{enumerate}

Combining everything, the center jump condition can be written in matrix form as
\[
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda) + C_2) c + (\tilde{A} + D_1) d = 0
\]
\end{proof}
\end{lemma}

Finally, we compute the jump in the direction of $\Psi(0)$.
% lemma : jump in decaying adjoint direction
\begin{lemma}\label{jumpadj}
The jumps in the direction of $\Psi(0)$ are given by
\begin{equation}
\begin{aligned}
\xi_i = 
\langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) \\
+ M_\Psi \lambda( e^{-\nu(\lambda)X_i}c_i + e^{\nu(\lambda)X_{i-1}}c_{i-1})
- \lambda_2 d_i M + R_i(\lambda)(c, d)
\end{aligned}
\end{equation}
$M$ is the higher order Melnikov integral
\begin{equation}\label{M}
M = \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\end{equation}
The remainder term $R(\lambda)(c^-, d)$ is analytic in $\lambda$, linear in $(c^-, d)$, and has piecewise bound
\begin{align*}
|R(\lambda)_i&(c_i^-, d)| \leq C \Big( (|\lambda| + e^{-\alpha X_m})^2(|e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |e^{-\nu(\lambda)X_i}c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})^2(e^{-(\alpha - \eta) X_{i-1}} |e^{\nu(\lambda)X_{i-2}}c_{i-2}| + e^{-(\alpha - \eta) X_i} |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \\
&+ (|\lambda| + e^{-\alpha X_m})^3 |d| \Big)
\end{align*}
We can write these conditions in matrix form as
\begin{equation}
(\lambda M_\Psi \tilde{K}(\lambda) + C_2 K(\lambda) + K_2(\lambda))c + (A - \lambda^2 M I + D_2)d = 0
\end{equation}
The matrix $A$ is given by
\begin{align*}
A &= \begin{pmatrix}
-a_0 -a_1 & a_0 + a_1 \\
-a_0 + a_1 & -a_0 - a_1
\end{pmatrix} && n = 2 \\
A &= \begin{pmatrix}
-a_{n-1} - a_0 & a_0 & & & \dots & a_{n-1}\\
a_0 & -a_0 - a_1 &  a_1 \\
& a_1 & -a_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & a_{n-2} & -a_{n-2} - a_{n-1} \\
\end{pmatrix} && n > 2
\end{align*}
with
\begin{align*}
a_i &= \langle \Psi(X_i), Q'(-X_i) \rangle \\
\end{align*}
The matrix $K(\lambda)$ is defined in Lemma \ref{jumpcenteradj}. The matrix $\tilde{K}(\lambda)$ is given by
\begin{align*}
\tilde{K}(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & e^{\nu(\lambda)X_0} \\
e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0} 
\end{pmatrix}
\end{align*}
The remainder matrices have uniform bounds
\begin{align*}
C_2 &= \mathcal{O}(e^{-(\alpha - \eta) X_m}(|\lambda| + e^{-\alpha X_m})^2) \\
D_2 &= \mathcal{O}((|\lambda| + e^{-\alpha X_m})^3)
\end{align*}
$K_2(\lambda)$ has the same form as $K(\lambda)$, but each term in $K(\lambda)$ has been multiplied by a factor of order $\mathcal{O}(|\lambda| + e^{-\alpha X_m})^2$. The specific forms of $K_2(\lambda)$ and $C_2$ are given in the proof.

\begin{proof}
Recall that the terms $P_i^\pm(0; \lambda) Z_i^\pm(0)$ are given by
\begin{align*}
P_i^-(0; \lambda) Z_i^-(0) &= P^-(0) b_i^- + P_i^-(0; \lambda) e^{\nu(\lambda) X_{i-1}} c_{i-1} \\
&+ P_i^-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- + (P_i^-(0; \lambda) - P^-(0))b_i^- + P_i^-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^- \\
&+ \lambda^2 d_i P_i^-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy \\
&+ \lambda^2 d_i P_i^-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy  \\ 
P_i^+(0; \lambda) Z_i^+(0) &= P^+(0) b_i^+ + P_i^+(0; \lambda) e^{-\nu(\lambda)X_i} c_i \\
&+ P_i^+(0; \lambda) \Phi^u(0, X_i; \lambda) a_i^+ + (P_i^+(0; \lambda) - P^+(0)) b_i^+ + P_i^+(0; \lambda) (P_0^s(\lambda) - P_0^s(0)) b_i^+ \\
&+ P_i^+(0; \lambda) e^{-\nu(\lambda)X_i} \tilde{c}_i \\
&+ \lambda^2 d_i P_i^+(0; \lambda) \int_{X_i}^0 \Phi^u(0, y; \lambda) P_i^+(y; \lambda)^{-1} \tilde{H}_i^+(y) dy \\
&+ \lambda^2 d_i P_i^+(0; \lambda) \int_{X_i}^0 \Phi^c(0, y; \lambda) P_i^+(y; \lambda)^{-1} \tilde{H}_i^+(y) dy
\end{align*}

As in Lemma \ref{jumpcenteradj}, we begin by computing the leading order terms.

\begin{enumerate}
\item The non-center integral will give us the higher order Melnikov integral. For the ``minus'' piece, we use the uniform estimate $\tilde{H}_i^-(y) = H(y) + \mathcal{O}(e^{-\alpha_0 X_m})$ from Lemma \ref{stabestimates} to get
\begin{align*}
&\langle \Psi(0), P_i^-(0; \lambda) \int_{-X_{i-1}}^0 \Phi^s(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy \rangle \\
&= \int_{-X_{i-1}}^0 \langle \Psi(0), P_i^-(0; \lambda), \Phi^s(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) \rangle dy \\
&= \int_{-X_{i-1}}^0 \langle \Psi(0), P_i^-(0; \lambda), \Phi^s(0, y; \lambda) P_i^-(y; \lambda)^{-1} H(y) \rangle dy + \mathcal{O}({e^{-\alpha_0 X_m}})\\
&= \int_{-X_{i-1}}^0 \langle \Psi(0), \Theta(0, y) H(y) \rangle dy + \mathcal{O}(|\lambda| + {e^{-\alpha X_m}})\\
&= \int_{-X_{i-1}}^0 \langle \Theta(y, 0)^* \Psi_i(0), H(y) \rangle dy + \mathcal{O}(|\lambda| + {e^{-\alpha X_m}})\\
&= \int_{-X_{i-1}}^0 \langle \Psi(y), H(y) \rangle dy + \mathcal{O}(|\lambda| + {e^{-\alpha X_m}})\\
&= \int_{-\infty}^0 \langle \Psi(y), H(y) \rangle dy + \mathcal{O}(|\lambda| + {e^{-\alpha X_m}})
\end{align*}
The ``positive'' piece is similar, and gives us the other half of the Melnikov integral.

\item For the terms involving $a$, we use the expressions from Lemma \ref{Zinv2}. This is similar to what we did in Lemma \ref{jumpcenteradj}. For the term involving $a_{i-1}^-$, we have 
\begin{align*}
\langle &\Psi(0), P_i^-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- \rangle \\
&= -\langle \Psi(0), \Theta_i^s(0, -X_{i-1}; \lambda) P_0^s(0) D_{i-1} d \rangle + \langle \Psi(0), P_i^-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) A_4(\lambda)_{i-1}^-(c, d) \rangle
\end{align*}
For the leading order term, similar to Lemma \ref{jumpcenteradj}, we have
\begin{align*}
\langle \Psi(0), &\Theta_i^s(0, -X_{i-1}; \lambda) P_0^s(0) D_{i-1} d \rangle \\
&= \langle \Psi(-X_{i-1}), P^s_-(-X_{i-1}) P_0^s(0) D_{i-1} d \rangle + \mathcal{O}(e^{-2 \alpha X_{i-1}}(|\lambda| + e^{-2 \alpha X_m})|d|)
\end{align*}
Substituting the expression for $D_{i-1}d$ from Lemma \ref{stabestimates} and proceeding as in Lemma \ref{jumpcenteradj}, the leading order term becomes
\begin{align*}
\langle \Psi(0), &\Theta_i^s(0, -X_{i-1}; \lambda) P_0^s(0) D_{i-1} d \rangle \\
&= \langle \Psi(-X_{i-1}), Q'(-X_{i-1}) + Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) + \mathcal{O}(e^{-2 \alpha X_m}(|\lambda| + e^{-\alpha X_m})|d|) \\
&= \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) + \mathcal{O}(e^{-2 \alpha X_m}(|\lambda| + e^{-\alpha X_m})|d|)
\end{align*}
since $\langle \Psi(-X_{i-1}), Q'(-X_{i-1}) \rangle = 0$. For the higher order term, we use the bound for $A_4$ from Lemma \ref{Zinv2} to get
\begin{align*}
\langle \Psi(0), &P_i^-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) A_4(\lambda)_{i-1}^-(c, d) \rangle \\
&\leq C e^{-\alpha X_{i-1}} \Big(  
e^{-\alpha X_{i-1}} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-2}} c_{i-2}| + |e^{-\nu(\lambda)X_i}c_i|) \\
&+ e^{-(\alpha - \eta)X_{i-1}}|c_{i-1}| + e^{-\alpha X_m} |\lambda^2||d| + e^{-\alpha X_m}|D||d| \Big)
\end{align*}
Combining all of these, we have for the $a_{i-1}^-$ term,
\begin{align*}
\langle &\Psi(0), P_i^-(0; \lambda) \Phi^s(0, -X_{i-1}; \lambda) a_{i-1}^- \rangle = -\langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) \\
&+ \mathcal{O}\Big(  
e^{-2 \alpha X_{i-1}} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-2}} c_{i-2}| + |e^{-\nu(\lambda)X_i}c_i|) + e^{-(2 \alpha - \eta)X_{i-1}}|c_{i-1}| \\
&+ (|\lambda| + e^{-\alpha X_m})^3 |d| )
\end{align*}
Similarly, for the $a_i^+$ term, we have
\begin{align*}
\langle &\Psi(0), P_i^+(0; \lambda) \Phi^u(0, X_i; \lambda) a_i^+ \rangle = \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) \\
&+ \mathcal{O}\Big(  
e^{-2 \alpha X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) + e^{-(2 \alpha - \eta)X_i}|c_i| \\
&+ e^{-\alpha X_m} 
(|\lambda| + e^{-\alpha X_m})^3 |d| )
\end{align*}
\end{enumerate}

The remaining terms will be higher order. Doing these in turn, we have
\begin{enumerate}
\item For the terms involving $b$, we first note that by Lemma \ref{PsiIP}, the terms $P^-(0) b_i^-$ and $P^+(0)b_i^+$ will vanish when we take the inner product with $\Psi(0)$. For the remaining terms, we substitute the estimate for $B_1$ from Lemma \ref{Zinv2}.
\begin{align*}
&|\langle \Psi(0), (P_i^-(0; \lambda) - P^-(0))b_i^- + P_i^-(0; \lambda)(P_0^u(\lambda) - P_0^u(0))b_i^-| \\
&\leq C (|\lambda| + e^{-\alpha X_m})\Big( 
(|\lambda| + e^{-\alpha X_m})( |e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_i} c_i|)+ (|\lambda| + e^{-\alpha X_m})^2|d| \Big)
\end{align*}

\item For the terms involving $c$, we use Lemmas \ref{Vpmlambdalemma} and \ref{Ecconj} to get
\begin{align*}
\langle \Psi(0), P_i^-(0; \lambda) e^{\nu(\lambda) X_{i-1}} c_{i-1} \rangle &= \langle \Psi^c(0), V^-(0; \lambda) e^{\nu(\lambda) X_{i-1}} c_{i-1} \rangle + \mathcal{O}(e^{-2 \alpha X_m}|e^{\nu(\lambda) X_{i-1}} c_{i-1}|) \\
&= -M_\phi \lambda e^{\nu(\lambda) X_{i-1}} c_{i-1} + \mathcal{O}((|\lambda|^2 + e^{-2 \alpha X_m})|e^{\nu(\lambda) X_{i-1}} c_{i-1}|)
\end{align*}
Similarly,
\begin{align*}
\langle \Psi(0), P_i^+(0; \lambda) e^{-\nu(\lambda) X_i} c_i \rangle 
&= M_\phi \lambda e^{-\nu(\lambda) X_i} c_{i-1} + \mathcal{O}((|\lambda|^2 + e^{-2 \alpha X_m})|e^{-\nu(\lambda) X_i} c_i|)
\end{align*}

\item For the center integral term, we have
\begin{align*}
&\langle \Psi(0), P_i^-(0; \lambda)
\int_{-X_{i-1}}^0 \Phi^c(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) dy \rangle \\
&= \int_{-X_{i-1}}^0 \langle \Psi(0), P_i^-(0; \lambda) \Phi^c(0, y; \lambda) P_i^-(y; \lambda)^{-1} \tilde{H}_i^-(y) \rangle dy \\
&= \int_{-X_{i-1}}^0 \langle \Psi(0), P^-(0) \Phi^c(0, y; 0) P^-(y)^{-1} \tilde{H}_i^-(y) \rangle dy + \mathcal{O}(|\lambda| + e^{-\alpha X_m}) \\
&= \mathcal{O}(|\lambda| + e^{-\alpha X_m})
\end{align*}
where the integral vanishes by Lemma \ref{PsiIP} since $\Phi^c(0, y; 0) P^-(y)^{-1} \tilde{H}_i^-(y) \in E^c(0)$.

\item For the term involving $\tilde{c}$, we first use Lemmas \ref{Vpmlambdalemma} and \ref{Ecconj} to get
\begin{align*}
\langle \Psi(0), P_i^+(0; \lambda) e^{-\nu(\lambda) X_i}\tilde{c}_i \rangle \mathcal{O}((|\lambda| + e^{-2 \alpha X_m})|e^{-\nu(\lambda) X_i}\tilde{c}_i|)
\end{align*}
We obtained a bound for $|e^{-\nu(\lambda) X_i}\tilde{c}_i|$ in the previous lemma. Using that here, we have
\begin{align*}
|\langle &\Psi(0), P_i^+(0; \lambda) e^{-\nu(\lambda) X_i}\tilde{c}_i \rangle| \leq C (|\lambda| + e^{-2 \alpha X_m})\Big( e^{-(\alpha - 2\eta)X_i}|c_i| \\
&+ e^{-(\alpha-\eta) X_i} (|\lambda| + e^{-\alpha X_m})(|e^{\nu(\lambda)X_{i-1}} c_{i-1}| + |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) + (e^{-\alpha X_m} + |\lambda|)^2|d|  \Big)
\end{align*}

\end{enumerate}

Putting this all together, we have the jump expressions
\begin{align*}
\xi_i = \langle \Psi(X_i), Q'(-X_i) \rangle (d_{i+1} - d_i ) + \langle \Psi(-X_{i-1}), Q'(X_{i-1}) \rangle (d_i - d_{i-1} ) \\
+ M_\Psi \lambda( e^{-\nu(\lambda)X_i}c_i + e^{\nu(\lambda)X_{i-1}}c_{i-1})
- \lambda_2 d_i M + R_i(\lambda)(c, d)
\end{align*}
where $M$ is the higher order Melnikov integral
\[
M = \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\]
and the remainder term has piecewise bound
\begin{align*}
|R(\lambda)_i&(c_i^-, d)| \leq C \Big( (|\lambda| + e^{-\alpha X_m})^2(|e^{\nu(\lambda)X_{i-1}}c_{i-1}| + |e^{-\nu(\lambda)X_i}c_i|) \\
&+ (|\lambda| + e^{-\alpha X_m})^2(e^{-(\alpha - \eta) X_{i-1}} |e^{\nu(\lambda)X_{i-2}}c_{i-2}| + e^{-(\alpha - \eta) X_i} |e^{-\nu(\lambda)X_{i+1}}c_{i+1}|) \\
&+ (|\lambda| + e^{-\alpha X_m})^3 |d| \Big)
\end{align*}

As in Lemma \ref{jumpcenteradj}, we will write these jump expressions in matrix form. The terms involving the $c$ terms work out similarly to those in Lemma \ref{jumpcenteradj}. They are given by
\[
(\lambda M_\Psi \tilde{K}(\lambda) + C_2 K(\lambda) + K_2(\lambda))c
\]
$K(\lambda)$ is the same matrix as in Lemma \ref{jumpcenteradj}. $\tilde{K}(\lambda)$ is the same matrix as $K(\lambda)$, except all terms are positive.
\begin{align*}
\tilde{K}(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} & & & & & e^{\nu(\lambda)X_0} \\
e^{\nu(\lambda)X_1} & e^{-\nu(\lambda)X_2} \\
& e^{\nu(\lambda)X_2} & e^{-\nu(\lambda)X_3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & e^{\nu(\lambda)X_{n-1}} & e^{-\nu(\lambda)X_0} 
\end{pmatrix}
\end{align*}
$K_2(\lambda)$ is the ``$\tilde{\gamma}-$perturbation'' of $K(\lambda)$ given by
\begin{align*}
K_2(\lambda) =  
\begin{pmatrix}
e^{-\nu(\lambda)X_1} \tilde{\gamma}_{1,1} & & & & & e^{\nu(\lambda)X_0}\tilde{\gamma}_{1,0} \\
e^{\nu(\lambda)X_1}\tilde{\gamma}_{2,1} & e^{-\nu(\lambda)X_2}\tilde{\gamma}_{2,2} \\
& e^{\nu(\lambda)X_2}\tilde{\gamma}_{3,2} & e^{-\nu(\lambda)X_3}\tilde{\gamma}_{3,3} \\
\vdots & & \vdots & &&  \vdots \\
& & & & e^{\nu(\lambda)X_{n-1}}\tilde{\gamma}_{0,n-1} & e^{-\nu(\lambda)X_0}\tilde{\gamma}_{0,0} 
\end{pmatrix}
\end{align*}
where 
\begin{align*}
\tilde{\gamma}_{i,i-1}, \tilde{\gamma}_{i,i} &= \mathcal{O}(|\lambda| + e^{-\alpha X_m})^2
\end{align*}
$C_2$ is the periodic, banded matrix
\begin{align*}
C_2 &= \begin{pmatrix}
0 & \tilde{\gamma}_{1,2} & 0 & 0 & \dots & 0 & -\tilde{\gamma}_{n-1,0} & 0 \\
0 & 0 & \gamma_{2,3} & 0 & \dots & 0 & 0 & -\tilde{\gamma}_{2,1} \\
-\tilde{\gamma}_{3,1} & 0 & 0 & \tilde{\gamma}_{3,4} & \dots & 0 & 0 & 0 \\
&  & & \ddots  \\
0 & 0 & 0 & 0 & \dots & 0 & 0 & \tilde{\gamma}_{n-1,0} \\
\tilde{\gamma}_{0,1} & 0 & 0 & 0 & \dots & -\tilde{\gamma}_{0, n-2} & 0 & 0 
\end{pmatrix}
\end{align*}
where
\begin{align*}
\tilde{\gamma}_{i,i-2}, \tilde{\gamma}_{i,i+1} &= \mathcal{O}(e^{-(\alpha - \eta) X_m}(|\lambda| + e^{-\alpha X_m})^2) 
\end{align*}
The matrix $C_2$ has uniform bound
\begin{align*}
C_2 &= \mathcal{O}(e^{-(\alpha - \eta) X_m}(|\lambda| + e^{-\alpha X_m})^2)
\end{align*}

For the terms involving $d$, let
\[
a_i = \langle \Psi(X_i), Q'(-X_i) \rangle 
\]
By reversibility, $Q(-x) = R Q(x)$ implies $Q'(-x) = -R Q'(x)$. From Lemma \ref{varadjsolutions}, $\Psi(x) = R \Psi(-x)$. Thus, since $R^2 = I$ and $R$ is self-adjoint, we have as in Lemma \ref{jumpcenteradj},
\begin{align*}
\langle \Psi(-X_i), Q'(X_i) \rangle &= \langle \Psi(-X_i), R^2 Q'(X_i) \rangle \\
&= -\langle R \Psi(-X_i), Q'(-X_i) \rangle \\
&= -\langle \Psi(X_i), Q'(-X_i) \rangle \\
&= -a_i
\end{align*}
Thus the terms involving $d$ are given in matrix form by
\[
(A - \lambda^2 M I + D_2)d
\]
The matrix $A$ is given by
\begin{align*}
A &= \begin{pmatrix}
-a_0 -a_1 & a_0 + a_1 \\
-a_0 + a_1 & -a_0 - a_1
\end{pmatrix} && n = 2 \\
A &= \begin{pmatrix}
-a_{n-1} - a_0 & a_0 & & & \dots & a_{n-1}\\
a_0 & -a_0 - a_1 &  a_1 \\
& a_1 & -a_1 - a_2 &  a_2 \\
& & \vdots & & \vdots \\
a_{n-1} & & & & a_{n-2} & -a_{n-2} - a_{n-1} \\
\end{pmatrix} && n > 2
\end{align*}
$M$ is the higher order Melnikov integral
\[
M = \int_{-\infty}^\infty \langle \Psi(y), H(y) \rangle dy
\]
The remainder terms involving $D$ are collected into the matrix $D_2$, which has uniform bound
\begin{align*}
D_2 &= \mathcal{O}((|\lambda| + e^{-\alpha X_m})^3)
\end{align*}
\end{proof}
\end{lemma}

\subsection{Proof of Theorem \ref{blockmatrixtheorem}}

Theorem \ref{blockmatrixtheorem} combines the jump matrix formulas from Lemma \ref{jumpcenteradj} and Lemma \ref{jumpadj} into a single block matrix. 

\section{Proof of eigenvalue location theorems}

In Theorem \ref{locateeigtheorem}, we solve the block matrix equation from Theorem \ref{blockmatrixtheorem} to locate the PDE eigenvalues $\lambda$ for $|\lambda| < \delta$, where $\delta$ is given in Theorem \ref{blockmatrixtheorem}. We prove the theorem below in a series of lemmas. 

\subsection{Rescaling}

First, we adopt the same scaling and parameterization as in the existence problem. Recall from Theorem \ref{perexist} that a periodic $n-$pulse $Q_np(x)$ is specified by a scaling parameter $r \in \mathcal{R}$ and $n$ length parameters $b_j$, which depend on $r$ as well as a phase parameter $\theta$ and a baseline length parameter $b_j^0$.

In the next lemma, we rewrite the terms in the block matrix equation \eqref{blockeq} from Theorem \ref{blockmatrixtheorem} using this parameterization.

% block matrix reparameterization
\begin{lemma}\label{reparam}
Using the scaling and parameterization above, the block matrix equation from Theorem \ref{blockmatrixtheorem} takes the form
\begin{equation}\label{blockeq2}
\begin{pmatrix}
K(\lambda) + C_1 K(\lambda) + K_1(\lambda) & D_1 \\
C_2 K(\lambda) + K_2(\lambda) & r \tilde{A} - \lambda^2 MI + D_2
\end{pmatrix}
\begin{pmatrix}c \\ d \end{pmatrix} 
= 0
\end{equation}
$\tilde{A}$ has the same form as the matrix $A$ from Theorem \ref{blockmatrixtheorem}, except the entries $a_j$ replaced by $\tilde{a}_j$, where
\begin{align}\label{tildea}
\tilde{a}_j 
&= (-1)^{-\rho \log r / \pi} s_0 e^{\alpha \phi/\beta} \left( \beta b_j \cos\left( -\rho \log b_j \right) - \alpha b_j \sin \left( -\rho \log b_j  \right) \right) + \mathcal{O}(r^{\gamma/2\alpha})
\end{align}
The eigenvalues of $A$ are given by $\{0, \tilde{\mu_1}, \dots, \tilde{\mu}_{n-1} \}$, where $r \tilde{\mu}_j = \mu_j$ and $\mu_j$ is an eigenvalue of $A$.

The remainder terms have bounds
\begin{align*}
C_1 &= \mathcal{O}\left(r^{\tilde{\gamma}/2}(|\lambda| + r^{1/2})\right) \\
D_1 &= \mathcal{O}\left((|\lambda| + r^{1/2})^2\right) \\
C_2 &= \mathcal{O}\left(r^{\tilde{\gamma}/2}(|\lambda| + r^{1/2})^2\right) \\
D_2 &= \mathcal{O}\left((|\lambda| + r^{1/2})^3\right)
\end{align*}
where $0 < \tilde{\gamma} < 1$. The matrices $K_1(\lambda)$ and $K_2(\lambda)$ are perturbations of the nonzero entries of $K(\lambda)$ by $\mathcal{O}(|\lambda| + r^{1/2})$.

Finally the domain half-length $X$ is given by
\begin{align}\label{Xscaled}
X &= \frac{1}{2\alpha} (n |\log r| + |\log (b_0\cdots b_{n-1})| ) - \frac{n \phi}{2 \beta}
\end{align}

\begin{proof}
From the discussion following Lemma \ref{IPform}, 
\begin{align*}
r &= e^{-\alpha(2 X^* + \phi/\beta)} \\
b_j &= e^{-2 \alpha(X_j - X^*)} && j = 0, \dots, n-1
\end{align*}
where $X^* \leq X_m$. In terms of $b_j$ and $r$,
\begin{align*}
X^* &= -\frac{1}{2\alpha}\log r - \alpha \frac{\phi}{\beta} \\
X_j &= -\frac{1}{2\alpha}\log(b_j r) - \frac{\phi}{2 \beta} 
\end{align*}
In particular,
\begin{align*}
e^{-2 \alpha X_m} &\leq e^{-2 \alpha X^*} \leq C r \\
e^{-2 \alpha X_j} &= e^{\phi \alpha/\beta} _j r \\
\end{align*}

First, we rewrite the matrix $A$ using this scaling. From Lemma 6.1 in \cite{Sandstede1998},
\begin{align*}\label{IPpsiQprime}
\langle \Psi(-x), Q'(x) \rangle
&= s_0 e^{-2 \alpha x}\left( \beta \cos(2 \beta x + \phi) - \alpha \sin(2 \beta x + \phi)\right) + \mathcal{O}(e^{-(2 \alpha + \gamma) x}
\end{align*}
where $s_0 > 0$ and $\gamma$ are the same as in Lemma \ref{IPform}. Thus for the coefficients $a_j$ of $A$, we have
\begin{align*}
a_j &= \langle \Psi(-X_j), Q'(X_j) \rangle \\
&= s_0 e^{-2 \alpha X_j}\left( \beta \cos(2 \beta X_j + \phi) - \alpha \sin(2 \beta X_j + \phi)\right) + \mathcal{O}(e^{-(2 \alpha + \gamma) X_j}) \\
&= s_0 e^{\alpha \phi/\beta} r b_j \left( \beta \cos\left( -\frac{\beta}{\alpha} \log(b_j r) \right) - \alpha \sin \left( -\frac{\beta}{\alpha} \log(b_j r) \right) \right) + \mathcal{O}(r^{1+\gamma/2\alpha} b_j^{1 + \gamma/2\alpha}) \\
&= s_0 e^{\alpha \phi/\beta} r b_j \left( \beta \cos\left( -\rho \log(b_j r) \right) - \alpha \sin \left( -\rho \log(b_j r) \right) \right) + \mathcal{O}(r^{1+\gamma/2\alpha})
\end{align*}
since $b_j \in (0, 1]$. Since $r \in \mathcal{R}$, $r = \exp\left(-\frac{m \pi}{\rho}\right)$ for some nonnegative integer $m$, this becomes 
\begin{align*}
a_j &= s_0 e^{\alpha \phi/\beta} r b_j \left( \beta \cos\left( m \pi -\rho \log b_j \right) - \alpha \sin \left( m \pi -\rho \log b_j \right) \right) + \mathcal{O}(r^{1+\gamma/2\alpha}) \\
&= (-1)^m s_0 e^{\alpha \phi/\beta} r b_j \left( \beta \cos\left(-\rho \log b_j \right) - \alpha \sin \left(-\rho \log b_j \right) \right) + \mathcal{O}(r^{1+\gamma/2\alpha})
\end{align*}
To scale $r$ out of this, let $a_j = r \tilde{a}_j$, where
\begin{align*}
\tilde{a}_j 
&= (-1)^m s_0 e^{\alpha \phi/\beta} \left( \beta b_j \cos\left( -\rho \log b_j \right) - \alpha b_j \sin \left( -\rho \log b_j  \right) \right) + \mathcal{O}(r^{\gamma/2\alpha})
\end{align*}
Finally, we solve for $m$ in terms of $r$ to get $(-1)^{-\rho \log r / \pi}$. Substituting this in, we obtain
\begin{align*}
\tilde{a}_j 
&= (-1)^{-\rho \log r / \pi} s_0 e^{\alpha \phi/\beta} \left( \beta b_j \cos\left( -\rho \log b_j \right) - \alpha b_j \sin \left( -\rho \log b_j  \right) \right) + \mathcal{O}(r^{\gamma/2\alpha})
\end{align*}
Thus we have $A = r \tilde{A}$, where $\tilde{A}$ is the same matrix as $A$ with $a_j$ replaced with $\tilde{a}_j$. The matrices $\tilde{A}$ and $A$ are both symmetric, thus the eigenvalues of $\tilde{A}$ are real, and $(1,1,\dots,1)^T$ is an eigenvector of $\tilde{A}$ with eigenvalue 0. Furthermore, $\tilde{\mu}$ is an eigenvalue of $\tilde{A}$ if and only if $\mu = r \tilde{\mu}$ is an eigenvalue of $A$.

Since
\begin{align*}
e^{-\alpha X_m} &= C r^{1/2} \\
e^{-(\alpha - \eta) X_m} &= C r^{\tilde{\gamma}/2}
\end{align*}
where $0 < \tilde{\gamma} < 1$, the remainder terms in Theorem \ref{blockmatrixtheorem} have the bounds given above. In addition, $K_1(\lambda)$ and $K_2(\lambda)$ are perturbations of the nonzero entries of $K(\lambda)$ by $\mathcal{O}(|\lambda| + r^{1/2})$.

Finally, the domain half-length $X$ is given by
\begin{align*}
X &= \sum_{j=0}^{n-1} X_j \\
&= -\sum_{j=0}^{n-1} \frac{1}{2\alpha}\log(b_j r) - \frac{n \phi}{2 \beta}\\
&= -\frac{1}{2\alpha} \log\left( r^n \prod_{j=0}^{n-1} b_j \right) - \frac{n \phi}{2 \beta} \\
&= \frac{1}{2\alpha} (n |\log r| + |\log (b_0\cdots b_{n-1})| ) - \frac{n \phi}{2 \beta}
\end{align*}
\end{proof}
\end{lemma}

\subsection{Characterization of \texorpdfstring{$K(\lambda)$}{K} }

We will first find the interaction eigenvalues, which we expect to occur near where $A - \lambda^2 M I$ is singular. In order to do this, we will need to invert $K(\lambda)$ away from the points where $K(\lambda)$ is singular.

In this section, we characterize the matrix $K(\lambda)$. First, we prove the following general result about the determinant of a periodic, bi-diagonal matrix.

% bidiagonal determinant
\begin{lemma}\label{bidiag}
Let $A$ be the periodic bi-diagonal matrix
\begin{equation}
A = \begin{pmatrix}
a_1 & & & & & & b_n \\
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & \vdots & &&  \vdots \\
& & & & b_{n-2} & a_{n-1} \\
& & & & & b_{n-1} & a_n
\end{pmatrix}
\end{equation}
Then 
\begin{equation}
\det{A} = \prod_{k = 1}^n a_k + (-1)^n \prod_{k = 1}^{n-1} b_k
\end{equation}

\begin{proof}
Expanding by minors using the last column, we have
\begin{align*}
\det A &= a_n \det
\begin{pmatrix}
a_1 \\
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & & \vdots \\
& & & & b_{n-2} & a_{n-1}
\end{pmatrix}
+ (-1)^{n-1} \det
\begin{pmatrix}
b_1 & a_2 \\
& b_2 & a_3 \\
\vdots & & & & \vdots \\
& & & & & b_{n-2} & a_{n-1} \\
& & & & & & b_{n-1}
\end{pmatrix} \\
&= \prod_{k = 1}^n a_k + (-1)^{n-1} \prod_{k = 1}^n b_k
\end{align*}
since both of the matrices on the RHS are triangular.
\end{proof}
\end{lemma}

As a corollary, we can compute the determinant of $K(\lambda)$.
% determinant of K(\lambda)
\begin{corollary}\label{detKcorr}
For the matrix $K(\lambda)$ defined in Theorem \ref{blockmatrixtheorem}, we have 
\begin{equation}\label{detK}
\det K = e^{-\nu(\lambda)X} - e^{\nu(\lambda)X} = -2 \sinh (\nu(\lambda) X)
\end{equation}
where $X = X_0 + X_1 + \dots + X_{n-1}$ is half the length of the periodic domain. $\det K(\lambda) = 0$ if and only if $\nu(\lambda) = i n \pi/X$ for $n \in Z$. 
\begin{proof}
Since $K(\lambda)$ is a periodic, bi-diagonal matrix, by Lemma \ref{bidiag} we have
\begin{align*}
\det K(\lambda) &= \prod_{k = 0}^{n-1} e^{-\nu(\lambda)X_k} + (-1)^{n-1} \prod_{k = 1}^n (-e^{\nu(\lambda)X_k}) \\
&= e^{-\nu(\lambda)(X_0 + X_1 + \dots X_{n-1})} + (-1)^{n-1} (-1)^n e^{\nu(\lambda)(X_0 + X_1 + \dots X_{n-1})} \\
&= e^{-\nu(\lambda)X} - e^{\nu(\lambda)X} \\
&= -2 \sinh (\nu(\lambda)X)
\end{align*}
It follows that $\det K(\lambda) = 0$ if and only if $\nu(\lambda) = i n \pi/X$ for $n \in Z$.
\end{proof}
\end{corollary}

Corollary \ref{detKcorr} tells us that that $K(\lambda)$ is singular if and only if $\nu(\lambda) = i n \pi/X$ for $n \in Z$. In the next lemma, we determine values of $\lambda$ for which $K(\lambda)$ is singular. 

% lambda for which K(lambda) is singular
\begin{lemma}\label{Ksingularlemma}
For sufficiently small $n/X$, $K(\lambda)$ is singular at $\lambda = \pm \lambda^K(X,n)$, where
\begin{equation}\label{lambdaK}
\lambda^K(X,n)
= c \frac{n \pi i }{X} + \mathcal{O}\left( \frac{n}{X} \right)^3
\end{equation} 
$\lambda^K(X,n)$ is purely imaginary, $\lambda^K(X, 0) = 0$, and $\lambda^K(X, -n) = -\lambda^K(X, n)$.
\begin{proof}
To find the values of $\lambda$ where $K(\lambda)$ is singular, we need to solve $\nu(\lambda) = n \pi i/X$ for sufficiently small $n \in \Z$. We know $\nu(0) = 0$, so we only need to do this for nonzero $n$.

Let $G(\lambda, r) = \nu(\lambda) - r$. Then $G(0, 0) = 0$ and $D_\lambda G(0, 0) = \nu'(0) = 1/c$, which is nonzero by Hypothesis \ref{c0nonzero}. Using the IFT, we can solve for $\lambda$ in terms of $r$ for $r$ near 0. In other words, there exists a function $\lambda(r)$ such that $\lambda(0) = 0$ and $G(\lambda(r), r) = 0$ for sufficiently small $r$. Thus, for sufficiently small $r$, $\nu(\lambda(r)) = r$. By Lemma \ref{nulambdalemma}, $\nu(-\lambda(r)) = -\nu(\lambda(r)) = -r$, thus by uniqueness of the IFT solution, $\lambda(-r) = -\lambda(r)$, i.e. $\lambda(r)$ is an odd function. We also have from the IFT 

\begin{align*}
\lambda'(r) &= -\frac{1}{\partial_\lambda G(\lambda(r), r) } \partial_r G(\lambda(r), r) \\
&= \frac{1}{\partial_\lambda \nu(\lambda) } 
\end{align*}
which, at $\lambda = 0$, is $\lambda'(r) = c$. Expanding $\lambda(r)$ in a Taylor series about $r = 0$ and using the fact that $\lambda(r)$ is an odd function, we have
\begin{align*}
\lambda(r) &= \lambda(0) + \lambda'(0) r + \mathcal{O}(|r|^2) \\
&= c r + \mathcal{O}(|r|^3)
\end{align*}

For $n/X$ sufficiently small, take $r = n \pi i / X$. Let 
\[
\lambda^K(X, n) = \lambda\left( \frac{n \pi i}{X} \right)
\]
Then $\nu(\lambda^K(X, n)) = n \pi i / X$, which implies $\det K(\lambda^K(X, n)) = 0$. We have the expansion
\begin{align*}
\lambda^K(X,n)
&= c \frac{n \pi i }{X} + \mathcal{O}(n/X)^3 \\
\end{align*} 

Since $\lambda(r)$ is an odd function, $\lambda^K(X,-n) = -\lambda^K(X,n)$. Finally, since for $\lambda$ pure imaginary, $\nu(\lambda)$ is also pure imaginary, $\lambda(X,n)$ is pure imaginary.
\end{proof}
\end{lemma}

Before we continue, we note the following estimate for the norm of $K(\lambda)$.
\begin{equation}\label{Klambdanorm}
||K(\lambda)|| \leq n ||K(\lambda)||_{\text{max}} = C e^{|\text{Re }\nu(\lambda)|X_{n-1}}
\end{equation}

In the next lemma, we derive an expression for the inverse of $K(\lambda)$ (when it is nonsingular).

% lemma : inverse of K(lambda)
\begin{lemma}\label{Kinvlemma}
When $\det K(\lambda) \neq 0$,
\begin{equation}\label{Klambdainv}
K(\lambda)^{-1} = \frac{1}{\det K(\lambda)} \tilde{K}(\lambda)
\end{equation}
where
\begin{align}\label{tildeK}
\tilde{K}&(\lambda) = \\
&\begin{pmatrix}
e^{-\nu(\lambda)(X_2+\dots+X_{n-1}+X_0)} & e^{-\nu(\lambda)(-X_2-\dots-X_{n-1}-X_0)} &
e^{-\nu(\lambda)(X_2-\dots-X_{n-1}-X_0)} & \dots & e^{-\nu(\lambda)(X_2+\dots+X_{n-1}-X_0)}  \\ 
e^{-\nu(\lambda)(X_3+\dots+X_0-X_1)} & e^{-\nu(\lambda)(X_3+\dots+X_0+X_1)} &
e^{-\nu(\lambda)(-X_3-\dots-X_0-X_1)} & \dots & e^{-\nu(\lambda)(X_3+\dots-X_0-X_1)} \\ 
& \ddots & \ddots \\
e^{-\nu(\lambda)(-X_1-X_2 -\dots-X_{n-1})} & e^{-\nu(\lambda)(X_1-X_2 -\dots-X_{n-1})} &
e^{-\nu(\lambda)(X_1+X_2 -\dots-X_{n-1})} & \dots & e^{-\nu(\lambda)(X_1+X_2+\dots+X_{n-1})}  \nonumber 
\end{pmatrix}
\end{align}
and we have the bound
\begin{equation}\label{Klambdainvnorm}
||K(\lambda)^{-1}|| \leq C \frac{e^{|\text{Re }\nu(\lambda)|X }}{| \det K(\lambda) |}
\end{equation}

\begin{proof}
This can be verified directly. Note that each row is essentially a cyclic permutation of the previous row. Everything is shifted one place to the right, but a different index omitted in each row; row $k$ omits index $k$ (which is taken $\mod n$, so row $n$ omits the index 0). For row $j$, we can verify by matrix multiplication that
\begin{align*}
[K(\lambda)\tilde{K}(\lambda)]_{jj} &= e^{-\nu(\lambda)(X_0 + \dots + X_{n-1})} - e^{\nu(\lambda)(X_0 + \dots + X_{n-1})} = \det K(\lambda) \\
[K(\lambda)\tilde{K}(\lambda)]_{jk} &= 0 && j \neq k
\end{align*}
where $\det(K(\lambda))$ is given in Corollary \ref{detKcorr}. The same holds for the product $\tilde{K}(\lambda)K(\lambda)$.
\end{proof}
\end{lemma}

Before we continue, we recall that we need to make sure the roots of $\det A - \lambda^2 M I$ and $\det K(\lambda)$ do not get too close. To ensure that, we will from now on assume that the $\epsilon-$ball condition holds, which is given in Definition \ref{epsilonballs}. Note that the factor of $1/4$ in the $\epsilon-$ball condition ensures that the $\epsilon-$balls do not overlap. Lemma \ref{epsilonballlemma} which guarantees that the $\epsilon-$ball condition is always satisfied for sufficiently small $r$. We prove that lemma in the next section

\subsection{Proof of Lemma \ref{epsilonballlemma}}

The nonzero roots of $\det A - \lambda^2 M I$ are of the form $\pm r^{1/2} \sqrt{\tilde{\mu}_j/M}$, where $\tilde{\mu}_j$ is one of the nonzero eigenvalues of $\tilde{A}$. These roots come in pairs which are symmetric about the origin. Although we only have to consider the case when these roots are purely imaginary, we do not know in advance which ones these will be, so we consider the worst case scenario where all the roots are purely imaginary. Let $a = \max_j\{| \sqrt{\tilde{\mu}_j/M}|\}$. We will show that for sufficiently small $r$, 
\[
|\lambda^K(X,1)| - a r^{1/2} > \frac{\epsilon}{X}
\]
Since $X > 0$, this is equivalent to
\[
(|\lambda^K(X,1)| - a r^{1/2})X  > \epsilon
\]
This implies that any purely imaginary interaction eigenvalues will be located between 0 and $\pm \lambda^K(X,1)$. Recall from Lemma \ref{Ksingularlemma} that
\[
\lambda^K(X,1)
= c \frac{\pi i }{X} + \mathcal{O}(1/X)^3 
\]
Thus we have
\begin{align*}
(|\lambda^K(X,1)| - a r^{1/2})X &= \left( |c| \frac{\pi}{X} + \mathcal{O}(1/X)^3 - a r^{1/2} \right)X \\
&= |c| \pi + \mathcal{O}(1/X)^2 - a r^{1/2} X \\
&= |c| \pi \left(1 + \mathcal{O}(1/X)^2 - \tilde{a} r^{1/2} X\right)
\end{align*}
where $\tilde{a} = a / |c| \pi$. From Lemma \ref{reparam}, $X$ is given in terms of $r$ and $b_j$ by
\[
\frac{1}{2\alpha} (n |\log r| + |\log (b_0 \cdots b_{n-1})| ) + \tilde{C}
\]
Substituting this in, we have
\begin{align*}
(|&\lambda^K(X,1)| - a r^{1/2})X \\
&= C \left(1 - \tilde{a} r^{1/2}(n |\log r| + |\log (b_0 \cdots b_{n-1})| + \tilde{C}) + \mathcal{O}\left( \frac{1}{n |\log r| + |\log (b_0 \cdots b_{n-1})| + \tilde{C}} \right) \right)
\end{align*}
where $C$ is a positive constant. As $r \rightarrow 0$, $b_j \rightarrow b_j^0$, which are constants. Thus as $r \rightarrow 0$, the quantity in parentheses on the RHS approaches 1. 

Thus there exists $r(b^0) > 0$ such that for $r \in \mathcal{R}$ with $r \leq r(b^0)$, $(|\lambda^K(X,1)| - a r^{1/2})X > r^{1/4}$. Since $\epsilon = r^{1/4}/X$, the result follows upon multiplication by $X$.

\subsection{Bounds on \texorpdfstring{$K(\lambda)^{-1}$}{inverse of K} }

In this section, we obtain a bound for $K(\lambda)^{-1}$. This bound hold as long as we are sufficiently far from the points where $K(\lambda)$ is singular, which we guarantee by taking the $\epsilon-$ball condition. First, we obtain lower bounds for $\det K(\lambda)$. 

% bounds for Det K
\begin{lemma}\label{detKlemma}
We have the following lower bounds for $\det K(\lambda)$.
\begin{enumerate}[(i)]
\item If $|\text{Re }\nu(\lambda)| \geq 1/X$, 
\begin{equation}\label{detKbound1}
|\det K(\lambda)| \geq \sqrt{2} e^{|\text{Re }\nu(\lambda)X|}
\end{equation}
\item If the $\epsilon-$ball condition holds and $|\lambda| \geq C r^{1/2}$,
\begin{equation}\label{detKbound2}
|\det K(\lambda)|\geq C \min\{ X r^{1/2}, r^{1/4} \}
\end{equation}
\end{enumerate}

\begin{proof}
First, we take the case (i) where $|\text{Re }\nu(\lambda)| \geq 1/X$. For convenience, let $\nu(\lambda)X = a + bi$, so $|a| \geq 1$. Expanding $|\sinh(a + b i)|^2$ gives us
\begin{align*}
|\sinh(a + b i)|^2 
&= |\sinh a \cosh b i + \cosh a \sin b i|^2 \\
&= |\sinh a \cos b + i \cosh a \sin b |^2 \\
&= \sinh^2 a \cos^2 b + \cosh^2 a \sin^2 b \\
&= \sinh^2 a \cos^2 b + \sinh^2 a \sin^2 b 
+ \cosh^2 a \sin^2 b - \sinh^2 a \sin^2 b \\
&= \sinh^2 a (\cos^2 b + \sin^2 b) 
+ \sin^2 b( \cosh^2 a - \sinh^2 a) \\
&= \sinh^2 a + \sin^2 b
\end{align*}
In this case,
\begin{align*}
|\sinh(\nu(\lambda) X)|^2 &= |\sinh(a + b i)|^2 \\
&\geq \sinh^2 a \\
&= \frac{1}{4}\left( e^{2a} + e^{-2a} - 2 \right) \\
&\geq \frac{1}{4}\left( e^{2|a|} - 2 \right)
\end{align*}
For $|a| \geq 1$, we have
\begin{align*}
e^{2|a|} - 2 - \frac{e^{2|a|}}{2} 
&= \frac{e^{2|a|}}{2} - 2 \\
&= \frac{e^2}{2} - 2 > 0
\end{align*}
Thus $e^{2|a|} - 2 \geq \frac{e^{2|a|}}{2}$ and we conclude
\begin{align*}
|\sinh(\nu(\lambda) X)|^2 \geq \frac{e^{2|a|}}{2} \\
|\sinh(\nu(\lambda) X)| \geq \frac{e^{|a|}}{\sqrt{2}}
\end{align*}
from which it follows that if $|\text{Re } \nu(\lambda)| \geq 1/X$,
\begin{align*}
|\det K(\lambda)| &= 2 |\sinh(\nu(\lambda) X)|
\geq \sqrt{2} e^{|\text{Re }\nu(\lambda)X|}
\end{align*}

Next, we consider the case (ii). Assume the $\epsilon-$ball condition holds. There are two cases to consider. First, suppose $|\lambda| \leq \lambda^K(X,1)/2$. Since $\epsilon \leq 1/4X$, the $\epsilon$ criterion is automatically satisfied. Expanding $\sinh( \nu(\lambda) X)$ in a Taylor series about $\lambda = 0$, and recalling that $\nu(0) = 0$, we get
\begin{align*}
\sinh(\nu(\lambda + \xi) X) &= \frac{1}{c}X\xi + \mathcal{O}((X \xi)^3)
\end{align*}
Since $|\lambda| \geq C r^{1/2}$, we have $C_1 r^{1/2} < \xi < |c| \pi C_2/X$, thus for this case,
\begin{align*}
|\det K(\lambda)| &= 2 |\sinh(\nu(\lambda) X)| \\
& \geq C r^{1/2}X
\end{align*}

For the second case suppose $|\lambda| \geq \lambda^K(X,1)/2$. Since the points $\lambda^K(X,k)$ are spaced apart on the imaginary axis by approximtely $k \pi/X$, and $\epsilon \leq 1/4X$, there is enough room between the points for us to work. We want this bound to hold for when $|\text{Re } \nu(\lambda)| < 1/X$. 

Once again, let $\nu(\lambda) X = a + b i$. Then, using the same expansion for $|\sinh(a + b i)|^2$ as above, we have
\begin{align*}
|\sinh(\nu(\lambda) X)|^2 
&= \sinh^2 a + \sin^2 b \\
&\geq \sin^2 b \\
&= \sin^2 (\text{Im }\nu(\lambda)X)
\end{align*}
from which it follows that
\begin{align*}
|\det K(\lambda)| = 2 |\sinh(\nu(\lambda) X)| \geq 2|\sin(\text{Im }\nu(\lambda)X)|
\end{align*}

For $k/X$ suffienctly small, $\lambda^K(X, k)$ is defined by Lemma \ref{Ksingularlemma}. Since $\nu(\lambda)$ is smooth in $\lambda$, from Lemma \ref{nulambdalemma} we have the Taylor series expansion for $\nu'(\lambda)$
\[
\nu'(\lambda) = \frac{1}{c} + \mathcal{O}(|\lambda|^2)
\]
Expand $\nu(\lambda)$ in a Taylor series about $\lambda^K(X, k)$ to get
\begin{align*}
\nu\left( \lambda^K(X, k) + \xi \right) &= \nu( \lambda(X, k) ) + \nu'(\lambda(X, k)\xi
+ \mathcal{O}(\xi^2) \\
&= \frac{k \pi i}{X} + \left( \frac{1}{c} + \mathcal{O}(|\lambda(X, k)|^2) \right) \xi
+ \mathcal{O}(\xi^2) \\
&= \frac{k \pi i}{X} \frac{1}{c}\xi \left( 1 + \mathcal{O} \left(\frac{k}{X}\right)^2 \right) + \mathcal{O}(\xi^2)
\end{align*}
Since the $\epsilon-$ball condition holds,
\[
\text{Im } \xi \geq \epsilon = \frac{r^{1/4}}{X}
\]
Thus as long as $\xi$ is not so large that we are closer to a different $\lambda^K(X, k)$,
\begin{align*}
|\text{Im } \nu\left( \lambda^K(X, k) + \xi \right)X - k \pi| \geq C r^{1/4}
\end{align*}
from which it follows that
\[
|\det K(\lambda)| \geq C \min\{ X r^{1/2}, r^{1/4} \}
\]
\end{proof}
\end{lemma}

In the final lemma of this section, we obtain bounds on $K(\lambda)^{-1}$ as well as the products $K_1(\lambda)K(\lambda)^{-1}$ and $K_2(\lambda)K(\lambda)^{-1}$. Note that the lemma requires us to take $|\lambda| \geq C r^{1/2}$. This will not turn out to be a problem, since we will use this lemma to locate a finite number of interaction eigenvalues, all of which are of order $\mathcal{O}(r^{1/2})$.

% lemma : bounds on K
\begin{lemma}\label{Kinvboundslemma}
Choose $\lambda \in \C$ such that $|\lambda| \geq C r^{1/2}$ and the $\epsilon-$ball condition holds. Then we have the following bounds.
\begin{enumerate}[(i)]
\item 
\begin{equation}\label{Kinvbound}
||K(\lambda)^{-1}|| \leq C \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\} \\
\end{equation}
\item 
\begin{align}
||K_1(\lambda)K(\lambda)^{-1}|| &\leq C (|\lambda| + r^{1/2}) \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\} \label{K1Kinvbound} \\
||K_2(\lambda)K(\lambda)^{-1}|| &\leq C (|\lambda| + r^{1/2}) \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\} \label{K2Kinvbound}
\end{align}
\end{enumerate}

\begin{proof}
For the bound on $|K(\lambda)^{-1}|$, if $\text{Re }\nu(\lambda)|X \geq 1/X$, we have from Lemma \ref{detKlemma}
\begin{align*}
||K(\lambda)^{-1}|| &\leq C \frac{e^{|\text{Re }\nu(\lambda)|X }}{| \det K(\lambda) |} \leq C \frac{e^{|\text{Re }\nu(\lambda)|X }}{e^{|\text{Re }\nu(\lambda)X|}} = C 
\end{align*}

If $\text{Re }\nu(\lambda)|X \leq 1/X$, then we have from Lemma \ref{detKlemma}
\begin{align*}
||K(\lambda)^{-1}|| &\leq C \frac{e^{|\text{Re }\nu(\lambda)|X }}{| \det K(\lambda) |} \\
& \leq C \frac{1}{\min \{ r^{1/4}, X r^{1/2} \}} \\
& \leq C \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\}
\end{align*}
This gives us the overall bound
\begin{align*}
||K(\lambda)^{-1}|| &\leq C \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\}
\end{align*}

For $K_1(\lambda)K(\lambda)^{-1}$, using the equation for $K(\lambda)^{-1}$ from Lemma \ref{Kinvlemma} and the form of $K_1(\lambda)$ from the proof of Lemma \ref{jumpcenteradj},
\begin{align*}
||K_1(\lambda)K(\lambda)^{-1}|| &\leq 
C \frac{e^{|\text{Re }\nu(\lambda)|X}}{|\det K(\lambda)|} \max {|\gamma|_{ij}} \\
&\leq C \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\} \max {|\gamma|_{ij}}
\end{align*}
where we used the bounds we obtained from the first part of this lemma for the two cases where $\text{Re }\nu(\lambda)|X \geq 1/X$ and $\text{Re }\nu(\lambda)|X \leq 1/X$. The constants $\gamma_{ij}$ are the coefficients of $K_1(\lambda)$ from the proof of Lemma \ref{jumpcenteradj}. Since $\gamma_{ij} = \mathcal{O}(|\lambda| + r^{\tilde{\gamma}/2})$, we conclude
\begin{align*}
||K_1(\lambda)K(\lambda)^{-1}|| &\leq C (|\lambda| + r^{\tilde{\gamma}/2}) \max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\}
\end{align*}
Since $K_2(\lambda)$ is a similar perturbation of $K(\lambda)$, we have a similar bound for $||K_2(\lambda)K(\lambda)^{-1}||$.
\end{proof}
\end{lemma}

\subsection{Interaction Eigenvalues}

In this section, we find the interaction eigenvalues, which come from the second line of the block matrix equation from Theorem \ref{blockmatrixtheorem}. To do this, we solve the first line of the block matrix equation \eqref{blockeq} for $c$ and plug it into the second line of the block matrix. We expect the interaction eigenvalues to be close to the points where $A - \lambda^2 M I$ is singular. From Lemma \ref{reparam}, $A = r \tilde{A}$, thus it makes sense to take the scaling
\[
\lambda = r^{1/2}\tilde{\lambda}
\]

In the following lemma, we derive an equation we can solve to find the interaction eigenvalues.

% equation for d
\begin{lemma}\label{deqlemma}
For sufficiently small $r$, the interaction eigenvalues are given by $\lambda = r^{1/2} \tilde{\lambda}$, where the $\tilde{\lambda}$ are the values for which the equation
\begin{equation}\label{eqford}
(\tilde{A} - \tilde{\lambda}^2 MI + \tilde{D}_3)d = 0
\end{equation}
has a nontrivial solution. The remainder term $\tilde{D}_3$ has bound
\begin{equation}\label{tildeD3bound}
||\tilde{D}_3|| \leq C r^{1/2}
\end{equation}

\begin{proof}
First, we solve the top line of the block matrix equation \eqref{blockeq} for $c$. For $\lambda \neq \lambda^K(X, n)$, $K(\lambda)$ is invertible, and we can write the top line of \eqref{blockeq} as
\begin{align*}
(I + C_1 + K_1(\lambda)K(\lambda)^{-1}) K(\lambda) c = -D_1 d
\end{align*}
Using the scaling $\lambda = \mathcal{O}(r^{1/2})$ and the bounds from Lemma \ref{Kinvboundslemma}
\begin{align*}
||K_1(\lambda)K(\lambda)^{-1}|| &\leq C (|\lambda| + r^{1/2})\max \left\{ r^{-1/4}, \frac{r^{-1/2}}{X} \right\} \\
&\leq C \max \left\{ r^{1/4}, \frac{1}{X} \right\} \\
&\leq C \max \left\{ r^{1/4}, \frac{1}{n |\log r| + |\log (b_0 \cdots b_{n-1})| ) } \right\}
\end{align*}
where we use the expression for $X$ from Lemma \ref{reparam}. Combining this with the bound for $C_1$ (which is stronger, so is subsumed by the bound on $||K_1(\lambda)K(\lambda)^{-1}||$), we have the bound
\[
||C_1 + K_1(\lambda)K(\lambda)^{-1}|| \leq C \max \left\{ r^{1/4}, \frac{1}{n |\log r| + |\log (b_0 \cdots b_{n-1})| } \right\}
\]
Since the RHS goes to 0 as $r \rightarrow 0$, $I + C_1 + K_1(\lambda)K(\lambda)^{-1}$ is invertible for sufficiently small $r$. Let $C_3 = (I + C_1 + K_1(\lambda)K(\lambda)^{-1})^{-1}$. Then we can solve for $c$ to get
\[
c = -K(\lambda)^{-1} C_3 D_1 d
\]

Plugging this into the second line of \eqref{blockeq}, we get the folowing equation for $d$.
\begin{align*}
(C_2 K(\lambda) + K_2(\lambda))c + (r\tilde{A} - r \tilde{\lambda}^2 MI + D_2)d &= 0 \\
(r\tilde{A} - r \tilde{\lambda}^2 MI + D_2)d - (C_2 K(\lambda) + K_2(\lambda))K(\lambda)^{-1} C_3 D_1 &= 0 \\
(r\tilde{A} - r \tilde{\lambda}^2 MI + D_2)d - (C_2 + K_2(\lambda)K(\lambda)^{-1}) C_3 D_1 &= 0 \\
\end{align*}
Let 
\[
D_3 = D_2 - C_2 C_3 D_1 - K_2(\lambda) K(\lambda)^{-1} C_3 D_1
\]
be the remainder term, so that the equation for $d$ becomes
\[
(r\tilde{A} - r \tilde{\lambda}^2 MI + D_3)d = 0
\]
Using bounds from Lemma \ref{reparam} and Lemma \ref{Kinvboundslemma} together with the scaling $\lambda = \mathcal{O}(r^{1/2})$, we have the following bound for $D_3$
\begin{align*}
||D_3|| &\leq C \left( (|\lambda| + r^{1/2})^3 + r^{\tilde{\gamma}/2}(|\lambda| + r^{1/2})^4 + (|\lambda| + r^{1/2})^3 \right) \\
&\leq C r^{3/2}
\end{align*}
Dividing by $r$, we get the equation 
\[
(\tilde{A} - \tilde{\lambda}^2 MI + \tilde{D}_3)d = 0
\]
where 
\[
||\tilde{D}_3|| \leq C r^{1/2}
\]
\end{proof}
\end{lemma}

Because of our scaling, the parameter $r$ only occurs in the remainder term. If we assume Hypothesis \ref{Adistincteigs}, we can solve \eqref{eqford} for the interaction eigenvalues.

% solve for int eigs
\begin{lemma}\label{inteigslemma}
Assume Hypothesis \ref{Adistincteigs}, and let $0, \tilde{\mu}_1, \dots, \tilde{\mu}_{n-1}$ be the eigenvalues of $\tilde{A}$. Then there exists $r_1 \leq r_0$ such that for $r \in \mathcal{R}$ with $r \leq r_1$, we have $2n - 2$ pairs of interaction eigenvalues
\begin{align*}
\lambda &= \pm \lambda^{\text{int}}_j(r) && j = 0, \dots, n-2
\end{align*}
where
\begin{align}\label{inteigsformula}
\lambda^{\text{int}}_j(r) = r^{1/2} \sqrt{\tilde{\mu}_j / M} + \mathcal{O}(r^{3/4})
\end{align}
These interaction eigenvalue pairs are either real or purely imaginary, and the remainder term cannot move them off of the real or imaginary axis.

\begin{proof}
Let $\{0, \mu_1, \dots, \mu_{n-1}\}$ be the eigenvalues of $A$, which we are distinct by Hypothesis \ref{Adistincteigs}. Since $A = r \tilde{A}$, the eigenvalues of $\tilde{A}$ are $\{0, \tilde{\mu}_1, \dots, \tilde{\mu}_{n-1}\}$, which are also distinct, and $\mu_j = r \tilde{\mu}_j$.\\

Equation \eqref{eqford} has a nontrivial solution if and only if
\[
\tilde{E}(\tilde{\lambda}, r) = \det
\left( \tilde{A} - \tilde{\lambda}^2 MI + \mathcal{O}(r^{1/2}) \right) = 0
\]
When $r = 0$, $\tilde{E}(\tilde{\lambda}, 0) = \det(\tilde{A} - \tilde{\lambda}^2 MI)$, which we can evaluate by taking $\mu = \tilde{\lambda}^2 M$ in the characteristic polynomial of $\tilde{A}$.
\begin{equation}\label{tildeE1}
\tilde{E}(\tilde{\lambda}, 0) = \tilde{\lambda}^2
\left( \tilde{\lambda} - \sqrt{\tilde{\mu}_1 / M} \right)
\left( \tilde{\lambda} + \sqrt{\tilde{\mu}_1 / M} \right) \dots
\left( \tilde{\lambda} - \sqrt{\tilde{\mu}_{n-1} / M} \right)
\left( \tilde{\lambda} + \sqrt{\tilde{\mu}_{n-1} / M} \right)
\end{equation}

For $j = 1, \dots, n-1$, $\tilde{E}(\pm \sqrt{\tilde{\mu}_j / M}, 0) = 0$. Since the eigenvalues of $A_0$ are distinct, $\partial_{\tilde{\lambda}} \tilde{E}(\pm \sqrt{\tilde{\mu}_j / M}, 0) \neq 0$. Thus there exists $r_1 \leq r_0$ so that for $r \leq r_1$, we can use the IFT to solve for $\tilde{\lambda}$ in terms of $r$ near the $2n-2$ roots $\pm \sqrt{\tilde{\mu}_j / M}$ of \eqref{tildeE1}. In other words, for $r \leq r_1$, there are unique smooth functions $\tilde{\lambda}_j^\pm(r)$ such that $\tilde{\lambda}_j^\pm(0) = \pm \sqrt{\tilde{\mu}_j / M}$ and $\tilde{E}(\tilde{\lambda}_j^\pm(r); r) = 0$. We also have the estimate
\[
\tilde{\lambda}_j^\pm(r) = \pm \sqrt{\tilde{\mu}_j/ M} + \mathcal{O}(r^{1/4})
\]

Undoing the scaling, let
\[
\lambda_j^\pm(r) = r^{1/2} \tilde{\lambda}_j^\pm(r)
\]
These are the interaction eigenvalues we seek. By Hamiltonian symmetry, eigenvalues must come in quartets $\pm a \pm b i$. Since  the eigenvalues $\tilde{\mu}$ of $\tilde{A}$ are distinct, the only way we can satisfy Hamiltonian symmetry is if $\lambda_j^+(r) = \lambda_j^-(r)$, in which case the eigenvalue pairs must be real or purely imaginary. Thus the interaction eigenvalues are given by $\lambda = \pm \lambda^{\text{int}}_j(r)$, where
\begin{align*}
\lambda^{\text{int}}_j(r) = r^{1/2} \sqrt{\tilde{\mu}_j / M} + \mathcal{O}(r^{3/4})
\end{align*}
By Hamiltonian symmetry, the remainder term cannot move these off of the real or imaginary axis.
\end{proof}
\end{lemma}

\subsection{Characterization of \texorpdfstring{$A - \lambda^2 MI$}{Matrix A} }

We can now find the ``essential spectrum'' eigenvalues, which we expect to occur near the points where $K(\lambda)$ is singular. In order to do this, we will need to invert $A - \lambda^2 MI$ away from the points where it is singular.

As in the previous section, we will assume that the $\epsilon-$ball condition holds. In addition, since we expect that the smallest nonzero ``essential spectrum'' eigenvalues will occur at approximately $\lambda = \pm c \pi i / X$, we will restrict ourselves to $\lambda$ with $|\lambda| \geq C/X$.

We first prove a lower bound the determinant of $(A - \lambda^2 MI)$.

% lemma : bound on det (A - \lambda^2 MI)
\begin{lemma}\label{detAboundlemma}
We have the following lower bounds for $\det(A - \lambda^2 M I)$.
\begin{enumerate}[(i)]
\item If $|\lambda| \geq C/X$ and the $\epsilon-$ball condition holds,
\begin{equation}\label{detAbound1}
|\det(A - \lambda^2 M I)|
\geq C \frac{1}{X^2} \left( \frac{r^{1/4}}{X} \right)^{n-1} \left( |\lambda|^2 + r \right)^{(n-1)/2}
\end{equation}

\item If $|\lambda| \geq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, where $\tilde{\mu}_M = \max\{\tilde{\mu}_1, \dots, \tilde{\mu}_{n-1} \}$, then
\begin{equation}\label{detAbound2}
|\det(A - \lambda^2 M I)|
\geq C |\lambda|^{n+1} \left( |\lambda|^2 + r \right)^{(n-1)/2}
\end{equation}

\end{enumerate}
\begin{proof}
$\det(A - \lambda^2 MI)$ is the characteristic polynomial $p(t)$ of $A$ with $t = \lambda^2 / M$. Since the eigenvalues of $A$ are $\{0, r \tilde{\mu}_1, \dots, r\tilde{\mu}_{n-1}\}$, the roots of $\det(A - \lambda^2 MI)$ are 
\[
\{0, \pm r^{1/2} \sqrt{\tilde{\mu}_1/M}, \dots, \pm r^{1/2} \sqrt{\tilde{\mu}_{n-1}/M}\}
\]
where the root at 0 has algebraic multiplicty 2. Thus we have
\begin{align}\label{detAlambda}
\det(A &- \lambda^2 M I) \\ 
&= C \lambda^2 (\lambda - r^{1/2} \sqrt{\tilde{\mu_1}/M} )(\lambda + r^{1/2} \sqrt{\tilde{\mu}_1/M} )
\dots(\lambda - r^{1/2} \sqrt{\tilde{\mu}_{n-1}/M})(\lambda + r^{1/2} \sqrt{\tilde{\mu}_{n-1}/M} ) \nonumber
\end{align}

For the bound (i), suppose $|\lambda| \geq C/X$ and that the $\epsilon-$ball condition holds. For the $\lambda^2$ term in \eqref{detAlambda}, we use the lower bound $|\lambda| \geq C/X$. Since the pairs $\pm \mu_j$ are symmetric across the origin, we have the lower bound for each pair
\begin{align*}
(\lambda - r^{1/2} \sqrt{\tilde{\mu}/M} )(\lambda + r^{1/2} \sqrt{\tilde{\mu}_1/M} )
&\geq \epsilon \sqrt{ |\lambda|^2 + |r^{1/2} \sqrt{\tilde{\mu}_1/M}|^2 } \\
&\geq C \frac{r^{1/4}}{X} \sqrt{ |\lambda|^2 + r } \\
\end{align*}
Combining these, we have the bound
\begin{align*}
|\det(A - \lambda^2 M I)|
&\geq C \frac{1}{X^2} \left( \frac{r^{1/4}}{X} \right)^{n-1} \left( |\lambda|^2 + r \right)^{(n-1)/2} \\
\end{align*}

For bound (ii), suppose $|\lambda| \geq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$. For the pairs $\pm \mu_j$ in \eqref{detAlambda}, we have the lower bound
\begin{align*}
(\lambda - r^{1/2} \sqrt{\tilde{\mu}/M} )(\lambda + r^{1/2} \sqrt{\tilde{\mu}_1/M} )
&\geq \frac{|\lambda|}{2} \sqrt{ |\lambda|^2 + |r^{1/2} \sqrt{\tilde{\mu}_1/M}|^2 } \\
&\geq C |\lambda| \sqrt{ |\lambda|^2 + r } \\
\end{align*}
Combining these, we have the bound
\[
|\det(A - \lambda^2 M I)|
\geq C |\lambda|^{n+1} \left( |\lambda|^2 + r \right)^{(n-1)/2}
\]
\end{proof}
\end{lemma}

In the next lemma, we derive a bound for $(A - \lambda^2 M I)^{-1}$.

% bound on (A - \lambda^2 M I)^{-1}
\begin{lemma}\label{Ainvboundlemma}
Choose $\lambda \in \C$ such that $|\lambda| \geq C/X$ and the $\epsilon-$ball condition holds. Then we have the following bounds for $(A - \lambda^2 M I)^{-1}$.
\begin{enumerate}[(i)]
\item If $|\lambda| \leq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, where $\tilde{\mu}_M = \max\{\tilde{\mu}_1, \dots, \tilde{\mu}_{n-1}\}$, then
\begin{align}\label{Ainvbound1}
||(A - \lambda^2 M I)^{-1}|| &\leq C X ^{n+1} r^{(n-1)/4}
\end{align}

\item If $|\lambda| \geq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, then
\begin{equation}\label{Ainvbound2}
||(A - \lambda^2 M I)^{-1}|| \leq \frac{C}{|\lambda|^2}
\end{equation}
\end{enumerate}
\begin{proof}
When it is nonsingular, the inverse $(A - \lambda^2 M I)^{-1}$ is given by the formula
\[
(A - \lambda^2 M I)^{-1} = \frac{1}{\det(A - \lambda^2 M I)}\text{Adj}(A - \lambda^2 M I)
\]
where $\text{Adj}(A - \lambda^2 M I)$ is the adjugate matrix (the transpose of the cofactor matrix) corresponding to $A - \lambda^2 M I$. Since $A$ is $n \times n$, each entry in $\text{Adj}(A - \lambda^2 M I)$ involves sums of products of $n-1$ of the entries of $A - \lambda^2 M I$, each of which is $\mathcal{O}(r + |\lambda|^2)$, thus $||\text{Adj}(A - \lambda^2 M I)|| = \mathcal{O}(r + |\lambda|^2)^{n-1}$.

For the bound (i), we use lower bound \eqref{detAbound1} on $\det(A - \lambda^2 M I)$ from Lemma \ref{detAboundlemma} to get
\begin{align*}
||(A - \lambda^2 M I)^{-1}|| &\leq C X^2 \left(\frac{X}{r^{1/4}}\right)^{n-1} 
\frac{\left( |\lambda|^2 + r \right)^{n-1}}{\left( |\lambda|^2 + r \right)^{(n-1)/2}} \\
&= C X^2 X^{n - 1} r^{-(n-1)/4}\left( |\lambda|^2 + r \right)^{(n-1)/2} \\
&\leq C X ^{n+1} r^{(n-1)/4}
\end{align*}
where the last inequality holds since $|\lambda| \leq C r^{1/2}$.

For the bound (ii), we have $|\lambda| \geq C r^{1/2}$, and we use the lower bound \eqref{detAbound2} on $\det(A - \lambda^2 M I)$ from Lemma \ref{detAboundlemma} to get
\begin{align*}
||(A - \lambda^2 M I)^{-1}|| &\leq C \frac{1}{|\lambda|^{n+1}} 
\frac{\left( |\lambda|^2 + r \right)^{n-1}}{\left( |\lambda|^2 + r \right)^{(n-1)/2}} \\
&= C \frac{1}{|\lambda|^{n+1}} \left( |\lambda|^2 + r \right)^{(n-1)/2} \\
&\leq C \frac{1}{|\lambda|^{n+1}} |\lambda|^{n-1} \\
&=\frac{C}{|\lambda|^2}
\end{align*}
\end{proof}
\end{lemma}

\subsection{``Essential spectrum'' eigenvalues}

To find the ``essential spectrum'' eigenvalues, we solve the second line of of the block matrix equation \eqref{blockeq} for $d$ and plug it into the first line. In the next lemma, we derive an equation we can solve to obtain the ``essential spectrum'' eigenvalues.

% lemma : equation for c
\begin{lemma}\label{ceqlemma}
Let $\lambda \in \C$ such that $|\lambda| \geq C/X$ and the $\epsilon-$ball condition holds. Then sufficiently small $r$, the ``essential spectrum'' eigenvalues are the values of $\lambda$ for which 
\begin{align}\label{eqforc}
(K(\lambda) + C_5 K_3(\lambda)c &= 0
\end{align}
has a nontrivial solution, where $K_3(\lambda)$ has the same form as $K_1(\lambda)$, and
\begin{align*}
||C_5|| &\leq C
\end{align*}

\begin{proof}
As long as $\lambda$ is not one of the $2n - 1$ points $\{0, \pm \sqrt{\mu_1/M}, \dots, \pm \sqrt{\mu_{n-1}/M}$ where $A - \lambda^2 MI$ is singular, we can invert $A - \lambda^2 MI$ and write the bottom line of \eqref{blockeq} as 
\begin{align}\label{blockeqbottom}
(C_2 K(\lambda) + K_2(\lambda))c 
+ (A - \lambda^2 MI)(I + (A - \lambda^2 MI)^{-1} D_2))d = 0
\end{align}

To continue, we need to bound $(A - \lambda^2 MI)^{-1} D_2$, which we will do for the two cases in Lemma \ref{Ainvboundlemma}. For $|\lambda| \geq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, we have
\begin{align*}
|| (A - \lambda^2 MI)^{-1} D_2 || &\leq \frac{C}{|\lambda|^2} (|\lambda| + r^{1/2})^3 \\ 
&\leq C |\lambda|
\end{align*}
Since $|\lambda| < \delta$, for sufficiently small $\delta$ this will be less than 1. 

For $|\lambda| \leq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$,
\begin{align*}
|| (A - \lambda^2 MI)^{-1} D_2 || &\leq C X^{n+1}\left( |\lambda|^2 + r \right)^{(n-1)/4} (|\lambda| + r^{1/2})^3 \\
&\leq C X^{n+1} r^{(n-1)/4} r^{3/2} \\ 
&= C X^{n+1} r^{(n+1)/4} r \\
&= C r (r^{1/4} X)^{n+1}
\end{align*}
Using the expression for $X$ from Lemma \ref{reparam}, this becomes
\begin{align*}
|| (A - \lambda^2 MI)^{-1} D_2 ||
&\leq C r \left( r^{1/4} (n |\log r| + C_b )\right)^{n+1}
\end{align*}
Since $r^{1/4} |\log r| \rightarrow 0$ as $r \rightarrow 0$, we can find $r_2 \leq r_1$ such that for $r \in \mathcal{R}$ with $\leq r_2$, $|| (A - \lambda^2 MI)^{-1} D_2 || < 1$. 

Thus for both cases, $(I + (A - \lambda^2 MI)^{-1} D_2)$ is invertible. Let $D_3 = (I + (A - \lambda^2 MI)^{-1} D_2)^{-1}$. Then we can solve \eqref{blockeqbottom} for $d$ to get
\begin{align*}
d &= -(A - \lambda^2 MI)^{-1} D_3 (C_2 K(\lambda) + K_2(\lambda))c
\end{align*}

Plugging this in for $c$ in the first line of the block matrix equation, we get
\begin{align*}
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda))c + D_1 d &= 0 \\
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda))c - D_1 (A - \lambda^2 MI)^{-1} D_3 (C_2 K(\lambda) + K_2(\lambda))c &= 0 \\
(K(\lambda) + C_1 K(\lambda) + K_1(\lambda) - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2 K(\lambda) - D_1 (A - \lambda^2 MI)^{-1} D_3 K_2(\lambda))c &= 0 \\
(I + C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2) K(\lambda)c + (K_1(\lambda) - D_1 (A - \lambda^2 MI)^{-1} D_3 K_2(\lambda))c &= 0
\end{align*}

Next, we will obtain bounds on the terms in the above equation. For the term $D_1 (A - \lambda^2 MI)^{-1}$, we consider the same two cases we did above. For $|\lambda| \geq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, we have
\begin{align*}
|| D_1 (A - \lambda^2 MI)^{-1} || &\leq \frac{C}{|\lambda|^2} (|\lambda| + r^{1/2})^2 \\ 
&\leq C
\end{align*}
For $|\lambda| \leq 2 r^{1/2} \sqrt{\tilde{\mu}_M/M}$, we have
\begin{align*}
|| D_1 (A - \lambda^2 MI)^{-1} || &\leq C r^{1/2} \left( r^{1/4} (n |\log r| + |\log(b_0\cdots b_{n-1})| \right)^{n+1}
\end{align*}
If necessary, decrease $r_2$ so that $X r^{(2 \tilde{\gamma} - 1)/4} \leq 1$. Thus for $r \leq r_2$ we will always have $|| D_1 (A - \lambda^2 MI)^{-1} || \leq C$.

We can now bound $C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2$ to get
\begin{align*}
|| C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2 || &\leq C \left( r^{\tilde{\gamma}/2} (|\lambda| + r^{1/2}) + r^{\tilde{\gamma}/2} (|\lambda| + r^{1/2})^2 \right) \\
&\leq C r^{\tilde{\gamma}/2} (|\lambda| + r^{1/2}) 
\end{align*}

Since $|\lambda| < \delta$, for sufficiently small $\delta$ and $r \leq r_2$ (again, decreasing $r_2$ if necessary), $|| C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2 || < 1$, thus $I + C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2$ is invertible. Let $C_4 = (I + C_1 - D_1 (A - \lambda^2 MI)^{-1} D_3 C_2)^{-1}$, where we have the bound $||C_4|| \leq C$. Then our equation becomes
\begin{align*}
K(\lambda)c + C_4(K_1(\lambda) - D_1 (A - \lambda^2 MI)^{-1} D_3 K_2(\lambda))c &= 0
\end{align*}

Let $D_4 = -C_4 D_1 (A - \lambda^2 MI)^{-1} D_3$. This has bound
\begin{align*}
||D_4|| &\leq C (|\lambda| + r^{1/2})^3
\end{align*}
Substituting this in, our equation becomes
\begin{align*}
(K(\lambda) + C_4 K_1(\lambda) + D_4 K_2(\lambda))c &= 0
\end{align*}

Finally, we note that since $K_1(\lambda)$ and $K_2(\lambda)$ have the same form, and $C_4$ is a weaker bound than $D_4$, we can write this as
\begin{align*}
(K(\lambda) + C_5 K_3(\lambda))c &= 0
\end{align*}
where $K_3(\lambda)$ has the same form as $K_1(\lambda)$ and $||C_5|| \leq C$.
\end{proof}
\end{lemma}

In the next lemma, we find the ``essential spectrum'' eigenvalues.
% find essential spectrum eigs
\begin{lemma}\label{essspeclemma}
There exists $r_2 \leq r_1$ such that for $r \in \mathcal{R}$ with $r \leq r_2$, the following is true. For all positive integers $k$ with $|\lambda^K(X,k)| < \delta$, there is a pair of purely imaginary ``essential spectrum'' eigenvalues which are given by $\lambda = \pm \lambda^{ess}(X,k; r)$, where
\begin{equation}\label{lambdaess}
\lambda^{ess}(X, k; r) = c \frac{k \pi i }{X} \left( 1 + \mathcal{O}\left( \frac{1}{X} \right)\right) + \mathcal{O}\left( \frac{r^{1/2}}{X} \right)
\end{equation}
The remainder terms cannot move this off of the imaginary axis.

\begin{proof}
From Lemma \ref{ceqlemma}, we have a nontrivial solution to \eqref{eqford} if and only if 
\begin{align*}
E(\lambda) = \det (K(\lambda) + C_5 K_3(\lambda)) = 0
\end{align*}
Since we know the form of $K_3(\lambda)$, we have the following expression for $C_5 K_3(\lambda)$
\[
C_5 K_3(\lambda) = 
\begin{pmatrix}
c_{1,1}^- e^{-\nu(\lambda)X_1} - c_{1,1}^+ e^{\nu(\lambda)X_1} 
& \dots & 
c_{1, n-1}^- e^{-\nu(\lambda)X_{n-1}} - c_{1,n-1}^+ e^{\nu(\lambda)X_{n-1}} &
c_{1,0}^- e^{-\nu(\lambda)X_0} - c_{1,0}^+ e^{\nu(\lambda)X_0}  \\
\vdots & & \vdots & \\
c_{n,1}^- e^{-\nu(\lambda)X_1} - c_{n,1}^+ e^{\nu(\lambda)X_1}
& \dots & 
c_{1, n-1}^- e^{-\nu(\lambda)X_{n-1}} - c_{1,n-1}^+ e^{\nu(\lambda)X_{n-1}} &
c_{n,0}^- e^{-\nu(\lambda)X_0} - c_{n,0}^+ e^{\nu(\lambda)X_0} 
\end{pmatrix}
\]
where $c_{i,j}$ are constants with $|c_{i,j}| \leq C(|\lambda| + r^{1/2})$. 

To solve $E(\lambda) = 0$, we use the definition of the determinant of an $n \times n$ matrix $A$.
\begin{align*}
\det A = \sum_{\sigma \in S_n} \left( \text{sgn}(\sigma) \prod_{i=1}^n a_{i, \sigma(i)} \right)
\end{align*}
where $S_n$ is the symmetric group on $n$ elements. Applying this to $K(\lambda) + C_5 K_3(\lambda)$ and simplifying, we get
\begin{align}\label{Elambdaess}
E(\lambda)
&= -2 \sinh(\nu(\lambda)X) + \sum_{\tau \in T_n}
c_\tau \prod_{j = 0}^{n-1} e^{\tau(j) \nu(\lambda)X_j}
\end{align}

where $T_n = \{ (\pm 1, \pm 1, \dots, \pm 1 \}$ and $c_\tau = \mathcal{O}(|\lambda| + r^{1/2})$. From Lemma \ref{detKlemma}, $\det K(\lambda^K(X,k)) = 0$. Since we are looking for a small perturbation of $\lambda^K(X,k)$, let
\begin{equation}\label{tildelambdadef}
\lambda = \lambda^K(X,k) + \frac{\tilde{\lambda}}{X}
\end{equation}
where $k \in \Z$ with $|\lambda^K(X,k)| < \delta$. From the proof of Lemma \ref{detKlemma}, 
\begin{align*}
\nu\left( \lambda^K(X, k) + \frac{\tilde{\lambda}}{X} \right) 
&= \frac{k \pi i}{X} + \frac{1}{c}\frac{\tilde{\lambda}}{X} \left( 1 + \mathcal{O} \left(\frac{k}{X}\right)^2 \right) + \mathcal{O}\left( \frac{\tilde{\lambda}}{X}\right)^2 \\
&= \frac{k \pi i}{X} + C_k \frac{\tilde{\lambda}}{X} + \mathcal{O}\left( \frac{\tilde{\lambda}}{X}\right)^2 
\end{align*}
where $C_k = 1/c = \mathcal{O}(1)$. 

Substituting this into the term $\sinh(\nu(\lambda)X)$ in \eqref{Elambdaess}, we have
\begin{align*}
\sinh\left(\nu\left(\lambda^K(X, k) + \frac{\tilde{\lambda}}{X}\right)X\right)
&= \sinh\left(\left(\frac{k \pi i}{X} + C_k \frac{\tilde{\lambda}}{X} + \mathcal{O}\left( \frac{\tilde{\lambda}}{X}\right)^2 \right) X\right) \\
&= \sinh\left( k \pi i + C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X}\right) \right) \\
&= (-1)^k \left( C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X}\right) \right) + \mathcal{O}\left( \tilde{\lambda} + \frac{\tilde{\lambda}^2}{X} \right)^3 \\
&= (-1)^k C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X} + \tilde{\lambda}^3 \right)
\end{align*}

For the remainder term of $E(\lambda)$, we have
\begin{align*}
c_\tau \prod_{j = 0}^{n-1} &\exp\left( {\tau(j) \nu(\lambda)X_j} \right)
= c_\tau \prod_{j = 0}^{n-1} 
\exp\left( \tau_j \left( \frac{k \pi i}{X} + C_k \frac{\tilde{\lambda}}{X} + \mathcal{O}\left( \frac{\tilde{\lambda}}{X}\right)^2 \right) X_j\right) \\
&= c_\tau \exp\left( \left( \sum_{j=0}^{n-1} \frac{\tau_j X_j}{X} \right)
\left( k \pi i + C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X} \right) \right) \right) \\
&= c_\tau \exp\left( r_\tau
\left( k \pi i + C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X} \right) \right) \right) \\ 
&= c_\tau e^{i k \pi r_\tau} \exp \left( r_\tau C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X} \right) \right)
\end{align*}
where $r_\tau = \left( \sum_{j=0}^{n-1} \frac{\tau_j X_j}{X} \right)$ and $|r_\tau| \leq 1$ for all $\tau \in T_n$. Expanding the exponential in a Taylor series, we have
\begin{align*}
c_\tau \prod_{j = 0}^{n-1} \exp\left( {\tau(j) \nu(\lambda)X_j} \right)
&= \tilde{c}_\tau \left( 1 + r_\tau C_k \tilde{\lambda} + \mathcal{O}\left(\tilde{\lambda}^2 \right) \right) 
\end{align*}
where $\tilde{c}_\tau = c_\tau e^{i k \pi r_\tau} = \mathcal{O}(|\lambda| + r^{1/2})$. 
Since the remainder term of \eqref{Elambdaess} consists of a finite sum of terms of this form, we can write it as
\begin{align*}
\sum_{\tau \in T_n} c_\tau \prod_{j = 0}^{n-1} \exp\left( {\tau(j) \nu(\lambda)X_j} \right)
&= \mathcal{O}\left( (|\lambda| + r^{1/2}) \left( 1 + r_\tau C_k \tilde{\lambda} + \mathcal{O}\left(\tilde{\lambda}^2 \right) \right)\right) \\
&= \mathcal{O} \left( \frac{k \pi}{X} + \frac{\tilde{\lambda}}{X} + r^{1/2} \right)
\end{align*}

Combining all of these, we obtain an expression for $E(\lambda)$ which is entirely terms of $\tilde{\lambda}$.
\begin{align*}
E(\tilde{\lambda})
&= (-1)^k C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}^2}{X} + \tilde{\lambda}^3 \right) + \mathcal{O} \left( \frac{k \pi}{X} + \frac{\tilde{\lambda}}{X} + r^{1/2} \right) \\
&= (-1)^k C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}}{X} + \tilde{\lambda}^3 \right) + \mathcal{O} \left( \frac{k \pi}{X} + r^{1/2} \right) \\
&= (-1)^k C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}}{n|\log r| + \log|b_0\cdots b_{n-1}|} + \tilde{\lambda}^3 \right) + \mathcal{O} \left( \frac{k \pi}{X} + r^{1/2} \right)
\end{align*}

where we used our expression for $X$ from Lemma \ref{reparam}. Note that the last term on the RHS does not involve $\tilde{\lambda}$. We wish to solve $E(\tilde{\lambda}) = 0$. To do this, define
\[
F(\tilde{\lambda}) = (-1)^k C_k \tilde{\lambda} + \mathcal{O}\left( \frac{\tilde{\lambda}}{n|\log r| + \log|b_0\cdots b_{n-1}|} + \tilde{\lambda}^3 \right)
\]
so that we wish to solve
\[
F(\tilde{\lambda}) = \mathcal{O} \left( \frac{k \pi}{X} + r^{1/2} \right)
\]
Note that $F(0) = 0$ and for sufficiently small $r$, 
\[
\frac{\partial}{\partial\tilde{\lambda}}F(\tilde{\lambda})\big|_{\tilde{\lambda} = 0}
= (-1)^k C_k + \mathcal{O}\left( \frac{1}{n|\log r| + \log|b_0\cdots b_{n-1}|} \right) \neq 0
\]
since $C_k = \mathcal{O}(1)$. Thus by the inverse function theorem, $F$ is invertible in a neighborhood of 0. Recall that $|\frac{k \pi}{X}| < \delta$. Thus, decreasing $r_2$ and $\delta$ if needed, we can solve uniquely for $\tilde{\lambda}$, i.e. we have
\[
\tilde{\lambda} = F^{-1}\left( \mathcal{O} \left( \frac{k \pi}{X} + r^{1/2} \right)\right)
\]
In particular, since $F^{-1}$ is smooth with $F^{-1}(0) = 0$,
\[
\tilde{\lambda} = \mathcal{O}\left( \frac{k \pi}{X} + r^{1/2} \right)
\]
Substituting this into \eqref{tildelambdadef}, we have eigenvalues $\lambda$ at
\begin{align*}
\lambda &= \lambda^K(X,k) + \frac{\tilde{\lambda}}{X} \\
&= \lambda^K(X,k) + \mathcal{O}\left( \frac{1}{X} \left( \frac{k \pi}{X} + r^{1/2} \right) \right)\\
&= c \frac{k \pi i }{X} \left( 1 + \mathcal{O}\left( \frac{1}{X} \right)\right) + \mathcal{O}\left( \frac{r^{1/2}}{X} \right)
\end{align*}

By Hamiltonian symmetry, these must be purely imaginary since they cannot come in quartets. Thus, the ``essential spectrum'' eigenvalues are given by $\lambda = \pm \lambda^{ess}(X, k; r)$
\[
\lambda^{ess}(X, k; r) = c \frac{k \pi i }{X} \left( 1 + \mathcal{O}\left( \frac{1}{X} \right)\right) + \mathcal{O}\left( \frac{r^{1/2}}{X} \right)
\]
where $k$ is a positive integer with $k \pi/X < \delta$. The remainder terms cannot move these off of the imaginary axis.
\end{proof}
\end{lemma}

\subsection{Eigenvalue counts}

Finally, we will perform two counts of the small eigenvalues so that we can conclude that we have accounted for everything. First, we will count the eigenvalues with $|\lambda| < \delta$.

\begin{lemma}\label{eigcount}
There are $2n + 2 k_M + 1$ eigenvalues inside the circle $|\lambda| = \delta$, where $k_M$ is the largest positive integer $k$ such that $|\lambda^K(k,X) < \delta$. There are no other eigenvalues inside $|\lambda| = \delta$ besides these.

\begin{proof}
Use the radius $\delta$ from Theorem \ref{blockmatrixtheorem}. If necessary, decrease $\delta$ a little so that the circle of radius $\delta$ about the origin in the complex plane cuts exactly halfway between consecutive points $\lambda^K(X, k)$.

Take $\lambda$ with $|\lambda| = \delta$. Then $K(\lambda)$ is invertible. For all $k$ such that $|\lambda^K(X, k)| \leq \delta$, this implies
\[
| \lambda - \lambda^K(X, k)| \geq C \frac{1}{X}
\]
Following the proofs of Lemma \ref{detKlemma} and \ref{Kinvboundslemma}, we have
\[
|\det K(\lambda)| \geq C
\]
which implies
\begin{equation}\label{Kinvbounddelta}
||K(\lambda)^{-1}|| \leq C
\end{equation}

Since the $2n-2$ nonzero roots of $\det(A - \lambda^2 M I)$ are $\mathcal{O}(r^{1/2})$, we can find $r_3 \leq r_2$ such that for all $r \leq r_3$, $2 r^{1/2} \sqrt{\tilde{\mu}_M/M} \leq \delta$, where $\tilde{\mu}_M = \max\{|\tilde{\mu}_1|, \dots, |\tilde{\mu}_{n-1}| \}$. Thus for $|\lambda| = \delta$, using the bound \eqref{Ainvbound2} from Lemma \ref{Ainvboundlemma}, 
\begin{equation}\label{Ainvbounddelta}
||(A - \lambda^2 M I)^{-1}|| \leq \frac{C}{\delta^2}
\end{equation}

Factoring $K(\lambda)$ out of the top left, write \eqref{blockeq} as
\begin{equation}\label{blockeq2}
\begin{pmatrix}
(I + C_1 + K_1(\lambda)K(\lambda)^{-1})K(\lambda) & D_1 \\
C_2 K(\lambda) + K_2(\lambda) & A - \lambda^2 MI + D_2
\end{pmatrix}
\begin{pmatrix} c \\ d \end{pmatrix} = 0
\end{equation}
From the proof of Lemma \ref{deqlemma}, $I + C_1 + K_1(\lambda)K(\lambda)^{-1}$ is invertible. As in that lemma, let $C_3 = (I + C_1 + K_1(\lambda)K(\lambda)^{-1})$. Multiplying the top row of \eqref{blockeq2} by $C_3$, we obtain the equivalent formulation
\begin{equation}\label{blockeq3}
\begin{pmatrix}
K(\lambda) & C_3 D_1 \\
C_2 K(\lambda) + K_2(\lambda) & A - \lambda^2 MI + D_2
\end{pmatrix}
\begin{pmatrix} c \\ d \end{pmatrix} = 0
\end{equation}
Thus finding $\lambda$ for which \eqref{blockeq} has a nontrivial solution is equivalent to finding the zeros of $E(\lambda)$, where
\begin{equation}
E(\lambda) = \det 
\begin{pmatrix}
K(\lambda) & C_3 D_1 \\
C_2 K(\lambda) + K_2(\lambda) & A - \lambda^2 MI + D_2
\end{pmatrix}
\end{equation}

Using a standard determinant identity, since $K(\lambda)$ and $A - \lambda^2 M I$ are both invertible, we can write $E(\lambda)$ as
\begin{align*}
E(\lambda) &= \det(K(\lambda))
\det ( A - \lambda^2 MI + D_2 - (C_2 K(\lambda) + K_2(\lambda))K(\lambda)^{-1}C_3 D_1 ) \\
&= \det(K(\lambda))\det(A - \lambda^2 MI)
\det ( I + (A - \lambda^2 MI)^{-1}(D_2 - (C_2 + K_2(\lambda)K(\lambda)^{-1})C_3 D_1 ) \\
&= \det(K(\lambda))\det(A - \lambda^2 MI)\det(I + R(\lambda))
\end{align*}
where
\[
R(\lambda) = 
(A - \lambda^2 MI)^{-1}(D_2 - (C_2 + K_2(\lambda)K(\lambda)^{-1})C_3 D_1)
\]
Using the bounds \eqref{Ainvbounddelta} and \eqref{Kinvbounddelta} together with the bounds from Lemma \ref{reparam}, and recalling that $r^{1/2} < |\lambda| = \delta$, we have the bound on $R(\lambda)$
\begin{align*}
||R(\lambda)|| \leq C \frac{1}{\delta^2}
( |\delta|^3 + (r^{\tilde{\gamma}/2}\delta + \delta)\delta^2) = C \delta
\end{align*}

Thus we can write $R(\lambda) = \delta \tilde{R}(\lambda)$, where $\tilde{R}(\lambda) = \mathcal{O}(1)$. From a standard expansion of the determinant, 
\begin{align*}
\det(I + R(\lambda)) &= 1 + \delta \text{Tr}(\tilde{R}(\lambda)) + \mathcal{O}(\delta^2) \\
&= 1 + \mathcal{O}(\delta)
\end{align*}
For sufficiently small $\delta$, $\det(I + R(\lambda)) = 1 + \tilde{\delta}$, where $|\tilde{\delta}| < 1$. This gives us 
\begin{equation}
E(\lambda) = \det(K(\lambda))\det(A - \lambda^2 MI) + \tilde{\delta} \det(K(\lambda))\det(A - \lambda^2 MI)
\end{equation}

Since $\tilde{\delta} < 1$ and we are taking $\lambda = \delta$, by Rouch\'e's Theorem, $E(\lambda)$ and $\det(K(\lambda))\det(A - \lambda^2 MI)$ have the same number of zeros (counting multiplicty) inside the circle $|\lambda| = \delta$. By our choice of $\delta$, 
\begin{enumerate}[(i)]
\item $\det(A - \lambda^2 MI)$ has exactly $2n$ zeros inside the circle $|\lambda| = \delta$, which are given by $\{ 0, \pm r^{1/2} \sqrt{ \tilde{\mu}_1 /M}, \dots, \pm r^{1/2} \sqrt{\tilde{\mu}_{n-1}/M} \}$, where 0 has algebraic multiplicty 2.

\item Let $k_M$ be the largest positive integer $k$ such that $\lambda^K(k,X) < \delta$. Then $\det(K(\lambda))$ has exactly $2 K_M + 1$ zeros inside the circle $|\lambda| = \delta$, which are given by $\{0, \pm \lambda^K(1,X), \dots, \lambda^K(k_M,X)\}$, where 0 has algebraic multiplicity 1.
\end{enumerate}

Thus there are exactly $2n + 2 k_M + 1$ eigenvalues inside the circle $|\lambda| = \delta$. 
\end{proof}
\end{lemma}

We will also count the eigenvalues in a small ball around the 0 

\begin{lemma}\label{eigcount2}
Let 
\begin{equation}\label{xiradius}
\xi = \min\left\{ \frac{\pi}{2X}, \frac{r^{1/2}\sqrt{\tilde{\mu}_m/M} }{2} \right\} = 
\min\left\{ \frac{\pi}{2 C( n |\log X| + |\log(b_1\cdots b_{n-1}|)}, \frac{r^{1/2} \sqrt{\tilde{\mu}_m/M}}{2} \right\} 
\end{equation}
where $\tilde{\mu}_m = \min \{ |\tilde{\mu_1}|, \dots, |\tilde{\mu}_{n-1}| \}$. Then for sufficiently small $r$, there are exactly 3 eigenvalues inside the circle of radius $\xi$ in the complex plane.

\begin{proof}
For $|\lambda| = \xi$, $K(\lambda)$ is invertible. We look for nontrivial solutions to \eqref{blockeq}, which, as in the previous lemma, we rewrite as \eqref{blockeq2}.

To bound $K_1(\lambda)K(\lambda)^{-1}$, we follow the proof of Lemma \ref{Kinvboundslemma}. By our choice of $\xi$, the $\epsilon$ criterion in that lemma is automatically satisfied. Replacing the condition that $|\lambda| \geq C r^{1/2}$ with $|\lambda| = \delta$, we have the bound
\begin{align*}
||K_1(\lambda)K(\lambda)^{-1}|| &\leq C( \xi + r^{1/2})\max\left\{ r^{-1/4}, \frac{1}{\xi X} \right\} \\
&\leq C r^{1/2} \max\left\{ r^{-1/4}, \frac{1}{\xi X} \right\} \\
&\leq C r^{1/2} \max\left\{ r^{-1/4}, 1, \frac{r^{-1/2}}{X} \right\} \\
&\leq C \max\left\{ r^{1/4}, \frac{1}{X} \right\} \\
&\leq C \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\} 
\end{align*}
where we used the expression for $X$ from Lemma \ref{reparam}. Since the bound for $C_1$ is stronger than this, for sufficiently small $r$, $I + C_1 + K_1(\lambda)K(\lambda)^{-1}$ is invertible. Let $C_3 = (I + C_1 + K_1(\lambda)K(\lambda)^{-1})$. As in the previous lemma, multiply the top row of \eqref{blockeq2} by $C_3$ to get \eqref{blockeq3}. Then finding a nontrivial soluton to \eqref{blockeq3} is equivalent to solving $E(\lambda) = 0$, where 
\begin{equation}
E(\lambda) = \det 
\begin{pmatrix}
K(\lambda) & C_3 D_1 \\
C_2 K(\lambda) + K_2(\lambda) & A - \lambda^2 MI + D_2
\end{pmatrix}
\end{equation}

As in the previous lemma, since $K(\lambda)$ and $A - \lambda^2 M I$ are invertible for $|\lambda| = \xi$, we use a standard determinant identity to write $E(\lambda)$ as 
\begin{align*}
E(\lambda)
&= \det(K(\lambda))\det(A - \lambda^2 MI)\det(I + R(\lambda))
\end{align*}
where
\[
R(\lambda) = 
(A - \lambda^2 MI)^{-1}(D_2 - (C_2 + K_2(\lambda)K(\lambda)^{-1})C_3 D_1)
\]

First, we bound $(D_2 - (C_2 + K_2(\lambda)K(\lambda)^{-1})C_3 D_1)$. Since $K_2(\lambda)$ is of the same form as $K_1(\lambda)$, we can use the bound for $K_1(\lambda)K(\lambda)^{-1}$ here.
\begin{align*}
||(D_2 &- (C_2 + K_2(\lambda)K(\lambda)^{-1})C_3 D_1)|| \\
&\leq C \left( (\xi + r^{1/2})^3 + (\xi + r^{1/2})^2 \left( r^{\tilde{\gamma}/2}(\xi + r^{1/2})^2 + \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\} \right) \right) \\
&\leq C \left( r^{3/2} + r \left( r^{1 + \tilde{\gamma}/2} + \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\} \right) \right) \\
&\leq C r \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\} 
\end{align*}

For a bound on $(A - \lambda^2 MI)^{-1}$, we use Lemma \ref{Ainvboundlemma}. The bound depends on $\xi$. If $\xi = \frac{\pi}{2X}$, we can go ahead and use the bound \eqref{Ainvbound1} from Lemma \ref{Ainvboundlemma}, which is
\[
||(A - \lambda^2 MI)^{-1}|| \leq C X^{n+1} r^{(n-1)/4}
\]

If $\xi = \frac{\tilde{\mu}_m r^{1/2}}{2}$, then we need to compute a new bound. For $\det(A - \lambda^2 MI)$, we can adapt the proof of Lemma \ref{detAboundlemma} to get
\[
|\det(A - \lambda^2 MI)| \leq C \xi^2 (\xi + r^{1/2})^{n-1} r^{(n-1)/2}
\]
Using this in the proof of Lemma \ref{Ainvboundlemma}, we get
\begin{align*}
||(A - \lambda^2 MI)^{-1}|| &\leq C \frac{(r + \xi^2)^{n-1}}{\xi^2 (\xi + r^{1/2})^{n-1} r^{(n-1)/2}} \\
&= C \frac{r^{n-1}}{r \: r^{(n-1)/2} r^{(n-1)/2}} \\
&= \frac{C}{r} 
\end{align*}

Combining all of these, we can get a bound on $R(\lambda)$. If $\xi = \frac{\pi}{2X}$, then
\begin{align*}
||R(\lambda)|| &\leq C X^{n+1} r^{(n-1)/4} r \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\} \\
&\leq C r^{1/2} (r^{1/4} X)^{n+1} \max\left\{ r^{1/4}, \frac{1}{n|\log r| + C_b } \right\} \\
&\leq C r^{1/2} \left(r^{1/4}(n|\log r| + |\log(b_1 \cdots b_{n-1})|)\right)^{n+1} \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})| } \right\}
\end{align*}

This can be made arbitrarily small by taking $r$ sufficiently small. If $\xi = \frac{\tilde{\mu}_m r^{1/2}}{2}$, then 
\begin{align*}
||R(\lambda)|| &\leq \frac{C}{r} r \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})|} \right\} \\
&= C \max\left\{ r^{1/4}, \frac{1}{n|\log r| + |\log(b_1 \cdots b_{n-1})|} \right\} 
\end{align*}
This can also be made arbitrarily small. Choose $r_3$ sufficiently small so that for $r \leq r_3$,
\[
||R(\lambda)||_{max} \leq \frac{1}{3n}
\] 
so that $\text{Tr}(R(\lambda)) \leq 1/3$. From a standard expansion of the determinant, 
\begin{align*}
\det(I + R(\lambda)) &= 1 + \text{Tr}(R(\lambda)) + \mathcal{O}\left(\frac{1}{9n^2} \right) \\
&= 1 + p
\end{align*}
where $0 < |p| < 1$. Thus we have
\begin{align*}
E(\lambda) &= \det(K(\lambda))\det(A - \lambda^2 MI)\det(I + R(\lambda)) \\
&= \det(K(\lambda))\det(A - \lambda^2 MI)(1 + p) \\
&= \det(K(\lambda))\det(A - \lambda^2 MI) + p \det(K(\lambda))\det(A - \lambda^2 MI)
\end{align*}

Since $|p| < 1$, by Rouch\'e's Theorem, $E(\lambda)$ and $\det(K(\lambda))\det(A - \lambda^2 MI)$ have the same number of zeros (counting multiplicty) inside the circle $|\lambda| = \xi$. By our choice of $\xi$, $\det(K(\lambda))\det(A - \lambda^2 MI)$ has exactly 3 zeros inside $|\lambda| = \xi$, all of which occur at $\lambda = 0$. We conclude that $\tilde{E}(\lambda)$ (and thus $E(\lambda)$) has exactly 3 zeros inside $|\lambda| = \xi$.\\
\end{proof}
\end{lemma}

\subsection{Proof of Theorem \ref{locateeigtheorem}}

For part (i), it follows from \eqref{Arelations} that $Q_{np}'(x)$ is an eigenfunction with eigenvalue 0 and $T_{np}(x)$ is a generalized eigenfunction with eigenvalue 0 corresponding to $Q_{np}'(x)$. By Hypothesis \ref{Melnikov2hyp}, this Jordan chain cannot continue. By Lemma \ref{varadjsolutions}, there is another eigenfunction $V^c(x)$ with eigenvalue 0; this eigenfunction is bounded but does not decay to 0. Although Lemma \ref{varadjsolutions} states this for $A(Q(x))$, i.e. the linearization about the primary pulse, the same argument holds for $A(Q_{np}(x))$, since it only depends on the rest state.

Part (ii) follows from Lemma \eqref{inteigslemma} and part (iii) follows from Lemma \ref{essspeclemma}. Part (iv) follows from Lemmas \ref{eigcount} and \ref{eigcount2}. Using these lemmas, a complete account of the eigenvalues inside $|\lambda| = \delta$ is as follows.
\begin{enumerate}
	\item At $\lambda = 0$, there is an eigenvalue with algebraic multiplicity 3. The eigenfunctions are those from part (i).
	\item There are $2n - 2$ interaction eigenvalues, which come in pairs $\pm \lambda$. Each pair is real or purely imaginary.
	\item There $2 k_M$ purely imaginary ``essential spectrum'' eigenvalues, which also come in pairs.
\end{enumerate}

\subsection{Proof of Theorem \ref{inteigsparity}}

Let $r_1$ and $b^*$ be as in Theorem \ref{unifperexist}. Let $\tilde{A}_0$ be the tri-diagonal, symmetric matrix 
\begin{align*}
\tilde{A}_0 &= \begin{pmatrix}
-\tilde{a}_0 & \tilde{a}_0 \\
\tilde{a}_0 & -\tilde{a}_0 - \tilde{a}_1 &  \tilde{a}_1 \\
& \tilde{a}_1 & -\tilde{a}_1 - \tilde{a}_2 &  \tilde{a}_2 \\
& & \ddots & & \ddots \\
& & & & & \tilde{a}_{n-2} & -\tilde{a}_{n-2} \\
\end{pmatrix}
\end{align*}
which is obtained from the matrix $\tilde{A}$ by taking $\tilde{a}_{n-1} = 0$. The matrix $\tilde{A}_0$ is symmetric, so its eigenvalues are real, and $(1, 1, \dots, 1)^T$ is an eigenvector of $\tilde{A}_0$ with eigenvalue 0. Let $0, \mu^0_1, \dots, \mu^0_{n-1}$ be the eigenvalues of $\tilde{A}_0$. Let $n_+$ be the number of positive $\tilde{a}_j$ and $n_i = n - n_+ - 1$ be the number of negative $\tilde{a}_j$. By Lemma 5.4 of \cite{Sandstede1998} (noting that $\tilde{A}_0$ is the matrix $-A_0$ in that lemma),
\begin{enumerate}[(i)]
\item $\tilde{A}_0$ has $n_+$ negative eigenvalues (counting multiplicity)
\item $\tilde{A}_0$ has $n_-$ positive eigenvalues (counting multiplicity)
\end{enumerate}

For $\tilde{a}_{n-1}$ small, $\tilde{A}$ is a small perturbation of $\tilde{A}_0$. Since characteristic polynomials are smooth functions of matrix entries, the eigenvalues of a matrix are also smooth functions of the matrix entries. In particular, the eigenvalues of $\tilde{A}$ depend smoothly on $\tilde{a}_{n-1}$, and as $\tilde{a}_{n-1}$ approaches 0, the eigenvalues of $\tilde{A}$ approach those of $\tilde{A}_0$. In particular, as $\tilde{a}_{n-1}$ is increased from 0, the eigenvalues of $\tilde{A}$ can only change sign by crossing through 0. Thus for sufficiently small $\tilde{a}_{n-1}$, the signs of the eigenvalues of $\tilde{A}$ are determined by the signs of the $n-1$ matrix elements $\tilde{a}_0, \dots, \tilde{a}_{n-2}$. We will now obtain this result in terms of $r$ and the baseline length parameters used to contruct the periodic $n-$pulse.

From the proof of Lemma \eqref{reparam}, $\tilde{a}_j$ is given by
\begin{align}\label{tildeaj2}
\tilde{a}_j
&= (-1)^{-\rho \log r / \pi} s_0 e^{\alpha \phi/\beta} \left( \beta b_j(r; m_j, \theta) \cos\left( -\rho \log b_j(r; m_j, \theta) \right) - \alpha b_j(r; m_j, \theta) \sin \left( -\rho \log b_j(r; m_j, \theta) \right) \right)
\end{align}
As $r \rightarrow 0$, $b_j(r; m_j, \theta) \rightarrow b_j^*(m_j, \theta)$ by Theorem \ref{perexist}. As $m_{n-1} \rightarrow \infty$, $b_j^*(m_j, \theta) \rightarrow b_j^0$ by Lemma \ref{thetaparamlemma}. Finally, since $b_{n-1}^0 = \exp\left(-\frac{m_{n-1} \pi}{\rho}\right)$, $b_{n-1}(r; m_{n-1}, \theta) \rightarrow 0$ (and so $\tilde{a}_{n-1} \rightarrow 0$) as $(r, m_{n-1}) \rightarrow (0, \infty)$. Thus we can find a positive integer $M_1$ and $\tilde{r}_1 \leq r_1$ such that for all $m_{n-1} \geq M_1$ and $r \leq \tilde{r}_1$, 
\begin{enumerate}[(i)]
	\item $\tilde{a}_{n-1}$ is sufficiently small so that the eigenvalues of $\tilde{A}$ have the same sign as those of $\tilde{A}_0$.
	\item For $j = 0, \dots, n-2$ and for all $\theta \in [-\arctan \rho, \pi - \arctan \rho)$,
	\begin{equation}\label{bjunif}
	b_j(r; m_j, \theta) = b_j^0 e^{ -\frac{1}{\rho} \theta^*_j(r, m_{n-1}) } = e^{ -\frac{1}{\rho}(m_j \pi + \theta^*_j(r, m_{n-1})) } 
	\end{equation}
	where $|\theta^*_j(r, m_{n-1})| < \arctan \rho$.
\end{enumerate}

We can now determine the signs of the $\tilde{a}_j$ for $j = 0, \dots, n-2$. Since
\begin{align*}
\cos\left( -\rho \log b_j(r; m_j, \theta) \right) 
&= \cos\left( -\rho \log e^{ -\frac{1}{\rho}(m_j \pi + \theta^*_j(r, m_{n-1})) } \right) \\
&= \cos\left( m_j \pi + \theta^*_j(r, m_{n-1})\right) \\
&= (-1)^{m_j} \cos \theta^*_j(r, m_{n-1})
\end{align*}
and
\begin{align*}
\sin\left( -\rho \log b_j(r; m_j, \theta) \right) 
&= \sin\left( m_j \pi + \theta^*_j(r, m_{n-1})\right) \\
&= (-1)^{m_j} \sin \theta^*_j(r, m_{n-1})
\end{align*}
upon substituting \eqref{bjunif} into equation \eqref{tildeaj2} we obtain
\begin{align*}
\tilde{a}_j 
&= (-1)^{-\rho \log r / \pi} (-1)^{m_j} s_0 e^{\alpha \phi/\beta} b_j^0 e^{ -\frac{1}{\rho} \theta^*_j(r, m_{n-1}) } \left( \beta \cos\theta^*_j(r, m_{n-1}) - \alpha \sin \theta^*_j(r, m_{n-1}) \right) \\
&= (-1)^{m + m_j} \left[ s_0 \alpha e^{\alpha \phi/\beta} b_j^0 e^{ -\frac{1}{\rho} \theta^*_j(r, m_{n-1}) } \cos\theta^*_j(r, m_{n-1}) \right] \left( \rho - \tan \theta^*_j(r, m_{n-1}) \right)
\end{align*}
where we have let $r \in \mathcal{R}$ as $r = e^{-\frac{1}{\rho}m \pi}$ for some nonnegative integer $m$. The term in brackets is always positive since $|\theta^*_j(r, m_{n-1})| < \arctan \rho$. Thus the sign of $\tilde{a}_j(0)$ is completely determined by the term $(-1)^{m + m_j}$, and we have
\begin{align*}
\tilde{a}_j(0) &> 0 && \text{if } m + m_j \text{ is even} \\
\tilde{a}_j(0) &< 0 && \text{if } m + m_j \text{ is odd}
\end{align*}
From this, it follows that if $m$ is even,
\begin{enumerate}[(i)]
\item $\tilde{A}_0$ has $n_{\text{even}}$ negative eigenvalues (counting multiplicity)
\item $\tilde{A}_0$ has $n_{\text{odd}}$ positive eigenvalues (counting multiplicity)
\end{enumerate}
This is reversed if $m$ is odd. The result follows from equation \eqref{inteigsformula} from Lemma \ref{inteigslemma}, where we note the dependence on the sign of $M$. The condition that $m_{n-1} \geq M_1$ is equivalent to $b_{n-1}^0 \leq \tilde{b}^*$ for some $\tilde{b}^* \leq b^*$.

\subsection{Interaction Eigenvalues: Specific Cases}

There are specific cases in which we can compute the eigenvalues of $\tilde{A}$ in terms of the $\tilde{a}_j$.

Recall that the $\tilde{a}_j$ are given by
\begin{align*}
\tilde{a}_j(r)
&= (-1)^{-\rho \log r / \pi} s_0 e^{\alpha \phi/\beta} \left( \beta b_j(r; m_j; \theta) \cos\left( -\rho \log b_j(r; m_j; \theta) \right) - \alpha b_j(r; m_j; \theta) \sin \left( -\rho \log b_j(r; m_j; \theta)  \right) \right) + \mathcal{O}(r^{\gamma/2\alpha})
\end{align*}

First, we consider the case when $n = 2$. In that case, the eigenvalues of $\tilde{A}$ are $\{0, \tilde{a} \}$, where
\begin{align*}
\tilde{a} = \tilde{a}_0 + \tilde{a}_1
\end{align*}
For a symmetric 2-periodic pulse, $m_0 = m_1 = 0$ (recall that one of them must be 0). Then by Theorem \ref{2pulsebifurcation}, for sufficiently small $r$ we have symmetric solutions with equal length parameters $b_0(\theta) = b_1(\theta) = e^{-\theta/\rho}$. These length parameters do not depend on $r$. Thus we have
\begin{align*}
\tilde{a}_0(r) = \tilde{a}_1(r)  
&= (-1)^{-\rho \log r / \pi} s_0 e^{\alpha \phi/\beta} e^{-\theta/\rho} \left( \beta \cos \theta - \alpha \sin \theta \right) + \mathcal{O}(r^{\gamma/2\alpha}) \\
&= (-1)^{-\rho \log r / \pi}  \frac{s_0 e^{\alpha \phi/\beta} }{\alpha}  e^{-\theta/\rho} \left( \rho \cos \theta - \sin \theta \right) + \mathcal{O}(r^{\gamma/2\alpha})
\end{align*}

For $r = 0$, $\tilde{a}(0) = 0$ at the pitchfork bifurcation point $\theta = p^*(0)$. 





For small $r$, we should be able to argue that $\tilde{a}_j(r) = 0$ at the pitchfork bifurcation point $p_0(r)$. Thus there is a pitchfork bifurcation in the integration eigenvalues at $\theta = p_0(r)$, in which the interaction eigenvalues collide at the origin and switch from a real pair to a purely imaginary pair or vice versa. 

\iffulldocument\else
	\bibliographystyle{amsalpha}
	\bibliography{thesis.bib}
\fi

\end{document}