\documentclass[thesis.tex]{subfiles}

\begin{document}

\iffulldocument\else
	\chapter{KdV5}
\fi

\section{Overview of proof}

As in \cite{Sandstede1998}, we will use Lin's method to construct eigenfunctions to
\begin{equation}\label{PDEeigsystemper4}
\begin{aligned}
U'(x) &= A(Q_n(x); \lambda)U(x) \\
U(-X) &= U(X),
\end{aligned}
\end{equation}
where $A(\cdot; \lambda)$ is defined in \cref{AQnlambda} and the second equation ensures that the eigenfunctions obey the same periodic boundary conditions as the solution $Q_n(x)$. We will take a piecewise linear combination of kernel eigenfunctions as our ansatz for $U(n)$, and then join these together with small remainder functions. The specific form of the ansatz will be given in \cref{sec:perpiece} after the appropriate solutions to $U'(x) = A(Q(x); \lambda)U(x)$ have been constructed. As long as the individual pulses in $Q_n(x)$ are well-separated, we will use Lin's method to produce a unique function $U(x)$ which solves \cref{PDEeigsystemper4} but which generically has $n$ jumps. In contrast to \cite{Sandstede1998}, these $n$ jumps are in the two-dimensional space spanned by $\Psi(0)$ and $\Psi^c(0)$, which gives us $2n$ jump conditions. Finding the eigenvalues amounts to solving the $2n$ jump conditions. 

\section{Eigenvalues of background state}

Before we can solve the system \cref{PDEeigsystemper4} using Lin's method and derive the jump conditions, we will need to set up a considerable amount of machinery. Let $A(\lambda) = A(0; \lambda)$, which is a constant matrix. First, we obtain a result regarding the eigenvalues and eigenvectors of the constant matrix $A(\lambda)$.

% nu(lambda) lemma

\begin{lemma}\label{nulambdalemma}
There exists $\delta_0 > 0$ such that for $|\lambda| < \delta_0$, the matrix $A(\lambda)$ has a simple eigenvalue $\nu(\lambda)$. $\nu(\lambda)$ is smooth in $\lambda$, $\nu(0) = 0$, $\nu'(0) = 1/c$, and for $|\lambda| < \delta_0$,
\begin{equation}\label{nulambda}
\nu(\lambda) = \frac{1}{c} \lambda + \mathcal{O}(|\lambda|^3)
\end{equation}
In addition,
\begin{enumerate}[(i)]
\item $\nu(-\lambda) = -\nu(\lambda)$ and $\nu(\overline{\lambda}) = \overline{\nu(\lambda)}$.
\item The corresponding eigenvector to $\nu(\lambda)$ is $V_0(\lambda)$ which is smooth in $\lambda$ and has expansion
\begin{equation}\label{V0expansion}
V_0(\lambda) = V_0 + \lambda V_0'(0) + \mathcal{O}(\lambda^2),
\end{equation}
where $V_0'(0) = (0, 1/c^2, 0, \dots, 0)^T$. Furthermore, $V_0(-\lambda) = R V_0(\lambda)$, where $R$ is the standard reversor operator.
\end{enumerate}

Similarly, the matrix $-A(\lambda)^*$ has an eigenvalue $-\overline{\nu(\lambda)}$ with corresponding eigenvector $W_0(\overline{\lambda})$, both of which are smooth in $\overline{\lambda}$. $W_0(\overline{\lambda})$ has Taylor expansion
\begin{equation}\label{W0expansion}
W_0(\lambda) = W_0 + \overline{\lambda} W'(0) + \mathcal{O}(\overline{\lambda}^2),
\end{equation}
where 
\begin{equation}\label{W0prime}
W_0'(0) = \frac{1}{c} \left( 0, -c_3, 0, -c_5, 0, \dots, 0, -c_{2m-1}, 0, 1, 0\right)^T
\end{equation}
and symmetry property $W_0(-\overline{\lambda}) = R W_0(\overline{\lambda})$.

\begin{proof}

Using \eqref{defAphi} and \eqref{fpartials0},
\begin{equation}\label{Alambdaform}
A(\lambda) = 
\begin{pmatrix}
0 & 1 & 0 & \dots & 0 & 0 & 0 \\
0 & 0 & 1 & \dots & 0 & 0 & 0\\
& \vdots && \vdots \\
0 & 0 & 0 & \dots & 0 & 1 & 0 \\
- c & 0 & c_3 & \dots & c_{2m-1} & 0 & 1 \\
\lambda & 0 & 0 & \dots & 0 & 0 & 0
\end{pmatrix}
\end{equation}
which has characteristic polynomial
\begin{equation}\label{charpolyA0lambda}
p(\nu; \lambda) = \lambda = -\nu^{2m+1} + c_{2m-1} \nu^{2m-1} + \dots + c_3 \nu^3 - c \nu + \lambda
\end{equation}
When $\lambda = 0$, $p(0; \nu)$ has a root at $\nu = 0$. From Lemma \ref{nondegenlemma}, $\nu = 0$ is simple root and is located a distance $\sqrt{\alpha_0^2 + \beta_0^2}$ from the next smallest roots. 

Since $p(0; 0) = 0$ and $\partial_\nu p(0; 0) = -c \neq 0$, we can use the IFT to can solve for $\nu$ in terms of $\lambda$ near $\lambda = 0$. In other words, there exists $\delta_0 > 0$ and a smooth function $\nu(\lambda)$ such that $\nu(0) = 0$ and for $|\lambda| < \delta$, $p(\nu(\lambda)$ is the unique solution to $p(\nu; \lambda) = 0$. Using the IFT to differentiate $\nu(\lambda)$ at $\lambda = 0$,
\begin{align*}
\nu'(0) &= -\frac{1}{\partial_\nu p_2(\nu(\lambda); \lambda) } \partial_\lambda p ( \nu(\lambda); \lambda ) \Big|_{\lambda = 0}\\
&= -\frac{1}{\partial_\nu p(\nu(0); 0) } \\
&= \frac{1}{c}
\end{align*}
By reversibility, $p(\nu; \lambda)$ only involves odd powers of $\nu$, thus $p(\nu; \lambda) = 0$ implies $p(-\nu; -\lambda) = 0$. Uniqueness of the solution $\nu(\lambda)$ from the IFT implies that $\nu(-\lambda) = -\nu(\lambda)$, i.e. $\nu(\lambda)$ is an odd function of $\lambda$. Since $\nu(\lambda)$ is the root of a polynomial which is smooth in $\lambda$, we can expand $\nu(\lambda)$ in a Taylor series about $\lambda = 0$. Since $\nu(\lambda)$ is an odd function, the Taylor series involves only odd powers of $\lambda$ and is given by
\begin{align*}
\nu(\lambda) = \frac{1}{c} \lambda + \mathcal{O}(|\lambda|^3)
\end{align*}
Furthermore, if $p(\nu; \lambda) = 0$ then $p(\overline{\nu}; \overline{\lambda}) = 0$. Again, uniqueness of the solution $\nu(\lambda)$ from the IFT implies that $\nu(\overline{\lambda}) = \overline{\nu(\lambda)}$. Combining these two symmetry results, $\nu(\lambda)$ is pure imaginary if and only if $\lambda$ is also pure imaginary.

For the eigenvectors, let $V_0(\lambda)$ be an eigenvector of $A(\lambda)$ corresponding to $\nu(\lambda)$. This is only unique up to scalar multiple, but since $V_0(\lambda)$ is smooth in $\lambda$, scale $V_0(\lambda)$ so that $V(0) = V_0$. We can verify by direct calculation that $A(\lambda) = -R(A(-\lambda)R$, where $R$ is the standard reversor operator. Since
\begin{align*}
[A(\lambda) - \nu(\lambda) I]V = 0 &\iff -R(A(-\lambda) + \nu(\lambda) I)RV = 0 \\
&\iff (A(-\lambda) + \nu(\lambda) I)RV = 0,
\end{align*}
$RV_0(\lambda)$ is an eigenvector of $A(-\lambda)$ corresponding to $-\nu(\lambda)$ and $V_0(-\lambda) = R V_0(\lambda)$. Differentiating $A(\lambda)V_0(\lambda) = \nu(\lambda) V_0(\lambda)$ with respect to $\lambda$,
\begin{align*}
A'(\lambda)V_0(\lambda) + A(\lambda)V_0'(\lambda) = \nu'(\lambda)V_0(\lambda) + \nu(\lambda)V_0'(\lambda).
\end{align*}
Evaluating this at $\lambda = 0$, since $A'(\lambda) = B$, $\nu(0) = 0$, and $\nu'(0) = 0$, this becomes
\begin{align*}
B V_0(0) + A(0)V_0'(0) = \frac{1}{c} V_0(0)
\end{align*}
which we rearrange to get
\begin{align*}
A(\lambda)V_0'(0) = -B V_0(0) + \frac{1}{c} V_0(0)
= (1/c^2, 0, \dots, 0)^T.
\end{align*}
Using \eqref{Alambdaform} for $A(\lambda)$, this has a solution $V_0'(0) = (0, 1/c^2, 0, \dots, 0)^T$ which is orthogonal to $V_0$, and we have the Taylor expansion
\[
V_0(\lambda) = V_0 + \lambda V_0'(0) + \mathcal{O}(\lambda^2),
\]

We follow the exact same procedure with the adjoint asymptotic matrix $-A(\lambda)^*$, which has an eigenvalue $-\overline{\nu(\lambda)}$ that is smooth in $\overline{\lambda}$. To find $W_0'(\overline{\lambda})$, we follow the same procedure as above to get the equation
\begin{align*}
A(0)^* W_0'(0) = \frac{1}{c} W_0(0) - B^* W_0(0)
= (-1, 0, \dots, 0, 1/c)
\end{align*}
which has a solution 
\[
W_0'(0) = \frac{1}{c} \left( 0, -c_3, 0, -c_5, 0, \dots, 0, -c_{2m-1}, 0, 1, 0\right)^T
\]
that is orthogonal to $W_0$.

\end{proof}
\end{lemma}

\section{Gap and conjugation Lemmas}

In this section, we state and prove the gap and conjugation lemmas. We will use the conjugation lemma to simplify the system of equations \cref{PDEeigsystemper4} by converting $A(Q(x); \lambda)$ in to a constant coefficient matrix. The statements and notation of these lemmas are similar to those in \cite{Zumbrun2009}, except we allow the parameter vector $\Lambda$ to live in an arbitrary Banach space rather than in a subset of $\C^m$. The proofs follow those in \cite{Zumbrun2009}, but are given in much more detail. In addition, the proof of the conjugation lemma is used to prove a corollary. First, we state and prove the gap lemma.

% Gap lemma
\begin{lemma}[Gap Lemma]\label{gaplemma}
Let $W \in \C^N$, and consider the family of ODEs on $\R$
\begin{equation}\label{LambdaEVP}
W(x)' = A(x; \Lambda) W
\end{equation}
where $\Lambda \in \Omega$ is a parameter vector and $\Omega$ is a Banach space. Assume that
\begin{enumerate}
	\item The map $\Lambda \mapsto A(\cdot; \Lambda)$ is analytic in $\Lambda$.
	\item $A(x; \Lambda) \rightarrow A_\pm(\lambda)$ (independent of $\Lambda$) as $x \rightarrow \pm \infty$, and there exists $\delta > 0$ such that for $|\Lambda| < \delta$ we have the uniform exponential decay estimates 
	\begin{align}\label{ALambdadecay}
	\left| \frac{\partial^k}{\partial x^k} A(x; \Lambda) - A_\pm(\Lambda) \right| 
	&\leq C e^{-\theta |x|} && 0 \leq k \leq K
	\end{align}
	where $\alpha > 0$, $C > 0$, and $K$ is a nonnegative integer.
\end{enumerate}
Suppose $V^-(\Lambda)$ is an eigenvector of $A_-(\Lambda)$ with corresponding eigenvalue $\mu(\Lambda)$, both analytic in $\Lambda$. Then there exists a unique solution of \ref{LambdaEVP} of the form 
\begin{equation}
W(x; \Lambda) = V(x; \Lambda) e^{\mu(\Lambda)x}
\end{equation}
where $V$ is $C^1$ in $x$ and analytic in $\Lambda$ for $|\Lambda| < \delta$, and for any fixed $\tilde{\theta} < \theta$
\begin{align}
V(x; \Lambda) = V^-(\Lambda) + \mathcal{O}(e^{-\tilde{\theta}|x|}|V^-(\Lambda)|) && x \in \R^-
\end{align}
A similar result holds for $A_+(\lambda)$ on $\R^+$.

\begin{proof}
This proof follows \cite{Zumbrun2009}, with the main difference being that the parameter vector $\Lambda$ is in a general Banach space instead of a subset of $C^p$. Let $W(x; \Lambda) = V(x; \Lambda) e^{\mu(\Lambda) x}$. Substituting this into \eqref{LambdaEVP} and simplifying, we obtain the equivalent ODE
\begin{equation}\label{VEVP}
V(x; \Lambda)' = (A_-(\Lambda) - \mu(\Lambda)I)V(x; \Lambda) + \Theta(x; \Lambda) V(x; \Lambda)
\end{equation}
where $\Theta(x; \Lambda) = (A(x; \Lambda) - A_-(\Lambda)) = \mathcal{O}(e^{-\theta|x|})$ by \eqref{ALambdadecay}. Choose any $\tilde{\theta} < \theta_1 < \theta$ such that for $|\Lambda| < \delta$, the real part of the spectrum of $A_-(\Lambda)$ lies either to the left or to the right of the vertical line $\text{Re}(\nu) = \text{Re}(\mu(\Lambda) + \theta_1$ in the complex plane. Since the eigenvalues of $A_(\Lambda)$ are analytic in $\Lambda$, this is possible.

For $|\Lambda| < \delta$, define the spectral projections $P(\Lambda)$ and $Q(\Lambda)$, where $P(\Lambda)$ projects onto the direct sum of all eigenspaces of $A_-(\Lambda)$ corresponding to eigenvalues $\nu$ with $\text{Re}(\nu) < \text{Re}(\mu(\Lambda) + \theta_1$, and $Q(\Lambda)$ projects onto the direct sum of all eigenspaces of $A_-(\Lambda)$ corresponding to eigenvalues $\nu$ with $\text{Re}(\nu) > \text{Re}(\mu(\Lambda) + \theta_1$. $P(\Lambda)$ and $Q(\Lambda)$ are analytic in $\Lambda$ for $|\Lambda| < \delta$, and from the definition of $\theta_1$, we have the estimates
\begin{align*}
\left|e^{(A_-(\Lambda) - \mu(\Lambda)I)x}P \right| &\leq C e^{\theta_1 x} && x \geq 0 \\
\left|e^{(A_-(\Lambda) - \mu(\Lambda)I)x}Q \right| &\leq C e^{\theta_1 x} && x \leq 0
\end{align*}
Note that $P(\Lambda) + Q(\Lambda) = I$. Define the map $T$ on $L^\infty(-\infty, -M]$ by
\begin{align*}
TV(x; \Lambda) &= V^-(\Lambda) 
+ \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}P\Theta(y; \Lambda) V(y; \Lambda) dy \\
&- \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}Q\Theta(y; \Lambda) V(y; \Lambda) dy
\end{align*}
Taking the absolute value of both sides, for $x \leq 0$
\begin{align*}
|TV(x; \Lambda)| &\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]}
\left( \int_{-\infty}^x e^{\theta_1 (x - y)} e^{\theta y} dy + \int_x^{-M} e^{\theta_1 (x - y)} e^{\theta y} dy \right) \\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \int_{-\infty}^M e^{(\theta - \theta_1) y} dy \\
&= \leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \frac{e^{-(\theta - \theta_1)M}}{\theta - \theta_1}\\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} e^{-(\theta - \theta_1)M} \\
&\leq |V^-(\Lambda)| + C ||V(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{-(\theta - \theta_1)M} \\
& < \infty
\end{align*}
Since the RHS is independent of $x$, we have $T: L^\infty(-\infty, -M] \rightarrow L^\infty(-\infty, -M]$. 

Next, we show $T$ is a contraction.
\begin{align*}
|TV_1(x; \Lambda) - TV_2(x; \Lambda)| &\leq C ||V_1(x; \Lambda) - V_2(x; \Lambda)||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \frac{e^{-(\theta - \theta_1)M}}{\theta - \theta_1}\\
\end{align*}
Since $e^{-(\theta - \theta_1)M} \rightarrow 0$ as $m \rightarrow \infty$, for sufficiently large $M$ we have 
\begin{align*}
|TV_1(x; \Lambda) - TV_2(x; \Lambda)|_{L^\infty(-\infty, -M]} &\leq \frac{1}{2} ||V_1(x; \Lambda) - V_2(x; \Lambda)||_{L^\infty(-\infty, -M]} 
\end{align*}
Thus the map $T$ is a contraction. Since $L^\infty(-\infty, -M]$ is a Banach space, by the Banach fixed point theorem, the map $T$ has a unique fixed point $V = TV$, i.e. we have a function $V \in L^\infty(-\infty, -M]$ such that 
\begin{align*}
V(x; \lambda) &= V^-(\Lambda) 
+ \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)x}P\Theta(y; \Lambda) V(y; \Lambda) dy 
- \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)x}Q\Theta(y; \Lambda) V(y; \Lambda) dy
\end{align*}

Differentiating this with respect to $x$, we obtain
\begin{align*}
V'(x; \Lambda) &= P\Theta(x; \Lambda) V(x; \Lambda) +
(A_-(\Lambda) - \mu(\Lambda)I) \int_{-\infty}^x e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}P\Theta(y; \Lambda) V(y; \Lambda) dy \\
&-(-Q\Theta(x; \Lambda) V(x; \Lambda))
-(A_-(\Lambda) - \mu(\Lambda)I) \int_x^{-M} e^{(A_-(\Lambda) - \mu(\Lambda)I)(x-y)}Q\Theta(y; \Lambda) V(y; \Lambda) dy \\
&= P\Theta(x; \Lambda) V(x; \Lambda) + Q\Theta(y; \Lambda) V(x; \Lambda) + (A_-(\Lambda) - \mu(\Lambda)I)(T V(x; \lambda) - V^-(\Lambda) ) \\
&= (P + Q)\Theta(x; \Lambda) V(x; \Lambda) + (A_-(\Lambda) - \mu(\Lambda)I)(V(x; \lambda) - V^-(\Lambda) ) \\
&= (A_-(\Lambda) - \mu(\Lambda)I)V(x; \lambda) + \Theta(x; \Lambda) V(x; \Lambda) - (A_-(\Lambda) - \mu(\Lambda)I)V^-(\Lambda) \\
&= (A_-(\Lambda) - \mu(\Lambda)I)V(x; \lambda) + \Theta(x; \Lambda) V(x; \Lambda)
\end{align*}
where we used the fact that $TV = V$ and $(A_-(\Lambda) - \mu(\Lambda)I)V^-(\Lambda) = 0$. Thus $V(x; \Lambda$ solves \eqref{VEVP}. Since $TV = V$, we let $V_1 = V$ and $V_2 = 0$ in the above to get the estimate
\begin{align*}
|V(x; \Lambda) - V^-(\Lambda)| &= |T(V(x; \Lambda)) - T(0)| \\
&\leq C ||V(x; \Lambda) - 0||_{L^\infty(-\infty, -M]} e^{\theta_1 x} \\
\end{align*}

Similarly, for sufficiently large $M$, we have
\begin{align*}
|V(x; \Lambda)| - |V^-(\Lambda)| &\leq | |V(x; \Lambda)| - |V^-(\Lambda)| | \\
&\leq |V(x; \Lambda) - V^-(\Lambda)| \\
&= |T(V(x; \Lambda)) - T(0)| \\
&\leq \frac{1}{2} ||V(x; \Lambda)||_{L^\infty(-\infty, -M]}
\end{align*}
thus it follows that
\begin{align*}
||V(x; \Lambda)||_{L^\infty(-\infty, -M]} \leq 2 |V^-(\Lambda)|
\end{align*}

Combining these, we have
\begin{align*}
|V(x; \Lambda) - V^-(\Lambda)| &\leq C e^{\tilde{\theta} x}|V^-(\Lambda)| \\
\end{align*}
from which we get
\begin{align*}
|V(x; \Lambda) = V^-(\Lambda) + \mathcal{O}( e^{\tilde{\theta} x}|V^-(\Lambda)| )\\
\end{align*}

Although $V(x; \Lambda)$ is only defined for $x \leq -M$, we extend $V(x; \Lambda)$ to all of $R^-$ using the evolution operator for the system.
\end{proof}
\end{lemma}

As a corollary to this, we state and prove the Conjugation Lemma, which allows us to make a smooth change of coordinates to convert the linear ODE $W'(x) = (x) W(x)$ into a constant coefficient system.

% Conjugation lemma
\begin{lemma}[Conjugation Lemma]
Let $W \in \C^N$, and consider the family of ODEs on $\R$
\begin{equation}\label{EVPconj}
W(x)' = A(x; \Lambda) W(x) + G(x)W(x) + F(x)
\end{equation}
where $\Lambda \in \Omega$ is a parameter vector and $\Omega$ is a Banach space. Take the same assumptions as in the Gap Lemma, i.e. 
\begin{enumerate}
	\item The map $\Lambda \mapsto A(\cdot; \Lambda)$ is analytic in $\Lambda$.
	\item $A(x; \Lambda) \rightarrow A_\pm(\lambda)$ (independent of $\Lambda$) as $x \rightarrow \pm \infty$, and there exists $\delta > 0$ such that for $|\Lambda| < \delta$ we have the uniform exponential decay estimates 
	\begin{align}
	\left| \frac{\partial^k}{\partial x^k} A(x; \Lambda) - A_\pm(\Lambda) \right| 
	&\leq C e^{-\theta |x|} && 0 \leq k \leq K
	\end{align}
	where $\alpha > 0$, $C > 0$, and $K$ is a nonnegative integer.
\end{enumerate}
Then in a neighborhood of any $\Lambda_0 \in \Omega$ there exist invertible linear transformations
\begin{equation}\label{conjlemmaP}
\begin{aligned}
P_+(x, \Lambda) &= I + \Theta_+(x, \Lambda) \\
P_-(x, \Lambda) &= I + \Theta_-(x, \Lambda) 
\end{aligned}
\end{equation}
defined on $\R^+$ and $\R^-$, respectively, such that
\begin{enumerate}[(i)]
\item The change of coordinates $W = P_\pm Z$ reduces \eqref{EVPconj} to the equations on $\R^\pm$
\begin{align}\label{conjZ}
Z'(x) = A^\pm(\Lambda) Z(x) + P_\pm(x, \Lambda)^{-1} G(x) P_\pm(x, \Lambda) + P_\pm(x, \Lambda)^{-1} F(x)
\end{align}

\item For any fixed $0 < \tilde{\theta} < \theta$, $0 \leq k \leq K+1$, and $j \geq 0$ we have the decay rates
\begin{align}\label{conjthetadecay}
\left| \partial_\Lambda^j \partial_x^k \Theta_\pm \right| \leq C(j, k)e^{-\tilde{\theta}|x|}
\end{align}
\end{enumerate}
\begin{proof}
We will prove this for the case where $F(x) = 0$ and $G(x) = 0$. The form of the conjugated system easily follows for general $F$ and $G$. We will also only consider the case on $\R^-$. The other case is similar. 

Let $W = P_-(x, \Lambda) Z$, where we will determine $P_-(x, \Lambda)$ later. Suppose that \cref{conjZ} is true. Substituting $W = P_-(x, \Lambda) Z$ into \eqref{EVPconj} and simplifying, we get
\begin{align*}
[P_-(x, \Lambda) Z(x)]' &= A(x; \Lambda)(P_-(x, \Lambda) Z(x)) \\
P_-'(x, \Lambda) Z(x) + P_-(x, \Lambda) Z'(x)
&= A(x; \Lambda)P_-(x, \Lambda) Z(x) \\
P_-'(x, \Lambda) Z(x) + P_-(x, \Lambda) A_-(\Lambda) Z(x)
&= A(x; \Lambda)P_-(x, \Lambda) Z(x)
\end{align*}
where we used \cref{conjZ} in the third line. Rearranging this, we obtain
\begin{equation*}
P_-'(x, \Lambda) Z(x)
= [A(x; \Lambda)P_-(x, \Lambda) - P_-(x, \Lambda) A_-(
\Lambda)]Z(x)
\end{equation*}
This suggests that $P_-(x, \Lambda)$ should satisfy the ODE
\begin{align}\label{Pprimecriterion}
P_-'(x, \Lambda) = A(x; \Lambda)P_-(x, \Lambda) - P_-(x, \Lambda) A_-(\Lambda)
\end{align}

Suppose that \cref{Pprimecriterion} is true. Substituting $W = P_-(x, \Lambda) Z$ and using \cref{Pprimecriterion}, equation \cref{EVPconj} reduces to
\begin{align*}
[P_-(x, \Lambda) Z(x)]' &= A(x; \Lambda)(P_-(x, \Lambda) Z(x)) \\
P_-'(x, \Lambda) Z(x) + P_-(x, \Lambda) Z'(x)
&= A(x; \Lambda)P_-(x, \Lambda) Z(x) \\
(A(x; \Lambda)P_-(x, \Lambda) - P_-(x, \Lambda) A_-)Z(x) + P_-(x, \Lambda) Z'(x)
&= A(x; \Lambda)P_-(x, \Lambda) Z(x) \\
A(x; \Lambda)P_-(x, \Lambda)Z(x) - P_-(x, \Lambda) A_- Z(x) + P_-(x, \Lambda) Z'(x)
&= A(x; \Lambda)P_-(x, \Lambda) Z(x) \\
P_-(x, \Lambda) Z'(x) &= P_-(x, \Lambda) A_- Z(x) 
\end{align*}
If $P_-(x, \Lambda)$ is invertible, then $Z'(x) = A_- Z(x)$.

Thus all that remains is to find an invertible operator $P_-(x, \Lambda)$ which satisfies \cref{Pprimecriterion}. Equation \cref{Pprimecriterion} has the form 
\begin{equation}\label{solvePminus}
P_-'(x, \Lambda) = \mathcal{A}(x; \Lambda) P_-(x, \Lambda)
\end{equation}
where $\mathcal{A}(x; \Lambda)$ is the linear operator
\[
\mathcal{A}(x; \Lambda) P = A(x; \Lambda) P - P A_-(\Lambda)
\]
By our assumptions on $A(x; \Lambda)$, $\mathcal{A} \rightarrow \mathcal{A}_-$ as $x \rightarrow -\infty$, where the limiting linear operator $\mathcal{A}_-$ is defined by
\[
\mathcal{A}_- P = A_-(\Lambda) P - P A_-(\Lambda)
\]
The limiting operator has analytic eigenvalue/eigenvector pair $0, I$ for all $\Lambda$, thus by the Gap Lemma, there exists a solution of \eqref{solvePminus} of the form 
\begin{equation*}
P_-(x, \Lambda) = I + \mathcal{O}(e^{-\tilde{\theta}|x|})
\end{equation*}
In other words, 
\begin{equation*}
P_-(x, \Lambda) = I + \Theta_-(x, \Lambda)
\end{equation*}
where 
\begin{equation}\label{Thetabound}
|\Theta_-(x, \Lambda)| \leq C e^{-\tilde{\theta}|x|}
\end{equation}
The $x$-derivative bound follow from the derivative bounds in the Gap Lemma, and the $\Lambda$-derivative bounds follow from standard analytic function theory.

Finally, we need to show that $P_-(x, \Lambda)$ is invertible for all $x \in \R^-$. Using \eqref{Thetabound}, we can find $M$ sufficiently large and negative such that for all $x \leq M$,
\[
|\Theta_-(x, \Lambda)| < 1/2
\]
It follows that $P_-(x, \Lambda)$ is invertible for $X \leq M$. To extend invertibility to all $x \in \R^-$, suppose that $P_-(x, \Lambda)^{-1}$ exists for all $x \in R^-$. Then, differentiating $P_-(x, \Lambda)^{-1} P_-(x, \Lambda) = I$ and solving for $[P_-(x, \Lambda)^{-1}]'$ (as in the proof of the inverse function theorem), we have (suppressing the dependence on $\Lambda$ for convenience)
\begin{align*}
(P_-^{-1})'(x) &= -P_-^{-1}(x)P_-'(x)P_-^{-1}(x) \\
&= -P_-^{-1}(x)( A(x)P_-(x) - P_-(x) A_-(\Lambda))P_-^{-1}(x) \\
&= A_-(\Lambda) P_-^{-1}(x) - A(x) P_-^{-1}(x)
\end{align*}
We have a solution to this ODE for $x \leq M$, and by variation of constants, this ODE has a unique solution for all $x \in \R^-$. Thus $P_-(x, \Lambda)^{-1}$ is obtained for all $x \in \R^-$ by evolving this ODE forward from an initial condition at some $x \leq M$. In this manner, we have shown that $P_-(x, \Lambda)^{-1}$ exists for all $x \in \R^-$.
\end{proof}
\end{lemma}

As a corollary, we find a conjugation operator for the adjoint equation.

\begin{corollary}\label{corr:adjconj}
Take the same hypotheses as in the conjugation lemma, and let $P_\pm(x; \Lambda)$ be the conjugation operators for $V(x)' = A(x; \Lambda) V(x)$ on $\R^\pm$. Then for the adjoint equation
\begin{equation}\label{conjadjW}
W'(x) = -A(x; \Lambda)^* W(x),
\end{equation}
the change of coordinates $W = (P_\pm^{-1})^* Z$ reduces \cref{conjadjW} to the equations
\begin{align}\label{ZconjW}
Z'(x) = -A^\pm(\Lambda)^* Z(x) 
\end{align}
on $\R^\pm$.
\begin{proof}
For convenience, let $Y(x) = W(x)^T$ and $S(x) = Z(x)^T$. Taking the transpose, equation \cref{conjadjW} is equivalent to
\begin{equation}\label{adjY}
Y'(x) = -Y(x)A^\pm(x; \Lambda) 
\end{equation}
As in the conjugation lemma, we will only consider the case on $\R^-$. By differentiating $P_-^{-1} P_- = I$, we have the relation
\begin{equation}\label{Pprimeinv}
[P_-^{-1}]' = -P_-^{-1} P_-' P_-^{-1}.
\end{equation}
Substitute $Y(x) = S(x) P^{-1}(x, \Lambda)$ into \cref{adjY}, which is equivalent to substituting $W(x) = [P^{-1}(x, \Lambda)]^* Z(x)$ into \cref{conjadjW}.
\begin{align*}
S'(x) P_-^{-1}(x, \Lambda) + S(x) P_-^{-1}(x, \Lambda)'
&= -S(x) P_-^{-1}(x, \Lambda) A(x, \Lambda)
\end{align*}
Using \cref{Pprimeinv}, this becomes
\begin{align*}
S'(x) P_-^{-1}(x, \Lambda) - S(x) P_-^{-1}(x, \Lambda) P_-'(x, \Lambda) P_-^{-1}(x, \Lambda)
&= -S(x) P_-^{-1}(x, \Lambda) A(x, \Lambda)
\end{align*}
Using \cref{Pprimecriterion} from the conjugation lemma, 
\begin{align*}
S'(x) P_-^{-1}(x, \Lambda) - S(x) P_-^{-1}(x, \Lambda) \left(A(x; \Lambda)P_-(x, \Lambda) - P_-(x, \Lambda) A_-(\Lambda)\right) P_-^{-1}(x, \Lambda)
&= -S(x) P_-^{-1}(x, \Lambda) A(x, \Lambda)
\end{align*}
which simplifies to
\begin{align*}
S'(x) P_-^{-1}(x, \Lambda) - S(x) P_-^{-1}(x, \Lambda) A(x; \Lambda) + S(x) A_-(\Lambda) P_-^{-1}(x, \Lambda)
&= -S(x) P_-^{-1}(x, \Lambda) A(x, \Lambda)
\end{align*}
The second term on the LHS cancels, leaving us with
\begin{align*}
S'(x) P_-^{-1}(x, \Lambda) &= -S(x) A_-(\Lambda) P_-^{-1}(x, \Lambda)
\end{align*}
Applying $P_-(x, \Lambda)$ on the right and taking the transpose, this becomes
\[
Z'(x) = -A_-(\Lambda)^* Z(x)
\]
\end{proof}
\end{corollary}

\section{Conjugation}\label{sec:conjugation}

Recall that the eigenvalue problem we wish to solve is given by
\begin{equation*}
U'(x) = A(Q_n(x); \lambda) U(x).
\end{equation*}
Since $Q_n(x)$ is a piecewise perturbation of the primary pulse $Q(x)$, we will first apply the conjugation lemma to the equation
\begin{equation}\label{vareqlambda}
U'(x) = A(Q(x); \lambda) U'(x).
\end{equation}
This will greatly simplify \cref{PDEeigsystemper4} by transforming the matrix $A(Q(x); \lambda)$ into the constant coefficient matrix $A(\lambda)$ via a smooth change of coordinates. For all $\lambda$, $A(Q(x); \lambda)$ decays exponentially to the constant-coefficient matrix $A(\lambda)$ with exponential decay rate
\[
|A(Q(x); \lambda) - A(\lambda)| \leq C e^{-\alpha_0 |x|}
\]

Let $\alpha$ be as chosen in \cref{sec:existdichot}, and recall that $\alpha$ is slightly less than $\alpha_0$. Using the conjugation lemma on $\R^+$ with $\Lambda = \lambda$ and $\Lambda_0 = 0$, there exists $\delta_2 > 0$ and an invertible linear transformation 
\[
P_+(x; \lambda) = I + \Theta_+(x; \Lambda)
\]
such that for all $|\lambda| < \delta_2$, the change of coordinates $U = P_+(x; \lambda) Z$ conjugates \eqref{vareqlambda} into the equation
\begin{align*}\label{Zplus1}
(Z_i^+)'(x) &= A(\lambda) Z(x) && x \in \R^+.
\end{align*}
By the conjugation lemma, the conjugation operator $P_+(x; \lambda)$ has the form
\begin{equation}\label{projTheta}
P_+(x; \lambda) = I + \Theta_+(x; \lambda),
\end{equation}
and $\Theta_+(x; \lambda)$ has the uniform decay rate
\begin{equation}\label{Thetadecay}
|\Theta_+(x; \lambda)| \leq C e^{-\alpha |x|}.
\end{equation}
These bounds also apply to derivatives with respect to $x$ and $\lambda$ (though with a different constant out front).

Rather than applying the conjugation lemma again on $\R^-$, we will use the symmetries of our system to define the conjugation operator on $\R^-$ in terms of the conjugation operator on $\R^+$. We do this in a series of lemmas. First we prove a symmetry relation for $A(Q(x); \lambda)$.

\begin{lemma}\label{AQxsymmetrylemma}
Let $R$ be the standard reversor operator. Then
\begin{enumerate}[(i)]
\item $A(Q(x); \lambda) = -R A(Q(-x); -\lambda)R$
\item If $U(x)$ is a solution to $U'(x) = U(Q(x); \lambda) U(x)$ on $\R^+$, then $R U(-x)$ is a solution to $U'(x) = A(Q(x); -\lambda) U(x)$ on $\R^-$.
\end{enumerate}
\begin{proof}
Since we will be dealing with reversor operators on two difference spaces, let $R_{n}$ be the matrix for the standard reversor operator on $\R^n$. For part (i), using the symmetry relations $DF(RU) = -RDF(U)R$ and $Q(-x) = RQ(X)$, we have
\begin{align*}
-R_{2m+1} &A(Q(-x); -\lambda) R_{2m+1}
= \begin{pmatrix}-R_{2m} & 0 \\ 0 & -1 \end{pmatrix} 
\begin{pmatrix}
DF(Q(-x)) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} -\lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \begin{pmatrix}R_{2m} & 0 \\ 0 & 1 \end{pmatrix} \\
&= \begin{pmatrix}
-R_{2m} DF(Q(-x)) R_{2m} & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} 
= \begin{pmatrix}
DF(R_{2m}(Q(-x))) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \\
&= \begin{pmatrix}
DF(Q(x)) & \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \\
\begin{pmatrix} \lambda & 0 & \dots & 0 \end{pmatrix} & 0
\end{pmatrix} \\ 
&= A(Q(x); \lambda)
\end{align*}
For part (ii), for $x \in \R^-$,
\begin{align*}
\frac{d}{dx} &\left[ R_{2m+1} U(-x) \right] = -R_{2m+1} U'(-x) \\
&= -R_{2m+1} A(Q(-x); \lambda) U(-x) \\
&= -R_{2m+1} A(Q(-x); \lambda) R_{2m+1} [ R_{2m+1} U(-x)] \\
&= A(Q(x); -\lambda) [R_{2m+1} U(-x)]
\end{align*}
\end{proof}
\end{lemma}

In the next lemma, we define the conjugation operator on $\R^-$ in terms of the conjugation operator on $\R^+$.

\begin{lemma}\label{conjRminuslemma}
For $x \in \R^-$ and $|\lambda| < \delta_1$, define $P_-(x; \lambda)$ by
\begin{equation}\label{defPminus}
P_-(x; \lambda) = RP_+(-x; -\lambda)R
\end{equation}
Then the substitution $U(x) = P_-(x; \lambda) Z(x)$ conjugates the ODE 
\begin{equation}\label{Veqminus}
U'(x) = A(Q(x); \lambda) U(x)
\end{equation}
into the constant-coefficient ODE 
\begin{equation}\label{Zeqminus}
Z'(x) = A(\lambda)Z(x).
\end{equation}
\begin{proof}
We substitute $U(x) = P_-(x; \lambda) Z(x)$ into \eqref{Veqminus}. For the LHS of \eqref{Veqminus}, we have
\begin{align}\label{PminusLHS}
\frac{d}{dx}[P_-(x; \lambda) Z(x)] &= \frac{d}{dx}[RP_+(-x; -\lambda)R Z(x)] = -RP'_+(-x; -\lambda)R Z(x) + RP_+(-x; -\lambda)R Z'(x)
\end{align}
For the RHS of \eqref{Veqminus}, using part (i) of Lemma \ref{AQxsymmetrylemma} and $R^2 = I$,
\begin{align*}
A(Q(x); \lambda)P_-(x; \lambda) Z(x) &= A(Q(x); \lambda)RP_+(-x; -\lambda)R Z(x) \\
&= -R[ -R A(Q(x); \lambda)R ]P_+(-x; -\lambda)R Z(x) 
\end{align*}
which simplifies to
\begin{align}\label{Zeqminus1}
A(Q(x); \lambda)P_-(x; \lambda) Z(x) &= -R A(Q(-x); -\lambda) P_+(-x; -\lambda)R Z(x). 
\end{align}
From the proof of the conjugation lemma,
\begin{align*}
P'_+(x; \lambda) = A(Q(x); \lambda)P_+(x; \lambda) - P_+(x; \lambda) A(\lambda)
\end{align*}
Rearranging this and evaluating it at $-x$ and $-\lambda$, 
\begin{align*}
 A(Q(-x); -\lambda)P_+(-x; -\lambda) = P'_+(-x; -\lambda) + P_+(-x; -\lambda) A(-\lambda)
\end{align*}
Substituting this into \eqref{Zeqminus1}, we have
\begin{align*}
A(Q(x); \lambda)&P_-(x; \lambda) Z(x) = -R [ P'_+(-x; -\lambda) + P_+(-x; -\lambda) A(-\lambda) ] R Z(x) \\
&= -R P'_+(-x; -\lambda) R Z(x) - R P_+(-x; -\lambda) R [ R A(-\lambda) R]Z(x)
\end{align*}
Using $-R A(-\lambda) R = A(\lambda)$, which we show either by direct computation or by taking $x \rightarrow \infty$ in part (i) of Lemma \ref{AQxsymmetrylemma},
\begin{align}\label{PminusRHS}
A(Q(x); \lambda)&P_-(x; \lambda) Z(x) =  -R P'_+(-x; -\lambda) R Z(x) + R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align}
Equating \cref{PminusLHS} and \cref{PminusRHS},
\begin{align*}
-RP'_+(-x; -\lambda)&R Z(x) + RP_+(-x; -\lambda)R Z'(x) \\
&= -R P'_+(-x; -\lambda) R Z(x) + R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align*}
which simplifies to
\begin{align*}
RP_+(-x; -\lambda)R Z'(x) = R P_+(-x; -\lambda) R A(\lambda) Z(x)
\end{align*}
Since $R$ and $P_+(-x; -\lambda)$ are invertible, this finally reduces to 
\begin{align*}
Z'(x) = A(\lambda) Z(x)
\end{align*}
which is the equation we want.
\end{proof}
\end{lemma}

\section{Exponential trichotomy}

Since $A(\lambda)$ is a constant coefficient matrix, we know exactly how solutions $Z' = A(\lambda)Z$ evolve. Let $E^{u/s/c}(0)$ be the stable, unstable, and center eigenspaces of $A(0)$. $E^s(0)$ and $E^u(0)$ are $m$-dimensional, and $E^c(0)$ is 1-dimensional. For $|\lambda| < \delta$, let $E^{u/s/c}(\lambda)$ be the corresponding eigenspaces of $A(\lambda)$, which have the same dimensions as $E^{u/s/c}(0)$ since $\lambda$ is small. In particular, 
\[
E^c(\lambda) = \spn\{ V_0(\lambda) \},
\]
where $V_0(\lambda)$ is defined in Lemma \ref{nulambdalemma}. Although $E^c(\lambda)$ is not a true center eigenspace if $\Re \nu(\lambda) \neq 0$, we retain this notation for convenience. Let $P^{u/s/c}(\lambda)$ be eigenprojections for the eigenspaces $E^{u/s/c}(\lambda)$. These are smooth in $\lambda$. 

Next, we set up an exponential trichotomy for this system. Let
\begin{equation}
\Phi(x, y; \lambda) = e^{A(\lambda)(x-y)}
\end{equation}
be the evolution of the constant-coefficient ODE
\[
Z' = A(\lambda) Z
\]
and let $\Phi^{u/s/c}(x, y; \lambda) = \Phi(x, y; \lambda)P^{u/s/c}(\lambda)$ be the evolutions on the respective eigenspaces. For $|\lambda| < \delta$, $|\nu(\lambda)| < \eta$, and we have 
\begin{equation}\label{Zevolbounds}
\begin{aligned}
|\Phi^s(x, y; \lambda)| &\leq C e^{-\tilde{\alpha}(x - y)} \\
|\Phi^u(x, y; \lambda)| &\leq C e^{-\tilde{\alpha}(y - x)} \\
|\Phi^c(x, y; \lambda)| &\leq C e^{\tilde{\alpha}|x - y|} 
\end{aligned}
\end{equation}
This is an exponential trichotomy on $\R$. Since $E^c(\lambda)$ is one-dimensional, the center evolution $\Phi^c(x, y; \lambda)$ is given by
\begin{align}\label{centerevol}
\Phi^c(x, y; \lambda) V &= e^{\nu(\lambda)(x - y)} P^c(\lambda)V
\end{align}

We relate the evolution of the conjugated system to that of the original system in the following way. Recall that the variational equation is the linearization about the primary pulse $Q(x)$:
\begin{align}\label{vareqstab}
V'(x) &= A(Q(x); 0) V(x)
\end{align}
Let $\tilde{\Phi}(y, x)$ be the evolution operator for the variational equation. The conjugation lemma gives the following relationship between $\tilde{\Phi}(y, x)$ and $\Phi(y, x; 0)$.
\begin{align*}
\tilde{\Phi}(y, x) &= P_+(y; 0) \Phi(y, x; 0) P_+(x; 0)^{-1} && x, y \geq 0 \\
\tilde{\Phi}(y, x) &= P_-(y; 0) \Phi(y, x; 0) P_-(x; 0)^{-1} && x, y \leq 0
\end{align*}

Using the exponential trichotomy for the conjugated system, the conjugation operator induces exponential trichotomies on $\R^\pm$ for the variational equation. The stable, unstable, and center projections for this trichotomy are given by
\begin{equation}\label{trichotomyprojunconj}
\tilde{P}^{s/u/c}_\pm(x) = P_\pm(x; 0) P^{s/u/c}(0) P_\pm(x, 0)^{-1}
\end{equation}
The center subspaces on $\R^+$ and $\R^-$ are both one-dimensional and are given by $\C V^c(x)$. 

In the next section, we will derive an expression for the center projections $\tilde{P}^c_\pm(x)$. From \cref{trichotomyprojunconj},
\begin{align*}
\tilde{P}^c_\pm(x) u &= P_\pm(x; 0) P^c(0) P_\pm(x, 0)^{-1} u \\
&= P_\pm(x; 0) \langle W_0, P_\pm(x, 0)^{-1} u \rangle V_0 \\
&= \langle W_0, P_\pm(x, 0)^{-1} u \rangle P_\pm(x; 0) V_0,
\end{align*}
thus we have
\begin{align}\label{centerproj1}
\tilde{P}^c_\pm(x) u 
&= \langle W_0, P_\pm(x, 0)^{-1} u \rangle V^c(x)
\end{align}
Since $\Psi^c(x) = W_0$ is a constant solution to the adjoint variational equation, we have a simpler form for the center projection for the variational equation. 

\begin{lemma}\label{centerprojlemma}
For the trichotomies of \cref{vareqstab} on $\R^\pm$, the center projection is given by 
\begin{align}\label{centerproj}
\tilde{P}^c_\pm(x) U &= \langle W_0, U \rangle V^c(x)
\end{align}
\begin{proof}
From \cref{corr:adjconj}, $[P_\pm(x, 0)^{-1}]^*$ is the conjugation operator for the adjoint variational equation. In particular, this implies that $[P_\pm(x, 0)^{-1}]^* W_0$ is a solution to the adjoint variational equation. Since $[P_\pm(x, 0)^{-1}]^* \rightarrow I$ as $x \rightarrow \pm \infty$, 
\[
[P_\pm(x, 0)^{-1}]^* W_0 \rightarrow W_0 \text{ as }x \rightarrow \pm \infty
\]
By \cref{varadjsolutions}, the constant solution $\Psi^c(x) = W_0$ is the unique bounded solution to the adjoint variational equation which decays to $W_0$ (constant multiples will decay to something else). Thus we conclude that $[P_\pm(x, 0)^{-1}]^* W_0 = W_0$. Using this with \cref{centerproj1},
\begin{align*}
\tilde{P}^c_\pm(x) u 
&= \langle W_0, P_\pm(x, 0)^{-1} u \rangle V^c(x) \\
&= \langle [P_\pm(x, 0)^{-1}]^*W_0, u \rangle V^c(x) \\
&= \langle W_0, u \rangle V^c(x) 
\end{align*}
\end{proof}
\end{lemma}

In the next lemma, we derive a useful result concerning the adjoint of the trichotomy projections at $x = 0$.

\begin{lemma}\label{lemma:trichadjoint}
For the trichotomy projections $\tilde{P}_+^u(0)$ and $\tilde{P}_-^s(0)$, we have
\begin{equation}
\begin{aligned}
\tilde{P}_+^u(0)^* \Psi(0) &= \Psi(0) \\
\tilde{P}_-^s(0)^* \Psi(0) &= \Psi(0)
\end{aligned}
\end{equation}
\begin{proof}
Since
\begin{align*}
\ker \tilde{P}_+^u(0)^* &\perp \ran \tilde{P}_+^u(0) \\
\ran \tilde{P}_+^u(0)^* &\perp \ker \tilde{P}_+^u(0)
\end{align*}
and $\ker \tilde{P}_+^u(0) = T_{Q(0)} W^s(0) \oplus T_{Q(0)} W^c(0)$, $\tilde{P}_+^u(0)^*$ acts as the identity on $(T_{Q(0)} W^s(0) \oplus T_{Q(0)} W^c(0))^\perp$. Since $\Psi(0) \perp T_{Q(0)} W^s(0)$, $\Psi(0) \in \ran \tilde{P}_+^u(0)^*$, $\tilde{P}_+^u(0)^* \Psi(0) = \Psi(0)$. The result for $\tilde{P}_-^s(0)^*$ is similar.
\end{proof}
\end{lemma}

To conclude this section, we use use \cref{centerprojlemma} to derive several expansions which will be useful later.

\begin{lemma}\label{W0projlemma}
For all $U \in \R^{2m+1}$, we have the following.
\begin{enumerate}[(i)]
	\item $\langle W_0, P_\pm(x, 0) P^{s/u}(0) U \rangle = 0$
	\item $\langle W_0, \Theta_\pm(x, 0) P^{s/u}(0) U \rangle = 0$
	\item $\langle W_0(\lambda), \Theta_\pm(x, \lambda) P^{s/u}(\lambda) U \rangle  = \mathcal{O}(|\lambda|( e^{-\alpha |x|} + |\lambda|)|U|)$
	\item $\langle W_0, P_\pm(0; \lambda) P^{s/u}(0) U \rangle = \mathcal{O}(|\lambda||U|)$
	\item $P^c(0) G_i^\pm(x) U = \langle W_0, G_i^\pm(x) U\rangle = 0$
\end{enumerate}
where $P_\pm(x; \lambda) = I + \Theta_\pm(x, \lambda)$ are the conjugation operators and $P^{s/u}(\lambda)$ are the eigenprojections for $E^{s/u}(\lambda)$.
\begin{proof}
By Lemma \ref{centerprojlemma}, $\tilde{P}_\pm^c(x)U = \langle W_0, U \rangle V^c(x)$, thus $\langle W_0, U \rangle = 0$ for all $U$ in the range of the stable and unstable projections of the trichotomy for \cref{vareqstab}. These ranges are given by $P_\pm(x, 0) E^{s/u}(0)$. This proves (i). For (ii), 
\begin{align*}
\langle W_0, \Theta_\pm(x, 0) P^{s/u}(0) U\rangle &=
\langle W_0, (I - P_\pm(x, 0)) P^{s/u}(0) U\rangle \\
&= \langle W_0, P^{s/u}(0) U \rangle - \langle P_\pm(x, 0)P^{s/u}(0) U \rangle \\
&= 0
\end{align*}
by part (i) and the fact that $\langle W_0, \cdot \rangle$ is the projection on $E^c(0)$. For (iii), since the eigenprojections $P^{s/u}(\lambda)$ are matrices which are smooth in $\lambda$, we can expand them in a Taylor series about $\lambda = 0$ to get 
\[
P^{s/u}(\lambda) = P^{s/u}(0) + \mathcal{O}(\lambda).
\] 
Using the Taylor series for $W_0(\lambda)$ from \cref{nulambdalemma} and the decay rates \cref{Thetadecay} for the conjugation operators,
\begin{align*}
\langle &W_0(\lambda), \Theta_\pm(x; \lambda) P^{s/u}(\lambda) U \rangle = \langle W_0 + \mathcal{O}(\overline{\lambda}), \Theta_\pm(x; 0) + \mathcal{O}(e^{-\alpha |x|}|\lambda|))(P^{s/u}(0) + \mathcal{O}(\lambda)) U \rangle \\
&= \langle W_0, (I + \Theta_\pm(x, 0))P^{s/u}(0)U \rangle +
\mathcal{O}(|\lambda||U|) \\
&= \langle W_0, P_\pm(x, 0)P^{s/u}(0)U \rangle +
\mathcal{O}(|\lambda|( e^{-\alpha |x|} + |\lambda|)|U|)\\
&= \mathcal{O}(|\lambda|( e^{-\alpha |x|} + |\lambda|)|U|) \\
\end{align*}
where for the last equality we used part (ii). For (iv), we expand the conjugation operators in $\lambda$ to get
\begin{align*}
\langle W_0, &P_\pm(0; \lambda)P^{s/u}(\lambda) U \rangle =
\langle W_0, (P_\pm(0; 0) + \mathcal{O}(|\lambda|))(P^{s/u}(0) + \mathcal{O}(|\lambda|)) U) \\
&= \langle W_0, P_\pm(0; 0) P^{s/u}(0)U \rangle + \mathcal{O}(|\lambda||U|) \\
&= \langle W_0, \tilde{P}_\pm(0) U \rangle + \mathcal{O}(|\lambda||U|) \\
&= \mathcal{O}(|\lambda||U|) 
\end{align*}
where in the last line we used Lemma \ref{centerprojlemma}. For (v), since the bottom row of $G_i^\pm(x)$ is all zeros, the last component of $G_i^\pm(x) U$ is 0 for all $U$. It follows that $\langle W_0, G_i^\pm(x) U\rangle = 0$. 
\end{proof}
\end{lemma}

\section{Solutions in center subspace}

The constant-coefficient ODE
\[
Z(x)' = A(\lambda)Z(x)
\]
has a solution $Z(x) = V_0(\lambda)e^{\nu(\lambda)x}$. In this section, we show that the ODE
\[
V(x)' = A(Q(x); \lambda)V(x)
\]
has solutions $V^\pm(x; \lambda)$ on $\R^+$ and $\R^-$ which approach $V_0(\lambda)e^{\nu(\lambda)x}$ as $x \rightarrow \pm \infty$. We then characterize these solutions and their derivatives with respect to $\lambda$. First, we show that the solutions $V^\pm(x; \lambda)$ exist.

\begin{lemma}\label{lemma:Vpm}
For sufficiently small $|\lambda|$, the equation $V' = A(Q_n(x); \lambda)V$ has solutions $V^\pm(x; \lambda)$ on $\R^\pm$ which are given by
\begin{align}\label{Vpmlambda}
V^\pm(x; \lambda) &= e^{\nu(\lambda)x}(V_0(\lambda) + V_1^\pm(x; \lambda)),
\end{align}
where
\begin{equation}\label{Vpmdecay}
|V_1^\pm(x; \lambda)| \leq C e^{-\alpha |x|}
\end{equation}
and we have the symmetry relationship
\begin{equation}\label{Vpmsymmetry}
V^-(x; \lambda) = R V^+(-x; -\lambda).
\end{equation}
\begin{proof}
Let $Z(x) = e^{\nu(\lambda)x}V_0(\lambda)$, which is a solution to $Z'(x) = A(\lambda)Z$ contained in the center subspace $E^c(\lambda)$. Let
\[
V^+(x; \lambda) = P_+(x; \lambda) Z(x) = e^{\nu(\lambda)x}P_+(x; \lambda)V_0(\lambda).
\]
By the expansion \eqref{conjlemmaP} from the Conjugation Lemma,
\begin{align*}
V^+(x; \lambda) &= e^{\nu(\lambda)x}(I + \Theta_+(x; \lambda))V_0(\lambda) \\
&= e^{\nu(\lambda)x}( V_0(\lambda) + V_1^+(x; \lambda)),
\end{align*}
where $V_1^+(x; \lambda) = \Theta_+(x; \lambda) V_0(\lambda)$. This is \eqref{Vpmlambda}, and the decay result \eqref{Vpmdecay} comes from the conjugation lemma. Similarly, we define 
\begin{align*}
V^-(x; \lambda) &= P_-(x; \lambda) Z(x) \\
&= RP_+(-x; -\lambda)R e^{\nu(\lambda)x} V_0(\lambda) \\
&= e^{\nu(\lambda)x} R(I + \Theta_+(-x; -\lambda))R V_0(\lambda) \\
&= e^{\nu(\lambda)x}( V_0(\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) )
\end{align*}
Letting $V_1^-(x; \lambda) = R\Theta_+(-x; -\lambda) V_0(-\lambda)$, we have
\begin{align*}
V^-(x; \lambda) &= e^{\nu(\lambda)x}( V_0(\lambda) + V_1^-(x; \lambda))
\end{align*}
For the symmetry relation, using Lemma \ref{nulambdalemma}, we also have
\begin{align*}
V^-(x; \lambda) &= e^{\nu(\lambda)x}( V_0(\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= e^{\nu(\lambda)x}( R V_0(-\lambda) + R\Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R e^{-\nu(\lambda)(-x)}( V_0(-\lambda) + \Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R e^{\nu(-\lambda)(-x)}( V_0(-\lambda) + \Theta_+(-x; -\lambda) V_0(-\lambda) ) \\
&= R V^+(-x; -\lambda)
\end{align*}
\end{proof}
\end{lemma}

We now use this result to prove the existence of $V^c(x)$ in part (i) of Lemma \ref{varadjsolutions}. It then follows that $V^\pm(x; 0) = V^c(x)$.

\begin{lemma}\label{lemma:Vcexists}
There exists a solution $V^c(x)$ to \eqref{vareq2} which is given by
\[
V^c(x) = V_0 + V^c_1(x)
\]
where $V^c_1(x) = \mathcal{O}(e^{-\alpha |x|})$. In particular $V^c(x) \rightarrow V_0$ as $|x| \rightarrow \infty$. $V^c$ is symmetric with respect to the standard reversor operator $R$, i.e. $V^c(-x) = R V^c(x)$. Finally, $V^c(x) = V^\pm(x; 0)$, where $V^\pm(x; 0)$ is defined in \cref{lemma:Vpm}. 

\begin{proof}
We employ the following dimension counting argument. Recall that $\dim W^{s/u}(0) = m$ and $\dim W^c(0) = 1$, thus $\dim W^{cs}(0) = m + 1$, and $\dim W^{cu}(0) = m + 1$. $\Psi(0) \perp T_{Q(0)}W^{cs}(0) + T_{Q(0)}W^{cu}(0)$, so $\dim T_{Q(0)}W^{cs}(0) + T_{Q(0)}W^{cu}(0) \leq 2m$. By counting dimensions, this implies that $\dim T_{Q(0)}W^{cs}(0) \cap T_{Q(0)}W^{cu}(0) = 2$. Since $\dim T_{Q(0)}W^s(0) \cap T_{Q(0)}W^s(0) = 1$ by Lemma \ref{nondegenlemma}, we conclude that there exists $Y_0 \in T_{Q(0)}W^{cs}(0) \cap T_{Q(0)}W^{cu}(0)$ which is linearly independent from $Q'(0)$, and $Y^0 \notin T_{Q(0)}W^s(0) \cap T_{Q(0)}W^s(0)$.

Using \cref{lemma:Vpm}, let
\[
V^\pm(x) = V^\pm(x; 0) = V_0 + V_1^\pm(x)
\]
where $V_1^\pm(x) = \mathcal{O}(e^{-\alpha |x|})$. From the construction in \cref{lemma:Vpm},
\[
V^\pm(x) = P_\pm(x; 0) V_0,
\]
and we also have the symmetry relation $V^-(x) = R V^+(-x)$. We will show that $V^+(0) = V^-(0)$.

By the trichotomy for the variational equation, at $x = 0$ there is a one-dimensional center subspace for $\R^+$ and a one-dimensional center subspace for $\R^-$. By the dimension counting argument above, both of the center subspaces must be spanned by $Y^0$, thus they are the same subspace. Using the projections \eqref{trichotomyprojunconj}, $V^\pm(0)$ are in these center subspaces, thus $V^\pm(0) \in \Span \{Y^0 \}$. In particular, this implies that $V^+(0)$ and $V^-(0)$ are scalar multiples of each other. 

From Lemma \ref{varadjsolutions}, $\Psi^c(x) = W_0$ is a solution to the adjoint variational equation on $\R$. By Lemma \ref{eigadjoint}(i), the inner product $\langle W_0, V^\pm(x) \rangle$ is constant in $x$. Sending $x \rightarrow \pm \infty$ and recalling that $V_0 = (1/c, 0, \dots, 0, 1)^T $ and $W_0 = (0, \dots, 0, 1)^T$,
\[
\langle W_0, V^+(0) \rangle = \langle W_0, V^-(0) \rangle
= \langle W_0, V(0) \rangle = 1
\]
This implies that the last component of $V^+(0)$ and $V^-(0)$ is 1. Since $V^+(0)$ and $V^-(0)$ are scalar multiples of each other, they must in fact be equal. Let
\[
V^c(x) = \begin{cases}
V^+(x) & x \geq 0 \\
V^-(-x) & x \leq 0 
\end{cases}
\]
which is well-defined since $V^+(0) = V^-(0)$. $V^c(x)$ has the properties stated in the lemma.
\end{proof}
\end{lemma}

In the next lemma, we characterize the derivative of $V^\pm(x; \lambda)$ with respect to $\lambda$.

\begin{lemma}\label{lemma:Vpmderiv}
The derivative $\partial_\lambda V^+(x; 0)$ satisfies the equation
\begin{align}\label{Vderivsolves}
Y'(x) &= A(Q(x)) Y(x) + B V^c(x) && x \in \R^+,
\end{align}
and $\partial_\lambda V^-(x; 0) = -R \partial_\lambda V^+(-x, 0)$. Let 
\begin{equation}\label{deftildeV}
V^+(x; \lambda) = e^{\nu(\lambda)x}\tilde{V}^+(x; \lambda).
\end{equation}
Then $\partial_\lambda \tilde{V}(x,0) \rightarrow V_0'(0)$ as $x \rightarrow \infty$ and
\begin{equation}\label{VtildeVderiv}
\partial_\lambda V^+(x; 0)
= \partial_\lambda \tilde{V}^+(x; 0) + \frac{1}{c} x V^c(x) 
\end{equation}
In addition, $\partial_\lambda \tilde{V}^+(x; 0)$ satisfies the equation
\begin{align}\label{tildeVderivsolves}
Y'(x) &= A(Q(x)) Y(x) + \left( B - \frac{1}{c}I \right) V^c(x) && x \in \R^+.
\end{align}
and $\partial_\lambda \tilde{V}^-(x; 0) = -R \partial_\lambda \tilde{V}^+(-x, 0)$.

\begin{proof}
We only need to do this for $V^+(x; \lambda)$ since the result for $V^-(x; \lambda)$ follows by symmetry. Recall that $V^+(x; \lambda)$ solves the equation
\begin{equation}\label{Vplussolves1}
V^+(x; \lambda)' = A(Q(x); \lambda) V^+(x; \lambda)
\end{equation}
Taking the derivative of both sides with respect to $\lambda$, we have
\begin{align*}
[\partial_\lambda V^+(x; \lambda)]' 
&= A(Q(x); \lambda) \partial_\lambda V^+(x; \lambda) + [\partial_\lambda A(Q(x); \lambda)] V^+(x; \lambda) \\
&= A(Q(x); \lambda) \partial_\lambda V^+(x; \lambda) + B V^+(x; \lambda)
\end{align*}
At $\lambda = 0$, this becomes
\[
[\partial_\lambda V^+(x; 0)]' = A(Q(x)) \partial_\lambda V^+(x; 0) + B V^c(x),
\]
thus $\partial_\lambda V^+(x; 0)$ solves \cref{Vderivsolves}. For the symmetry relationship, we have
\begin{align*}
\partial_\lambda V^-(x; \lambda) &= \frac{\partial}{\partial_\lambda}\left[ R V^+(-x, -\lambda)\right] \\
&= -R \partial_\lambda V^+(-x, -\lambda)
\end{align*}
At $\lambda = 0$, this is
\begin{align*}
\partial_\lambda V^-(x; 0) 
&= -R \partial_\lambda V^+(-x, 0)
\end{align*}

Define $\tilde{V}^+(x, \lambda)$ by \cref{deftildeV}. From \cref{deftildeV} and \cref{Vpmlambda}, $\tilde{V}^+(x, \lambda) \rightarrow V_0(\lambda)$ as $x \rightarrow \infty$, thus $\partial_\lambda \tilde{V}^+(x, 0) \rightarrow V_0'(0)$ as $x \rightarrow \infty$. Using \cref{deftildeV} and taking the derivative with respect to $\lambda$,
\begin{align*}
\partial_\lambda V^+(x; \lambda)
&= e^{\nu(\lambda)x} \partial_\lambda \tilde{V}^+(x; \lambda) + \nu'(\lambda)x \tilde{V}^+(x; \lambda)
\end{align*}
Taking $\lambda = 0$ and noting that $\tilde{V}^+(x; 0) = V^c(x)$ and $\nu'(0) = 1/c$, we obtain \cref{VtildeVderiv}. Finally, plug in \cref{deftildeV} to \cref{Vplussolves1} to get
\begin{align*}
e^{\nu(\lambda)x} [\tilde{V}^+(x; \lambda)]' + \nu(\lambda) e^{\nu(\lambda)x} \tilde{V}^+(x; \lambda) &= 
A(Q(x); \lambda) e^{\nu(\lambda)x} \tilde{V}^+(x; \lambda)
\end{align*}
which simplifies to
\begin{align*}
[\tilde{V}^+(x; \lambda)]' &= 
[A(Q(x); \lambda) - \nu(\lambda) I ] \tilde{V}^+(x; \lambda)
\end{align*}
Taking the derivative of this with respect to $\lambda$,
\begin{align*}
[\partial_\lambda \tilde{V}^+(x; \lambda)]' &= 
[A(Q(x); \lambda) - \nu(\lambda) I ] \partial_\lambda \tilde{V}^+(x; \lambda) + \partial_\lambda [A(Q(x); \lambda) - \nu(\lambda) I ]\tilde{V}^+(x; \lambda) \\
&= [A(Q(x); \lambda) - \nu(\lambda) I ] \partial_\lambda \tilde{V}^+(x; \lambda) + [B - \nu'(\lambda)I]\tilde{V}^+(x; \lambda) 
\end{align*}
At $\lambda = 0$, this becomes
\begin{align*}
[\partial_\lambda \tilde{V}^+(0; \lambda)]' &= A(Q(x))\partial_\lambda \tilde{V}^+(x; \lambda) + \left( B - \frac{1}{c}I\right) V^c(x),
\end{align*}
thus $\partial_\lambda \tilde{V}^+(x; \lambda)$ solves \cref{tildeVderivsolves}. The symmetry relationship for $\partial_\lambda \tilde{V}^-(0; \lambda)$ is the same as for $\partial_\lambda V^-(0; \lambda)$
\end{proof}
\end{lemma}

In the next lemma, we evaluate two important inner products involving $\partial_\lambda \tilde{V}^+(x; 0)$ which will appear in our analysis.

\begin{lemma}\label{lemma:VderivIPs}
We have the following inner products involving $\partial_\lambda \tilde{V}^+(0; 0)$. 
\begin{enumerate}[(i)]
\item
$
\begin{aligned}[t]
\langle W_0, \partial_\lambda \tilde{V}^+(0; 0) \rangle
= -\frac{1}{2} \tilde{M}
\end{aligned}
$
where
\begin{align}\label{defMtilde}
\tilde{M} = \int_{-\infty}^{\infty} \left(v^c(y) - \frac{1}{c}\right) dy,
\end{align}
which is finite.
\item 
$
\begin{aligned}
\langle \Psi(0), \partial_\lambda \tilde{V}^+(0; 0) \rangle = -\frac{1}{2} M^c
\end{aligned}
$,
where $M^c$ is the center Melnikov-type integral
\begin{equation}\label{defMc}
M^c = \int_{-\infty}^\infty q(y) v^c(y) dy
\end{equation}
with $q(y)$ the first component of $Q(y)$ and $v^c(y)$ the first component of $V^c(y)$.

\end{enumerate}
\begin{proof}
For convenience, let $Y(x) = \partial_\lambda \tilde{V}^+(x; 0)$. By Lemma \ref{lemma:Vpmderiv}, $Y(x)$ solves equation \cref{tildeVderivsolves}. Using the variation of constants formula and the exponential trichotomy projections \cref{trichotomyprojunconj}, we can formally write $Y(x)$ in integrated form as
\begin{equation}\label{Yintform}
\begin{aligned}
Y(x) &= \tilde{\Phi}^s_+(x,0)\tilde{P}^s_+(0) Y(0) 
+ \int_0^x \tilde{\Phi}^s(x,y)\left( B - \frac{1}{c}I \right) V^c(y) dy \\
&+ \int_{\infty}^x \tilde{\Phi}^u(x,y)\left( B - \frac{1}{c}I \right) V^c(y) dy + \int_{\infty}^x \tilde{\Phi}^c(x,y)\left( B - \frac{1}{c}I \right) V^c(y) dy 
\end{aligned}
\end{equation}
Since $Y(x) = \partial_\lambda \tilde{V}^+(x, 0) \rightarrow V_0'(0)$ as $x \rightarrow \infty$ and $\langle W_0, V_0'(0) \rangle = 0$, we can integrate in from infinity on the center subspace. Using \cref{centerprojlemma}, this becomes
\begin{equation}\label{Yintegform}
\begin{aligned}
Y(x) &= \tilde{\Phi}^s_+(x,0)\tilde{P}^s_+(0) Y(0) 
+ \int_0^x \tilde{\Phi}^s(x,y)\left( B - \frac{1}{c}I \right) V^c(y) dy \\
&+ \int_{\infty}^x \tilde{\Phi}^u(x,y)\left( B - \frac{1}{c}I \right) V^c(y) dy + V^c(x) \int_{\infty}^x \langle W_0, \left( B - \frac{1}{c}I \right) V^c(y) \rangle dy 
\end{aligned}
\end{equation}
In order to prove that \cref{Yintform} is a valid expression for $Y(x)$, we need to show that the integrals converge for all $x$. The convergence of the first and second integrals is straightforward since $V^c(x)$ is bounded and we have exponentially decaying estimates for $\tilde{\Phi}^s(x,y)$ and $\tilde{\Phi}^u(x,y)$ for the direction in which we are integrating. Thus it remains to check the third integral. Let 
\[
V^c(x) = (v^c(x), \partial_x v^c(x), \dots, \partial_x^{2m-1} v^c(x), 1)
\]
Then it follows that
\[
\langle W_0, \left( B - \frac{1}{c}I \right) V^c(y) \rangle = v_0(y) - \frac{1}{c}
\]
By Lemma \ref{lemma:Vcexists}, $|V^c(y) - V_0|\leq Ce^{-\alpha y}$. Since the first component of $V_0$ is $1/c$, $|v_0(y) - 1/c| \leq Ce^{-\alpha |x|}$. Using this with the third integral of \cref{Yintegform}, 
\begin{align*}
\left| \int_{-\infty}^x \langle W_0, \left( B - \frac{1}{c}I \right) V^c(y) \rangle dy \right| 
\leq C \int_x^{\infty} e^{-\alpha y} dy = C \frac{e^{-\alpha x}}{\alpha}
\end{align*}
which is finite for all $x$. Thus the expression \cref{Yintegform0} is valid. Evaluating this at $x = 0$, we have
\begin{equation}\label{Yintegform0}
\begin{aligned}
Y(0) &= \tilde{P}^s_+(0) Y(0) 
+ \int_{\infty}^0 \tilde{\Phi}^u(0,y)\left( B - \frac{1}{c}I \right) V^c(y) dy + V^c(0) \int_{\infty}^0 \langle W_0, \left( B - \frac{1}{c}I \right) V^c(y) \rangle dy 
\end{aligned}
\end{equation}

For the inner product with $\Psi^c(0) = W_0$, only the center integral term survives, so we have
\begin{align*}
\langle W_0, Y(0) \rangle
&= \langle W_0, V^c(0) \rangle \int_{\infty}^0 \left(v_0(y) - \frac{1}{c}\right) dy 
= -\int_0^{\infty} \left(v^c(y) - \frac{1}{c}\right) dy 
\end{align*}
which is finite. Since $v^c(y)$ is an even function, we obtain the result in part (i). For the inner product with $\Psi(0)$, only the first integral term survives. First, we note that 
\begin{align*}
\tilde{\Phi}^u(0,y) V^c(y) = \tilde{P}_+^u(y) \tilde{P}_+^c(y)V^c(y) = 0
\end{align*}
Thus for the inner product with $\Psi(0)$ we have
\begin{align*}
\langle \Psi(0), Y(0) \rangle
&= \int_{\infty}^0 \langle \Psi(0), \tilde{P}_+^u(0) \tilde{\Phi}(0,y) B V^c(y) \rangle dy \\
&= \int_{\infty}^0 \langle \tilde{P}_+^u(0)^*\Psi(0), \tilde{\Phi}(0,y) B V^c(y) \rangle dy \\
\end{align*}
By \cref{lemma:trichadjoint}, $\tilde{P}_+^u(0)^*\Psi(0) = \Psi(0)$, thus we have
\begin{align*}
\langle \Psi(0), Y(0) \rangle
&= \int_{\infty}^0 \langle \Psi(0), \tilde{\Phi}(0,y) B V^c(y) \rangle dy \\
&= -\int_0^\infty \langle \Psi(y), B V^c(y) \rangle dy \\
&=-\int_0^\infty q(y) v^c(y) dy,
\end{align*}
since $q(y)$ is the last component of $\Psi(y)$. Since $v^c(y)$ and $q(y)$ are both even functions, we obtain the result in part (ii).
\end{proof}
\end{lemma}

To conclude this section, as a corollary, we use the previous lemma to evaluate some important inner products.

\begin{corollary}\label{lemma:VpmPsiIP}
\begin{equation}\label{VpmIPs}
\begin{aligned}
\langle \Psi^c(0), V^\pm(0; \lambda) \rangle &= 1 \mp \frac{1}{2} \tilde{M}\lambda + \mathcal{O}(|\lambda|^2) \\
\langle \Psi(0), V^\pm(0; \lambda) \rangle &= \mp \frac{1}{2} M^c \lambda + \mathcal{O}(|\lambda|^2)
\end{aligned}
\end{equation}
\begin{proof}
Using Lemma \ref{lemma:Vpm} and Lemma \ref{varadjsolutions}, we can expand $V^+(0; \lambda)$ in a Taylor series about $\lambda = 0$ to get
\begin{align*}
V^+(0; \lambda) &= V^c(0) + \partial_\lambda V^+(0; 0) \lambda + \mathcal{O}(|\lambda|^2) \\
&= V^c(0) + \partial_\lambda \tilde{V}^+(0; 0) \lambda + \mathcal{O}(|\lambda|^2), 
\end{align*}
since $\partial_\lambda V^+(0; 0) = \partial_\lambda \tilde{V}^+(0; 0)$. For the inner product with $\Psi^c(0)$, we use \cref{lemma:VderivIPs} to get
\begin{align*}
\langle \Psi^c(0), V^+(0; \lambda) \rangle &= 
\langle W_0, V^c(0) \rangle + \langle W_0, \partial_\lambda \tilde{V}^+(0; 0) \rangle + \mathcal{O}(|\lambda|^2) \\
&= 1 - \frac{1}{2} \tilde{M}\lambda + \mathcal{O}(|\lambda|^2)
\end{align*}
The result for $\langle \Psi^c(0), V^-(0; \lambda) \rangle$ follows from the symmetry relations $\partial_\lambda \tilde{V}^-(0; 0)= -R \partial_\lambda \tilde{V}^+(0; 0)$ and $W_0 = R W_0$. For the inner product $\langle \Psi(0), V^+(0; \lambda) \rangle$, we use \cref{lemma:VderivIPs} and \cref{VtildeVderiv} to get
\begin{align*}
\langle \Psi(0), V^+(0; \lambda) \rangle 
&= \langle \Psi(0), V^c(0) \rangle + \langle \Psi(0), \partial_\lambda \tilde{V}^+(0; 0) \rangle \lambda  + \mathcal{O}(|\lambda|^2) \\
&= -\frac{1}{2} M^c \lambda + \mathcal{O}(|\lambda|^2)
\end{align*}
The result for $\langle \Psi(0), V^-(0; \lambda) \rangle$ follows from symmetry as above.
\end{proof}
\end{corollary}

\section{Piecewise formulation}\label{sec:perpiece}

With all of these preliminaries taken care of, we will write the eigenvalue problem \cref{PDEeigsystemper4} in a piecewise form similar to \cite{Sandstede1998}. Let $Q_n(x)$ be a periodic $n$-pulse solution to \eqref{genODE} constructed according to Theorem \ref{perexist}. From Theorem \ref{perexist} and Lemma \ref{solvewithjumps}, we can write $Q_n(x)$ piecewise as
\begin{equation}\label{Qnppiece}
\begin{aligned}
Q_i^-(x) &= Q^-(x; \beta_i^-) + \tilde{Q}_i^-(x) && x \in [-X_{i-1}, 0] \\
Q_i^+(x) &= Q^+(x; \beta_i^+) + \tilde{Q}_i^+(x) && x \in [0, X_i]
\end{aligned}
\end{equation}
where $Q_i^-: [-X_{i-1}, 0] \rightarrow \R$ and $Q_i^+: [0, X_i]$ and the pieces are joined together end-to-end in a loop. (Note that we are using $\tilde{Q}_i^-(x)$ in place of $V_i^\pm(x)$ in Lemma \ref{solvewithjumps}).

When $\lambda = 0$, it follows from \cref{sec:HamPDE} and the definitions of $A(Q_n(x))$ and $B$ that 
\begin{equation}\label{PDEeigkernel}
\begin{aligned}
{[\partial_x Q_n]}'(x) &= A(Q_n(x))\partial_x Q_n(x) \\
{[\partial_c Q_n]}'(x) &= A(Q_n(x))\partial_c Q_n(x) + \lambda B \partial_x Q_n(x).
\end{aligned}
\end{equation}
We also showed above in \cref{lemma:Vpm} that there exist functions $V^\pm(x; \lambda)$ on $\R^\pm$ which satisfy
\begin{equation}\label{PDEeigcenter}
[V^\pm(x; \lambda)]'(x) = A(Q(x); \lambda) V^\pm(x; \lambda)
\end{equation}
To exploit the relations \eqref{PDEeigkernel} and \eqref{PDEeigcenter}, we take the following piecewise ansatz for the eigenfunction $U(x)$
\begin{equation}\label{Vpiecewise}
\begin{aligned}
U_i^-(x) &= d_i (\partial_x Q_i^-(x) + \lambda \partial_c Q_i^-(x)) + c_{i-1} e^{\nu(\lambda)X_{i-1} } V^-(x; \lambda) + W_i^-(x) && x \in [-X_{i-1}, 0] \\
U_i^+(x) &= d_i (\partial_x Q_i^+(x) + \lambda \partial_x Q_i^+(x)) + c_i e^{-\nu(\lambda)X_i }V^+(x; \lambda) + W_i^+(x) && x \in [0, X_i] 
\end{aligned}
\end{equation}
where $c_i, d_i \in \C$ are constants, $W_i^-(x) \in C([-X_{i-1}, 0], \C)$, and $W_i^+(x) \in C([0, X_i], \C)$. Since we are on a periodic domain, all subscripts are taken $\Mod n$. We note that the $c_i$ and the factors $e^{-\nu(\lambda)X_i }$ are chosen to facilitate the matching at $\pm X_i$. Substituting this ansatz into \cref{PDEeigsystemper4} and simplifying, we obtain the following equation for $W_i^\pm(x)$.
\begin{equation}\label{Wipm2}
\begin{aligned}
(W_i^-)'(x) &= A(Q(x); \lambda) W_i^-(x) + G_i^-(x) W_i^-(x) + c_{i-1} e^{\nu(\lambda)X_{i-1}} G_i^-(x)V^-(x; \lambda) + d_i \lambda^2 \tilde{H}_i^-(x) \\
(W_i^+)'(x) &= A(Q(x); \lambda) W_i^+(x) + G_i^+(x) W_i^+(x) + c_i e^{-\nu(\lambda)X_i } G_i^+(x)V^+(x; \lambda) + d_i \lambda^2 \tilde{H}_i^+(x)
\end{aligned}
\end{equation}
where
\begin{align*}
G_i^\pm(x) &= A(Q_i^\pm(x)) - A(Q(x)) \\
\tilde{H}_i^\pm(x) &= \partial_c Q_i^\pm(x) \\ 
H(x) &= \partial_c Q(x)
\end{align*}

Since the eigenfunction $U(x)$ must be continuous, the $2n$ pieces $U_i^\pm(x)$ must also be joined together end-to-end in a loop. In other words, $n$ matching conditions at $x = \pm X_i$ and $n$ matching conditions at $x = 0$ must be satisfied. Thus to obtain an eigenfunction $U(x)$, the functions $W_i^\pm(x)$ must solve the system of equations
\begin{equation}\label{eigsystem0}
\begin{aligned}
(W_i^-)'(x) &= A(Q(x); \lambda) W_i^-(x) + G_i^-(x) W_i^-(x) + c_{i-1} e^{\nu(\lambda)X_{i-1}} G_i^-(x)V^-(x; \lambda) + d_i \lambda^2 \tilde{H}_i^-(x) \\
(W_i^+)'(x) &= A(Q(x); \lambda) W_i^+(x) + G_i^+(x) W_i^+(x) + c_i e^{-\nu(\lambda)X_i } G_i^+(x)V^+(x; \lambda) + d_i \lambda^2 \tilde{H}_i^+(x) \\
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d + C_i c \\
W_i^+(0) - W_i^+(0) &+ c_i e^{-\nu(\lambda)X_i}V^+(0; \lambda) - c_{i-1} e^{\nu(\lambda)X_i} V^-(0; \lambda) = 0
\end{aligned}
\end{equation}
for $i = 0, \dots, n-1$, where
\begin{align}\label{defDid}
D_i d &= d_{i+1}[\partial_x Q_{i+1}^-(-X_i) + \lambda \partial_c Q_{i+1}^-(-X_i)]
- d_i [ \partial_x Q_i^+(X_i) + \lambda \partial_c Q_i^+(X_i) ]
\end{align}
and
\begin{align}\label{defCic}
C_i c &= c_i \left( e^{\nu(\lambda) X_i} V^-(-X_i; \lambda) - e^{-\nu(\lambda) X_i} V^+(X_i; \lambda) \right)
\end{align}
As in \cite{Sandstede1998}, we will not be able to find a solution to this system for arbitrary $\lambda$. We will instead consider the system
\begin{equation}\label{eigsystem}
\begin{aligned}
(W_i^-)'(x) &= A(Q(x); \lambda) W_i^-(x) + G_i^-(x) W_i^-(x) + c_{i-1} e^{\nu(\lambda)X_{i-1}} G_i^-(x)V^-(x; \lambda) + d_i \lambda^2 \tilde{H}_i^-(x) \\
(W_i^+)'(x) &= A(Q(x); \lambda) W_i^+(x) + G_i^+(x) W_i^+(x) + c_i e^{-\nu(\lambda)X_i } G_i^+(x)V^+(x; \lambda) + d_i \lambda^2 \tilde{H}_i^+(x) \\
W_i^+(X_i) - W_{i+1}^-(-X_i) &= D_i d + C_i c \\
W_i^\pm(0) &\in \R \Psi(0) \oplus \R \Psi^c(0) \oplus Y^+ \oplus Y^- \\
W_i^+(0) - W_i^-(0) &\in \R \Psi(0) \oplus \R \Psi^c(0) 
\end{aligned}
\end{equation}
for $i = 0, \dots, n-1$, where the fourth equation in \cref{eigsystem0} is relaxed to the requirement that the jumps $W_i^+(0) - W_i^-(0)$ can only be in the directions of $\Psi^c(0)$ and $\Psi(0)$. A solution to \eqref{eigsystem} solves the \cref{eigsystem} if and only if the $n$ jumps conditions at $x = 0$ in the direction of $\Psi(0) \oplus \R \Psi^c(0)$ are satisfied, i.e.  
\begin{equation}\label{jumpxi1}
\begin{aligned}
\xi_i &= \langle \Psi(0), W_i^+(0) - W_i^-(0) + c_i e^{-\nu(\lambda)X_i}V^+(0; \lambda) - c_{i-1} e^{\nu(\lambda)X_i} V^-(0; \lambda) \rangle = 0  \\
\xi_i^c &= \langle \Psi^c(0), W_i^+(0) - W_i^-(0) + c_i e^{-\nu(\lambda)X_i}V^+(0; \lambda) - c_{i-1} e^{\nu(\lambda)X_i} V^-(0; \lambda) \rangle = 0 
\end{aligned}
\end{equation}
for $i = 0, \dots, n-1$. 

\section{Conjugation of system}

We will now apply the conjugation we derived in \cref{sec:conjugation} to the system \cref{eigsystem}. Making the substitution $W_i^\pm(x) = P_\pm(x; \lambda) Z_i^\pm(x)$, we obtain the equations
\begin{equation}\label{systemZ}
\begin{aligned}
(Z_i^-(x))' = A(\lambda) &Z_i^-(x) + P_-(x; \lambda)^{-1} G_i^-(x) P_-(x; \lambda) Z_i^-(x)  \\
&+ c_{i-1} e^{\nu(\lambda)X_{i-1}} P_-(x; \lambda)^{-1} G_i^-(x)V^-(x; \lambda) + \lambda^2 d_i P_-(x; \lambda)^{-1} \tilde{H}_i^-(x) \\
(Z_i^+(x))' = A(\lambda) &Z_i^+(x) + P_+(x; \lambda)^{-1} G_i^+(x) P_+(x; \lambda) Z_i^+(x)  \\
&+ c_i e^{-\nu(\lambda)X_i} P_+(x; \lambda)^{-1} G_i^+(x)V^+(x; \lambda) + \lambda^2 d_i P_+(x; \lambda)^{-1} \tilde{H}_i^+(x)
\end{aligned}
\end{equation}
with matching conditions at tails
\begin{equation}\label{systemmiddle}
P_+(X_i; \lambda) Z_i^+(X_i) - P_-(-X_i; \lambda) Z_{i+1}^-(-X_i; \lambda) = D_i d + C_i c 
\end{equation}
and conditions at $x = 0$
\begin{align}
P_\pm(0; \lambda) Z_i^\pm(0) &\in Y^+ \oplus Y^- \oplus \C \Psi(0) \oplus \C \Psi^c(0) \label{systemcenter1} \\
P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) &\in \C \Psi(0) \oplus \C \Psi^c(0) \label{systemcenter2}.
\end{align}
The jump conditions become
\begin{equation}\label{jumpcondZ}
\begin{aligned}
\xi_i &= \langle \Psi(0), P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) + c_i e^{-\nu(\lambda)X_i}V^+(0; \lambda) - c_{i-1} e^{\nu(\lambda)X_i} V^-(0; \lambda) \rangle = 0  \\
\xi_i^c &= \langle \Psi^c(0), P_+(0; \lambda) Z_i^+(0) - P_-(0; \lambda) Z_i^-(0) + c_i e^{-\nu(\lambda)X_i}V^+(0; \lambda) - c_{i-1} e^{\nu(\lambda)X_i} V^-(0; \lambda) \rangle = 0 
\end{aligned}
\end{equation}

\section{Constants and estimates}

In this section, we will define constants which we will use throughout the rest of the analysis. We will also provide estimates on terms which will arise when we solve \cref{eigsystem}.

Recall from Lemma \ref{eigA0lemma} that $A(0)$ has a simple eigenvalue at 0, a quartet of eigenvalues $\pm \alpha_0 \pm \beta_0 i$, and for all other eigenvalues $\nu$ of $A(0)$, $|\Re \nu| > \alpha_0$. Let $(b_0, \dots, b_{n-1}, \theta)$ be any periodic parameterization, and let $r_* = r_*(b_0, \dots, b_{n-1}, \theta)$ be as in Theorem \ref{perexist}. 

\begin{enumerate}
	\item Let $\alpha$ be as chosen in \cref{sec:existdichot}, and recall that $\alpha$	is slightly less than $\alpha_0$. Let $\tilde{\alpha} = \alpha/2$.

	\item Choose $\delta \leq \min\{\delta_1, \delta_2\}$ sufficiently small so that for all $|\lambda| < \delta$
	\begin{enumerate}
		\item $|\nu(\lambda)| < \delta$, where $\nu(\lambda)$ defined in Lemma \ref{nulambdalemma}.

		\item The real part of any other eigenvalue of $A(\lambda)$ lies strictly outside the interval $[-\tilde{\alpha}, \tilde{\alpha}]$. This is possible since the eigenvalues of $A(\lambda)$ are smooth in $\lambda$.
	\end{enumerate}
	As we proceed we may need to decrease $\delta$. 

	\item Choose $r_0 \leq r_*$ such that $r_0^{1/2} \leq \delta$. If we decrease $\delta$, $r_0$ will also decrease so that this is still satisfied.

	\item As in \cref{sec:rescale}, define
	\begin{equation}\label{Xstarstab}
	X^* = -\frac{1}{2\alpha}\log r - \frac{\phi}{2\beta_0}
	\end{equation}
	Note that $X_j \geq X^*$ for all $j = 0, \dots, n-1$.

\end{enumerate}

In the next lemma, we give an estimate for terms of the form $e^{\pm \nu(\lambda) X_j}$, which will show up in our analysis. In order to get a uniform estimate, we will place an upper bound on the  magnitude of $\lambda$. Although we can perform our analysis without doing this, this additional condition allows the form of the block matrix in \cref{blockmatrixtheorem} to be relatively simple. 

\begin{lemma}\label{lemma:expnubound}
Choose any $N > 0$ and $\delta > 0$. Then there exists a constant $R_N = R(N, \delta)$ such that if $|\lambda| < \delta$ and $|\lambda| < N/|\log r|$,
\begin{align}\label{expnubound}
\left|e^{\nu(\lambda)X_j} \right| \leq R && j = 0, \dots, n-1
\end{align}
\begin{proof}
Using the expression \cref{Xj} from \cref{perexist},
\begin{align}\label{Xjmag}
|X_j(r; m_j, \theta)| &\leq \frac{1}{2 \alpha_0} |\log r| + \frac{1}{2\beta_0} |b_j(r; m_j, \theta)| + |L_0| && j = 0, \dots, n-1,
\end{align}
For all $r \leq r_*$ and $\theta$, the functions $b_j(r; m_j, \theta)$ are continuous in $r$ and satisfy bound $|b_j(r; m_j, \theta)| \leq (m_j + 1)\pi$. Let $m_{\max} = \max\{ m_0, \dots, m_{n-1}\}$. Then we have the uniform bound
\[
|b_j(r; m_j, \theta)| (\leq m_{\max} + 1)\pi
\]
Combining this with \cref{Xjmag}, we have the uniform bound
\begin{align}\label{Xjmag2}
\left|X_j(r; m_j, \theta)\right| &\leq \frac{1}{2 \alpha_0} |\log r| + \frac{\pi}{2\beta_0} (m_{\max} + 1) + |L_0| && j = 0, \dots, n-1,
\end{align}
For $\lambda$ with $|\lambda| \leq N/|\log r|$ and $|\lambda| < \delta$, it follows from \cref{nulambdalemma} that
\begin{align*}
|\nu(\lambda)| &\leq \frac{1}{c}|\lambda| + C |\lambda|^3 \\
&\leq \frac{N}{c |\log r|} + C \frac{N}{|\log r|}\delta^2
\end{align*}
Combining this with \cref{Xjmag2}, we have
\begin{align*}
|\nu(\lambda) X_j(r; m_j, \theta)| &\leq  N \left( \frac{1}{c} + C \delta^2 \right)\left( \frac{1}{2 \alpha_0} + \frac{1}{|\log r|} \left( \frac{\pi}{2\beta_0} (m_{\max} + 1) + |L_0| \right) \right)
\end{align*}
which is bounded for all $r \leq r_*$. We conclude that there exists a constant $R_N$ depending on $N$ and $\delta$ such that the uniform bound \cref{expnubound} holds.
\end{proof}
\end{lemma}

To conclude this section, we will collect estimates on the terms involved in the conjugated system in the following lemma.

\begin{lemma}\label{stabestimateslemma}
Let $\Delta H_i^\pm(x) = \tilde{H}_i^\pm(x) - H(x)$. Then we have the following estimates
\begin{enumerate}[(i)]
\item $|H(x)|, |\tilde{H}_i^\pm(x)| \leq C e^{-\alpha |x|}$
\item $|\Delta H_i^-(x)| \leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } + e^{-2 \alpha X_i} e^{\alpha x}$
\item $|\Delta H_i^+(x)| \leq C e^{-\alpha X_i} e^{-\alpha(X_i - x) } + e^{-2 \alpha X_{i-1}} e^{-\alpha x}$
\item $\|\Delta H_i^\pm\| \leq C(e^{-\alpha X_i} + e^{-\alpha X_{i-1}} )$
\item $|G_i^-(x)| \leq C e^{-\alpha X_{i-1}} e^{-\alpha(X_{i-1} + x) } + e^{-2 \alpha X_i} e^{\alpha x}$
\item $|G_i^+(x)| \leq C e^{-\alpha X_i} e^{-\alpha_0(X_i - x) } + e^{-2 \alpha X_{i-1}} e^{-\alpha x}$
\item $\|G\| \leq C e^{-\alpha X^*}$
\item $D_i d = ( Q'(X_i) + Q'(-X_i))(d_{i+1} - d_i ) + \mathcal{O} ( e^{-\alpha X_i} (e^{-\alpha X^*} + |\lambda| )$
\item $|C_i c| \leq C e^{-\alpha X_i} |c|$
\end{enumerate}
\begin{proof}
Recall that $H(x) = \partial_c Q(x)$ and $\tilde{H}(x) = \partial_c Q_i^\pm(x)$. By \cref{Qcbound} from \cref{Qclocalhyp},
\begin{equation}\label{Qcbound1}
|\partial_c Q(x)| \leq C e^{-\alpha|x|}
\end{equation}
We can obtain the same bound for $\partial_c Q_i^\pm(x)$ using Lin's method as in \cite{SandstedeStrut,Sandstede1993}. This gives us the bounds in (i). The bounds (ii) and (iii) follow from an adaptation of Lemma \ref{solvewithjumps} to derivative with respect to $c$. The bound (iv) follows from (ii) and (iii). Since $A(Q(x))$ is smooth in $Q(x)$, the bounds (v), (vi), and (vii) come from Lemma \ref{solvewithjumps}. 

For the estimate (viii), we use \eqref{VQpm} in Lemma \ref{solvewithjumps} and \eqref{Vpiecewise} (with $\tilde{Q}$ in place of $V$) to get
\begin{align*}
Q_{i+1}^-(-X_i) &= Q^-(-X_i; \beta_{i+1}^-) + \tilde{Q}_{i+1}^-(-X_i) \\
&= Q^-(-X_i; \beta_{i+1} ^-) + Q^+(X_i; \beta_i^+) + \mathcal{O}(e^{-2 \alpha X_i}) \\
&= Q(-X_i) + Q(X_i) 
+ \mathcal{O}(e^{-\alpha X_i}(e^{-\alpha X_{i-1}}+e^{-\alpha X_i}+e^{-\alpha X_{i+1}}))
\end{align*}
Since the bounds \ref{solvewithjumps} also apply to derivatives with respect to $x$, 
\begin{align*}
(Q_{i+1}^-)'(-X_i) &= Q'(-X_i) + Q'(X_i) + \mathcal{O}(e^{-\alpha X_i}e^{-\alpha X^*})
\end{align*}
Similarly,
\begin{align*}
(Q_i^+)'(X_i)' &= Q'(-X_i) + Q'(X_i) + \mathcal{O}(e^{-\alpha X_i}e^{-\alpha X^*})
\end{align*}
To get the estimate (viii), we substitute these into \cref{defDid} and use estimate (i) for $\partial_c Q_i^\pm(x)$.

Finally, for the estimate (ix), by Lemma \ref{lemma:Vpm} we have
\begin{align*}
e^{\nu(\lambda) X_i} V^-(-X_i; \lambda) 
&= e^{\nu(\lambda) X_i} e^{-\nu(\lambda) X_i}\left(V_0(\lambda) + \mathcal{O}(e^{-\alpha X_i}) \right) \\
&= V_0(\lambda) + \mathcal{O}(e^{-\alpha X_i})
\end{align*}
Similarly,
\begin{align*}
e^{-\nu(\lambda) X_i} V^+(X_i; \lambda)
&= V_0(\lambda) + \mathcal{O}(e^{-\alpha X_i})
\end{align*}
Using these, it follows that
\[
|C_i c| \leq C e^{-\alpha X_i} |c|
\]
\end{proof}
\end{lemma}

\iffulldocument\else
	\bibliographystyle{amsalpha}
	\bibliography{thesis.bib}
\fi

\end{document}