\documentclass[thesis.tex]{subfiles}

\begin{document}

\iffulldocument\else
	\chapter{KdV5}
\fi

\section{Proof of Results in \cref{sec:KdV5gen} }

\subsection{Proof of Lemma \ref{manifoldinH0}}

Let $U = (u_1, \dots, u_{2m})$ and $Q(x; c_0) = (q_1(x), \dots, q_{2m}(x))$. We wish to write the zero-level set $H^{-1}(0; c)$ as a graph near $Q(0; c_0)$. We will do this using the IFT.

By Hypothesis \ref{Qexistshyp}, $H(q_1(0), \dots, q_{2m}(0); c_0) = 0$ and $\nabla_U H(Q(0; c_0); c_0) \neq 0$. This implies that one of the $2m$ components of $\nabla_U H(Q(0; c_0); c_0)$ is nonzero. Renumbering the components of $Q(x)$ if necessary, we can without loss of generality take the first component of $\nabla_U H(Q(0); c_0)$ to be nonzero, i.e. $\partial_{u_1}H(q_1(0), \dots, q_{2m}(0); c_0) \neq 0$. We can use the IFT to solve $H(u_1, u_2 \dots, u_{2m}; c_0) = 0$ for $u_1$ in terms of $(u_2, \dots, u_{2m})$ and $c_0$ near $Q(0)$ and $c_0$.

Specifically, there exist open neighborhooods $V_1$ of $q_1(0)$ and $V_2$ of $(q_2(0), \dots, q_{2m}(0))$, $\delta > 0$, and a unique smooth function $g: V_2 \times (c_0 - \delta, c_0 + \delta) \rightarrow V_1$ such that $g(q_2(0), \dots, q_{2m}(0); c_0) = q_1(0)$ and for all $U \in V_2$ and $c \in (c_0 - \delta, c_0 + \delta)$, $H(g(U; c),U; c) = 0$. Our desired manifolds are then given by
\begin{equation}\label{defMc}
M(c) = \{ (g(U; c), U; c) : U \in V_2 \}
\end{equation}
for $c \in (c_0 - \delta, c_0 + \delta)$. These manifold are $(2m-1)-$dimensional, are smooth since $H$ is smooth, and are contained in $H^{-1}(0; c_0)$. Taking $U = (q_2(0), \dots, q_{2m}(0))$ and $c = c_0$ in \eqref{defMc}, $M(c_0)$ contains $Q(0; c_0)$.

\subsection{Proof of Theorem \ref{transverseint}}

First, we show that homoclinic orbits $Q(x; c)$ exist for $c$ near $c_0$.

\begin{lemma}\label{Qcexistslemma}
There exists $\delta > 0$ such that for $c \in (c_0 - \delta, c_0 + \delta)$, the stable and unstable manifolds $W^s(0; c)$ and $W^u(0; c)$ have a one-dimensional transverse intersection in $H^{-1}(0; c)$ which is a homoclinic orbit $Q(x; c)$. The map $c \rightarrow Q(x; c)$ is smooth.

\begin{proof}
This is a straightforward consequence of Lemma \ref{manifoldinH0}, the transverse intersection of $W^s(0; c_0)$ and $W^u(0; c_0)$ in $M(c_0) \subset H^{-1}(0; c_0)$ from Hypothesis \ref{H0transversehyp}, and the smoothness of $F$.

Let $\delta$ be as in Lemma \ref{manifoldinH0}, and for convenience, let $Q_0 = Q(0; c_0)$. Since we will be working entirely in the $(2m-1)$-dimensional manifolds $M(c)$, we will choose a local coordinate system to work in. To do this, we will write $M(c)$ as a graph over the tangent space of $M(c_0)$ in the following way. Since $W^s(0; c_0)$ and $W^u(0; c_0)$ in $M(c_0)$ intersect transversely in $M(c_0)$, and we have shown that this intersection is one-dimensional, we can write the three tangent spaces at $Q_0$ as follows.
\begin{align*}
T_{Q_0}W^u(0; c_0) &= V \oplus V^u \\
T_{Q_0}W^s(0; c_0) &= V \oplus V^s \\
T_{Q_0}M(c_0) &= T_{Q_0}W^u(0; c_0) 
+ T_{Q_0}W^s(0; c_0) = V \oplus V^u \oplus V^s
\end{align*}

Since $F(U; c)$ is smooth in $U$ and $c$, the stable and unstable manifolds $W^s(0; c)$ and $W^u(0; c)$ are also smooth in $c$ by the stable manifold theorem and smooth dependence of solutions to \eqref{genODE} on parameters. Thus for $c$ sufficiently close to $c_0$, $W^s(0; c)$ and $W^u(0; c)$ will both intersect $M(c)$. 

First, we write $M(c_0)$ as a graph over its own tangent space. There exists $r > 0$ such that for $|v|, |v_u|, |v_s| < r$ and $c \in (c_0 - \delta, c_0 + \delta)$ (shrinking $\delta$ if needed), 
\begin{align*}
M(c) = Q_0 + v + v_u + v^s + h(v, v_u, v_s; c)
\end{align*}
where $h: V \times V^u \times V^s \times (c_0 - \delta, c_0 + \delta) \rightarrow \R^{2m}$ is smooth, $h(0,0,0; c_0) = 0$ and $D_{(v, v_u, v_s)} h(0, 0, 0; c_0) = 0$.

Using this, we can write $W^s(0; c)$ and $W^u(0; c)$ as graphs over the their tangent spaces. Shrinking $r$ and $\delta$ if needed, there exist smooth functions $h^u: V \times V^u \times \R \rightarrow V^s$ and $h^s: V \times V^s \times \R V^u$ such that 
\begin{equation}\label{Wparam1}
\begin{aligned}
W^u(0; c) &= Q_0 + \{ v + v_u + h^u(v, v_u; c) + h(v, v_u, h^u(v, v_u; c); c): |v|, |v_u| \leq r, c \in (c_0 - \delta, c_0 + \delta) \} \\
W^s(0; c) &= Q_0 + \{ v + h^s(v, v_s; c) + v_s + h(v, h^s(v, v_s; c), v_s; c): |v|, |v_s| \leq r, c \in (c_0 - \delta, c_0 + \delta)  \}
\end{aligned}
\end{equation}
where
\begin{align*}
h^s(0, 0; c_0) &= h^u(0, 0; c_0) = 0 \\
D_{(v, v_u)} h^u(0, 0; c_0) &= D_{(v, v_s)}  h^s(0, 0; c_0) = 0
\end{align*}

Let $\Sigma$ be the hyperplane plane passing through $Q_0$ with no component in $V^c$, i.e.
\[
\Sigma = Q_0 + V^s + V^u
\]
To obtain a unique intersection point, we will consider the intersection of the stable and unstable manifolds to $\Sigma$. Since the restriction maps $(v, v_s) \mapsto v_s$ and $(v, y^-) \rightarrow y^-$ are smooth, $W^u(0; c) \cap \Sigma$ and $W^s(0; c) \cap \Sigma$ are smooth $(m-1)-$dimensional manifolds parameterized by
\begin{equation}\label{Wparam2}
\begin{aligned}
W^u(0; c) \cap \Sigma &= Q_0 + \{ v_u + h^u(0, v_u; c) + h(0, v_u, h^u(0, v_u; c); c): |v_u| \leq r, c \in (c_0 - \delta, c_0 + \delta) \} \\
W^s(0; c) \cap \Sigma &= Q_0 + \{ h^s(0, v_s; c) + v_s + h(0, h^s(0, v_s; c), v_s; c): |v_s| \leq r, c \in (c_0 - \delta, c_0 + \delta) \}
\end{aligned}
\end{equation}

We wish to show that for $c$ close to $c_0$, $W^s(0; c) \cap \Sigma$ and $W^u(0; c) \cap \Sigma$ have a unique point of intersection. Looking at \eqref{Wparam2}, it suffices to solve $K(v_u, v_s; c) = 0$, where $K: V^u \times V^s \times \R \rightarrow V^u \times V^s$ is defined by
\begin{align*}
K(v_u, v_s; c) = (v_u - h^s(0, v_s; c), v_s - h^u(0, v_u; c))
\end{align*}
Since $h^s(0, 0; c_0) = h^u(0, 0; c_0) = 0$, $K(0, 0, c_0) = 0$. Since $D_{v_u} h^u(0, 0; c_0) = D_{v_s} h^s(0, 0; c_0) = 0$, 
$D_{(v_u, v_s)}K(0, 0; c_0) = I_{2m-2}$, which is invertible. Using the IFT, there exists an open neighborhood $W$ of $(0, 0) \in V^u \times V^s$, $\tilde{\delta}$ with $0 < \tilde{\delta} < \delta$, and a unique smooth function $g: (c_0 - \tilde{\delta}, c_0 + \tilde{\delta}) \rightarrow W$ such that $g(c_0) = (0, 0)$ and $K(g(c), c) = 0$ for all $c \in (c_0 - \tilde{\delta}, c_0 + \tilde{\delta})$.

Let $g(c) = (g_u(c), g_s(c)) \in V^u \times V^s$. Then for $c \in (c_0 - \tilde{\delta}, c_0 + \tilde{\delta})$, the unique intersection point of $W^s(0; c) \cap \Sigma$ and $W^u(0; c) \cap \Sigma$ is given by the smooth function
\[
P(c) = Q_0 + g_u(c) + g_s(c) + h(0, g_u(c), g_s(c); c)
\]
Using $P(c)$ as the initial condition at $x = 0$, we obtain a unique solution $Q(x; c)$ to \eqref{genODE}. Since $P(c)$ is in both $W^s(0; c)$ and $W^u(0; c)$, $Q(x; c)$ is a homoclinic orbit. Since $P(c)$ and $F(U; c)$ are smooth in $c$, the map $c \rightarrow Q(x; c)$ is smooth.
\end{proof}
\end{lemma}

Next, we will show that $Q_c(x)$ is exponentially localized. We will show this on $\R^+$; the argument for $\R^+$ is identical. To do this, we will first show that $Q_c(x)$ is a fixed point of a map on an exponentially weighted space. We will then show that the map is differentiable in $c$.

Let $\delta$ be as in Lemma \ref{Qcexistslemma}. By Hypothesis \ref{hypeqhyp}, $DF(0; c_0)$ is hyperbolic and $|\Re \nu| \geq \alpha_0$ for all eigenvalues of $DF(0; c_0)$. Since $F$ is smooth, the eigenvalues of $DF(0; c_0)$ are smooth functions of $c$. Choose any $\epsilon > 0$ such that $\alpha_0 - 2 \epsilon > 0$. Then we can find $\delta_1$ with $0 < \delta_1 \leq \delta$ such that for all $c \in (c_0 - \delta_1, c_0 + \delta_1)$, $|\Re \nu| \geq \alpha_0 - \epsilon$ for all eigenvalues of $DF(0; c)$.

For convenience, let $A(c) = DF(0; c)$. Let $P^u(c)$ and $P^s(c)$ be the projections on the unstable and stable eigenspaces of $A(c)$. Then we have the following bounds for the matrix exponential $e^{A(c)x}$.
\begin{equation}\label{eAcbounds}
\begin{aligned}
||e^{A(c)x}P^s(c)|| &\leq Ke^{-(\alpha_0 - \epsilon) x} && x \geq 0\\
||e^{A(c)x}P^u(c)|| &\leq Ke^{(\alpha_0 - \epsilon) x} && x \leq 0
\end{aligned}
\end{equation}

Let $\eta = \alpha_0 - 2 \epsilon$, and define the exponentially weighted norm
\[
||G||_\eta = \sup_{x \in [0, \infty)} |e^{\eta x} G(x)|
\]
and the exponentially weighted space
\begin{equation}\label{defXeta}
X_\eta = \{ G \in C^0([0, \infty), \R^n) : ||G||_\eta < \infty \}
\end{equation}
$X_\eta$ is known to be a Banach space.

% lemma: contraction map
\begin{lemma}\label{Hcontractionlemma}
There exists $\delta_1$ with $0 < \delta_1 \leq \delta$ with the following property. For all $c \in (c_0 - \delta_1, c_0 + \delta_1)$, there exists $x_0(c) \geq 0$ such that $Q(x + x_0(c); c)$ is the unique fixed point of the map $H: D \times B_1 \times B_2 \rightarrow D$ define by
\begin{equation}\label{defH}
[H(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}
with initial condition $a = Q(x_0(c); c)$. The spaces $B_1$, $B_2$, and $D$ are defined below in the proof.

\begin{proof}
First, we separate $U(x)' = F(U(x); c)$ into linear and nonlinear parts by expanding in a Taylor series about $U = 0$. Since $F(0) = 0$, this gives us the ODE
\[
U(x)' = DF(0; c)U(x) + N(U(x)) = A(c)U(x) + N(U(x))
\] 
where $N(0) = 0$ and $DN(0) = 0$ since $N$ is purely nonlinear. Since we obtained \eqref{genODE} by writing \eqref{eqODE} as a first order system, only the linear part $A(c)$ depends on $c$.
Suppose that $|U(x)| \leq \rho$ for $x \geq 0$, where $\rho$ will be chosen later. Then, following the proof of the stable manifold theorem, we can write $U(x)$ in integrated form as 
\[
U(x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\]
where $a$ is the initial condition. Define the following spaces
\begin{align*}
B_1 &= (c_0 - \delta_1, c_0 + \delta_1) \\
B_2 &= \{ a \in \R^n : |P^s(c) a| \leq \rho/2K \text{ for all } c \in B_1\} \\
D &= \{ u \in X_\eta : ||u||_\eta \leq \rho \}
\end{align*}
and define the map $H: D \times B_1 \times B_2 \rightarrow X_\eta$ by
\begin{equation}\label{defH}
[H(U, c, a)](x) = e^{A(c)x} P^s(c) a + \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy + \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy
\end{equation}

First, we will show that $H$ is well-defined, i.e. it maps into $X_\eta$. Since $F$ is smooth, $N$ is Lipschitz in a neighborhood of 0. Thus since $N(0) = 0$ and $DN(0) = 0$, there exists a Lipschitz constant $L(\rho)$ with $L(\rho) \rightarrow 0$ as $\rho \rightarrow 0$ such that 
\[
|N(U)| \leq L(\rho)|U|
\]
whenever $|U| \leq \rho$. In particular, if $||U(x)||_\eta \leq \rho$, $||U(x)||_\eta \leq \rho$ as well. Thus $|e^{\eta x} N(U(x))| \leq L(\rho)|e^{\eta x}U(x)|$ for all $x \in \R^+$, from which it follows that 
\begin{equation}\label{LrhoNU}
|N(U)|_\eta \leq L(\rho)|U|_\eta
\end{equation}
Similarly, it follows from the mean value inequality that for $U, V$ with $||U||_\eta, ||V||_\eta \leq \rho$
\begin{equation}\label{NUlip}
||N(U) - N(V)||_\eta \leq L(\rho)(||U||_\eta - ||V||_\eta) 
\end{equation}

We consider each of the terms on the RHS of \eqref{defH} individually. For the first term, since $a \in B_1$, we have
\begin{align*}
|e^{\eta x} e^{A(c)x } P^s(c) a | &\leq K e^{\eta x} e^{-(\alpha_0 - \epsilon) x} | P^s(c) a |\\
&\leq K \frac{\rho}{2 K} e^{-\epsilon x}\\
&\leq \frac{\rho}{2}
\end{align*}
For the first integral term,
\begin{align*}
\left| e^{\eta x} \int_\infty^x e^{A(c)(x - y)}P^u(c) N(U(y))dy \right| &= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) N(U(y))dy \right|\\
&\leq \int_x^\infty K e^{\eta x}e^{(\alpha_0 - \epsilon)(x - y)}|N(U(y))|dy \\
&= K \int_x^\infty e^{\eta (x - y)}e^{(\alpha_0 - \epsilon)(x - y)} | e^{\eta y} N(U(y))|dy \\
&\leq K \int_x^\infty e^{(2 \alpha_0 - 3 \epsilon)(x - y)} || N(U)||_\eta dy \\
&\leq K L(\rho) ||U||_\eta \int_x^\infty e^{(2 \alpha_0 - 3 \epsilon)(x - y)} dy \\
&= \frac{ K L(\rho) }{2 \alpha_0 - 3 \epsilon} ||U||_\eta \\
&\leq \frac{ K L(\rho) }{2 \alpha_0 - 3 \epsilon} \rho
\end{align*}
where we used the fact that $U \in D$, thus $||U||_\eta \leq \rho$. For the second integral term,
\begin{align*}
\left| e^{\eta x} \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y)) \right| &= \left| \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c) N(U(y)) dy \right|\\
&\leq \int_0^x K e^{\eta x}e^{-(\alpha_0 - \epsilon)(x -y)}|N(U(y))|dy \\
&= K \int_0^x e^{\eta (x - y)}e^{-(\alpha_0 - \epsilon)(x - y)}| e^{\eta y} N(U(y))|dy \\
&\leq K \int_0^x e^{-\epsilon(x - y)} || N(U)||_\eta dy \\
&\leq K L(\rho) ||U||_\eta \int_0^x e^{-\epsilon(x - y)} dy \\
&= K L(\rho) ||U||_\eta \frac{1 - e^{-\epsilon x} }{\epsilon} \\
&\leq \frac{K L(\rho)}{\epsilon} \rho
\end{align*}

Putting all of this together and taking the supremum over $x \in \R^+$, we have the bound
\begin{equation*}
||H(U, c, a)](x)||_\eta \leq \frac{\rho}{2} + K L(\rho) \left( \frac{1}{2 \alpha_0 - 3 \epsilon} + \frac{1}{\epsilon} \right) \rho
\end{equation*}
Choose $\rho$ sufficiently small so that 
\[
K L(\rho) \left( \frac{1}{2 \alpha_0 - 3 \epsilon} + \frac{1}{\epsilon} \right) \leq \frac{1}{2}
\]
Then 
\[
||H(U, c, a)](x)||_\eta \leq \rho
\]
which not only implies $H: D \times B_1 \times B_2 \rightarrow X_\eta$ but also $H: D \times B_1 \times B_2 \rightarrow D$. For $U, V \in D$, following what we did above, we have
\begin{align*}
| &e^{\eta x} ( H(U, c, a) - H(V, c, a) ) | \\
&= \left| \int_\infty^x e^{\eta x} e^{A(c)(x - y)}P^u(c) [N(U(y)) - N(V(y))]dy + \int_0^x e^{\eta x} e^{A(c)(x - y)}P^s(c)[N(U(y)- N(V(y))]dy \right| \\
&\leq K L(\rho) \left( \int_x^\infty e^{(2 \alpha - 3 \epsilon)(x-y)}||U - V||_\eta dy + \int_0^x e^{-\epsilon(x-y)}||U - V||_\eta dy \right) \\
&= K L(\rho) \left( \frac{1}{2 \alpha_0 - 3 \epsilon} + \frac{1}{\epsilon} \right) ||U - V||_\eta  \\
&\leq \frac{1}{2} ||U - V||_\eta 
\end{align*}
Thus $H$ is a uniform contraction. By the uniform contraction mapping principle, there is a unique map $G: B_1 \times B_2 \rightarrow D$ such that $H(G(c, a), c, a) = G(c, a)$ for all $c \in B_1$ and $a \in B_2$. The maps $G$ and $F$ have the same smoothness in the parameters $c$. 

Since $Q(x; c)$ is exponentially localized, there exists $x_0(c) \geq 0$ such that $|e^{\eta x} Q(x; c)| \leq \rho$ for all $x \geq x_0(c)$. Let $a(c) = Q(x_0(c); c)$. Since $F$ is smooth, $Q(x + x_0(c); c)$ is the unique solution on $\R^+$ to \eqref{genODE} with initial condition $a(c)$. Since $||Q(x + x_0(c); c)||_\eta \leq \rho$, $Q(x + x_0(c); c)$ is also a fixed point of \eqref{defH}. Thus by uniqueness from the contraction mapping principle, 
\[
G(c, a(c)) = Q(x + x_0(c); c)
\]
\end{proof}
\end{lemma}

All that remains is to show that $H(U, c, a)$ is Frechet differentiable in $c$, which will imply that $G(c, a)$ is as well. First, we prove the following lemma, which is a product rule for Frechet derivatives. 

\begin{lemma}\label{frechetproductlemma}
Let $F(c): \R \rightarrow X_\eta$, where $X_\eta$ is the weighted exponential space defined in \eqref{defXeta}. Suppose $F$ is Frechet differentiable at $c$ with, with Frechet derivative $L$. Then the following are true.

\begin{enumerate}[(i)]
\item Let $T(c)$ be an $n \times n$ matrix which is smooth in $c$. Then $T(c)F(c): \R \rightarrow X_\eta$ has Frechet derivative $T'(c)F(c) + T(c)L$ at $c$.

\item Let $S(c)$ be an $n \times n$ matrix which is smooth in $c$. Then $F(c)S(c): \R \rightarrow X_\eta$ has Frechet derivative $L S(c) + F(c)S'(c)$ at $c$.

\item Let $S(c) \in GL(n, \R)$ be a family of smooth invertible matrices paramaterized by $c$, where $S(c)$ is smooth and invertible in an open interval around $c$. Then $S^{-1}(c)F(c)S: \R \rightarrow X_\eta$ has Frechet derivative $(S^{-1})'(c) F(c) S(c) + S^{-1}(c) L S (c) + S^{-1}(c) F(c) S'(c)$ at $c$.
\end{enumerate}

\begin{proof}
Let $||F(c)||_\eta = M$. For (i), $T(c)F(c): \R \rightarrow X_\eta$ since for $x \geq 0$
\begin{align*}
|e^{\eta x} T(c)[F(c)](x)| \leq ||T(c)||\:|e^{\eta x} [F(c)](x)| 
= ||T(c)|| \:||F(c)||_\eta < \infty
\end{align*}
Using the definition of the Frechet derivative,
\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c+h)F(c+h) - T(c)F(c) - (T'(c)F(c) + T(c)L)h||_\eta}{|h|} \\
&= \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) + T(c)F(c+h) - T(c)F(c) - (T'(c)F(c) + T(c)L)h||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c) h ||_\eta}{|h|} \\
&\:\:+ \lim_{h \rightarrow 0}\frac{||T(c)F(c+h) - T(c)F(c) - T(c)L)h||_\eta}{|h|}
\end{align*}
We will evaluate the two limits on the RHS separately. For the second limit,
\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c)F(c+h) - T(c)F(c) - T(c)L)h||_\eta}{|h|} \\
&= |T(c)| \lim_{h \rightarrow 0}\frac{||F(c+h) - F(c) - L)h||_\eta}{|h|} \\
&= 0
\end{align*}
since $|T(c)|$ is a constant and $F(c)$ has Frechet derivative $L$. For the first limit,
\begin{align*}
\lim_{h \rightarrow 0}&\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c) h ||_\eta}{|h|} \\
&= \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c+h)h + T'(c)F(c+h)h - T'(c)F(c) h ||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0}\frac{||T(c+h)F(c+h) - T(c)F(c+h) - T'(c)F(c+h)h||_\eta}{|h|} + \lim_{h \rightarrow 0} \frac{||T'(c)F(c+h)h - T'(c)F(c) h ||_\eta}{|h|} \\
&\leq \lim_{h \rightarrow 0} \left| \frac{T(c+h) - T(c)}{h} - T'(c) \right| ||F(c+h)||_\eta + |T'(c)| \lim_{h \rightarrow 0} ||F(c+h) - F(c) ||_\eta \\
&= 0 \cdot M + |T'(c)| \cdot 0 \\
&= 0
\end{align*}
where we used the continuity $F: \R \rightarrow X_\eta$, the continuity of norms, and the differentiability of $T(c)$. Thus we have proved (i).

For (ii), the proof is similar. For (iii), take $T(c) = S^{-1}(c)$ in (i), then use (ii).
\end{proof}
\end{lemma}

Since $F(U; c)$ is smooth, $A(c)$, $P^s(c)$, and $P^u(c)$ are differentiable in $c$. Next, we prove a result about the Frechet derivative of $e^{A(c)x} P^s(c)$.

\begin{lemma}\label{EAPsderiv}
For $c \in (c_0 - \delta_1, c_0 + \delta_1)$, the map $c \rightarrow e^{A(c)x} P^s(c)$ is Frechet differentiable from $\R$ to $X_\mu$ for any $\mu$ with $0 \leq \mu < \alpha_0 - \epsilon$.
\begin{proof}
To make this easier, we will put the matrix $A(c)$ into Jordan canonical form. Let $S^{-1}(c)A(c)S(c) = \Lambda(c)$, where $\Lambda(c)$ is block diagonal consisting of Jordan blocks. Since $A(c)$ is smooth in $c$, $S(c)$ and $\Lambda(c)$ are as well. $S^{-1}(c)P^s(c)S(c) = P_1$, where $P_1$ is the matrix which projects onto the stable eigenspace of $\Lambda(c)$. Since $A(c)$ is hyperbolic, the dimensions of the eigenspaces will be the same for $c \in (c_0 - \delta_1, c_0 + \delta_1)$; thus since $\Lambda(c)$ is block diagonal, $P_1$ is constant coefficient and does not depend on $c$. Thus we have
\begin{align*}
S^{-1}(c) e^{A(c)x} P^s(c) S(c) &=  
S^{-1}(c) e^{A(c)x} S(c) S^{-1}(c) P^s(c) S(c) \\
&= e^{\Lambda(c)x}P_1 
\end{align*}
from which it follows that
\begin{align*}
e^{A(c)x} P^s(c) 
&= S(c) e^{\Lambda(c)x} P_1 S^{-1}(c)
\end{align*}
By Lemma \ref{frechetproductlemma}, it suffices to show that $e^{\Lambda(c)x} P_1$ is Frechet differentiable. Since matrices commute with their own eigenprojections, we will use the relation
\begin{equation}\label{P1commutes}
e^{\Lambda(c)x} P_1 = P_1 e^{\Lambda(c)x}
\end{equation}
which holds for all $c \in (c_0 - \delta_1, c_0 + \delta_1)$. 

For convenience, let $\alpha = \alpha_0 - \epsilon$ and $\mu = \alpha - \gamma$, where $\gamma > 0$. We will take
\begin{equation}\label{Frechetansatz1}
e^{\Lambda(c)x} P_1 \Lambda'(c)x
\end{equation}
as our ansatz for the Frechet derivative of $e^{\Lambda(c)x} P_1$. For all $x \in \R^+$, using \eqref{eAcbounds}, we have
\begin{align*}
\left| e^{\mu x} e^{\Lambda(c)x} P_1 \Lambda'(c)x \right| 
&\leq K|\Lambda'(c)| e^{(\alpha - \gamma) x} e^{-\alpha x} \\
&\leq C x e^{-\gamma x} \\
\end{align*} 
which is uniformly bounded in $x$. Thus \eqref{Frechetansatz1} is a bounded linear transformation from $\R$ to $X_\mu$.

Since $\Lambda(c)$ is smooth in $c$, we can expand it as a Taylor series around $c$ to get
\[
\Lambda(c+h) = \Lambda(c) + \Lambda'(c)h + R(h)h
\]
where $R(h) \rightarrow 0$ as $h \rightarrow 0$. Using this together with the definition of the Frechet derivative and \eqref{P1commutes},
\begin{align*}
&\frac{e^{\mu x} |e^{\Lambda(c+h)x}P_1 - e^{\Lambda(c)x}P_1 - e^{\Lambda(c)x} P_1 \Lambda'(c)x h|}{|h|} \\
&= \frac{e^{\mu x}}{|h|}| P_1|\left| e^{(\Lambda(c) + \Lambda'(c)h + R(h)h)x} - e^{\Lambda(c)x} - e^{\Lambda(c)x} P_1 \Lambda'(c)h x \right| \\
&= \frac{e^{\mu x}}{|h|}| P_1 e^{\Lambda(c)x}|\left| e^{(\Lambda'(c)h + R(h)h)x} - I - \Lambda'(c)h x \right| \\
&= \frac{1}{|h|} |e^{\alpha x} e^{\Lambda(c)x} P_1| e^{-\gamma x} \left| e^{\Lambda'(c)h + R(h)h} - I - \Lambda'(c)hx \right| \\
&\leq \frac{C}{|h|} e^{-\gamma x} \left| e^{\Lambda'(c)hx}e^{R(h)hx} - I - \Lambda'(c)hx \right| \\ 
\end{align*}
where we used the fact that $e^{\alpha x} e^{\Lambda(c)x} P_1$ is uniformly bounded, which follows from \eqref{eAcbounds}. Using the series expansion for the matrix exponentials, we have
\begin{align*}
e^{\Lambda'(c)hx}&e^{R(h)hx} - I - \Lambda'(c)hx \\
&= e^{\Lambda'(c)hx} \left(I + \sum_{n=1}^\infty \frac{(R(h)hx)^n}{n!} \right) - I - \Lambda'(c)hx \\
&= I + \Lambda'(c)hx + \sum_{n=2}^\infty \frac{(\Lambda'(c)hx)^n}{n!} + e^{\Lambda'(c)hx} \sum_{n=1}^\infty \frac{(R(h)hx)^n}{n!} - I - \Lambda'(c)hx \\
&= \sum_{n=2}^\infty \frac{(\Lambda'(c)hx)^n}{n!} + e^{\Lambda'(c)hx} \sum_{n=1}^\infty \frac{(R(h)hx)^n}{n!} \\
&= (\Lambda'(c)hx)^2 \sum_{n=0}^\infty \frac{(\Lambda'(c)hx)^n}{(n+2)!} + e^{\Lambda'(c)hx} R(h)hx \sum_{n=0}^\infty \frac{(R(h)hx)^n}{(n+1)!} 
\end{align*}
Since $\Lambda'(c)$ is a constant and is smooth in $c$ and $R(h) \rightarrow 0$ as $h \rightarrow 0$, choose $h \leq 1$ sufficiently small so that for all $c \in (c_0 - \delta_1, c_0 + \delta_1)$, 
\[
|\Lambda'(c)h|, |R(h)h| \leq \frac{\gamma}{4}
\]
Recalling that $x \geq 0$, we have
\begin{align*}
&\left| e^{\Lambda'(c)hx}e^{R(h)hx} - I - \Lambda'(c)hx \right| \\
&\leq (|\Lambda'(c)h|x)^2 \sum_{n=0}^\infty \frac{(|\Lambda'(c)h|x)^n}{n!} + e^{|\Lambda'(c)h|x} |R(h)h|x \sum_{n=0}^\infty \frac{(|R(h)h|x)^n}{n!} \\
&\leq (|\Lambda'(c)h|x)^2 e^{|\Lambda'(c)h|x} + e^{|\Lambda'(c)h|x} |R(h)h|x e^{|R(h)h|x} \\
&= C \left(|h|^2 x^2 \exp\left(\frac{\gamma}{4}x\right) 
+ |h| |R(h)|x \exp\left(\frac{\gamma}{2}x\right) \right)
\end{align*}
Substituting this in, we have
\begin{align*}
&\frac{e^{\mu x} |e^{\Lambda(c+h)x}P_1 - e^{\Lambda(c)x}P_1 - e^{\Lambda(c)x} P_1 \Lambda'(c)x h|}{|h|} \\
&\leq \frac{C}{|h|} e^{-\gamma x} \left(|h|^2 x^2 \exp\left(\frac{\gamma}{4}x\right) 
+ |h| |R(h)|x \exp\left(\frac{\gamma}{2}x\right) \right) \\
&\leq C \left( |h| x^2 \exp\left(-\frac{3\gamma}{4}x\right) + |R(h)| x \exp\left(-\frac{\gamma}{2}x\right) \right) \\
&= C (|h| + |R(h)|)
\end{align*}
Sending $h \rightarrow 0$, since this is uniform in $x$, we conclude that
\begin{align*}
\lim_{h \rightarrow 0}
\frac{||e^{\Lambda(c+h)x}P_1 - e^{\Lambda(c)x}P_1 - e^{\Lambda(c)x} P_1 \Lambda'(c)x h||_\mu}{|h|} = 0
\end{align*}
\end{proof}
\end{lemma}

Finally, we will show that $H$ is Frechet differentiable in $c$.

\begin{lemma}\label{HFrechetlemma}
The map $H: D \times B_1 \times B_2 \rightarrow D$ defined in Lemma \ref{Hcontractionlemma} is Frechet differentiable in $c$.
\begin{proof}
First, we note that the dependence on $c$ is via the term $e^{A(c)x}$ and the projections $P^s(c)$ and $P^u(c)$. Since differentiation is linear, we will consider each of the three terms in $H$ separately. Recall that $U \in D$ means that $||U||_\eta \leq \rho$, which implies that $||U|| \leq \rho$.

Let $L(x, c)$ be the Frechet derivative of $e^{A(c)x} P^s(c)$ from Lemma \ref{EAPsderiv}. Then the Frechet derivative of the first term is $L(x, c)a$. For the third term, we will show that the Frechet derivative is
\begin{equation}\label{frechet3ansatz}
L_3(U; c) = \int_0^x L(c, x - y) N(U(y)) dy
\end{equation}
First, we have to show that \eqref{frechet3ansatz} is a bounded linear transformation from $\R$ to $X_\eta$. Let $\mu = \eta + \epsilon/2 = \alpha_0 - 3\epsilon/2$. From Lemma \ref{EAPsderiv}, $e^{\mu x} L(c,x)$ is bounded, thus we have
\begin{align*}
\left| e^{\eta x} \int_0^x L(c, x - y) N(U(y)) dy \right| &\leq \int_0^x |e^{\eta (x-y)} L(c, x - y)| |e^{\eta y} N(U(y))| dy \\
&= \int_0^x e^{-\frac{\epsilon}{2}(x-y)} |e^{\mu (x-y)} L(c, x - y)| |e^{\eta y} N(U(y))| dy \\
&\leq C \int_0^x e^{-\frac{\epsilon}{2}(x-y)} || N(U(y))|_\eta dy \\
&\leq C \frac{2}{\epsilon}\left(1 - e^{-\frac{\epsilon}{2}x}\right) L(\rho)||U||_\eta \\
&\leq C ||U||_\eta
\end{align*}
where we used \eqref{LrhoNU} in the penultimate line. 

Using the definition of the Frechet derivative, for $x \in \R^+$ we have
\begin{align*}
\frac{1}{|h|}&e^{\eta x}\left| \int_0^x e^{A(c+h)(x - y)}P^s(c) N(U(y))dy - \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy - h \int_0^x L(c, x - y) N(U(y)) dy \right|\\
&= \frac{1}{|h|}e^{\eta x}\left| \int_0^x \left( e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y) \right) N(U(y)) dy \right| \\
&\leq \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| \left| e^{\eta y} N(U(y)) \right| dy \\
&\leq \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| || e^{\eta y} N(U(y)) ||_\eta dy \\
&\leq L(\rho)\rho \int_0^x \left| \frac{ e^{\eta(x-y)} (e^{A(c+h)(x - y)}P^s(c) - e^{A(c)(x - y)}P^s(c) - h L(c, x - y))}{h}\right| dy \\
&\leq L(\rho)\rho \int_0^x \left| \frac{ e^{\eta z} (e^{A(c+h)z }P^s(c) - e^{A(c)z }P^s(c) - h L(c, z))}{h}\right| dz
\end{align*}
From Lemma \ref{EAPsderiv}, $e^{\mu x} L(c,x)$ is bounded, thus we have 
\begin{align*}
\frac{1}{|h|}&e^{\eta x}\left| \int_0^x e^{A(c+h)(x - y)}P^s(c) N(U(y))dy - \int_0^x e^{A(c)(x - y)}P^s(c) N(U(y))dy - h \int_0^x L(c, x - y) N(U(y)) dy \right|\\
&\leq L(\rho)\rho \int_0^x e^{-\frac{\epsilon}{2}z} \left|\frac{ e^{\mu z} (e^{A(c+h)z }P^s(c) - e^{A(c)z }P^s(c) - h L(c, z))}{h}\right| dz \\
&\leq L(\rho)\rho \frac{ || e^{A(c+h)z }P^s(c) - e^{A(c)z }P^s(c) - h L(c, z)||_\mu}{|h|}  \int_0^x e^{-\frac{\epsilon}{2}z} dz \\
&\leq C L(\rho)\rho \frac{ || e^{A(c+h)z }P^s(c) - e^{A(c)z }P^s(c) - h L(c, z)||_\mu}{|h|} 
\end{align*}
By Lemma \ref{EAPsderiv}, since $L(c, z)$ is the Frechet derivative of $e^{A(c)z }P^s(c)$ from $\R$ to $X_\mu$, the RHS $\rightarrow 0$ as $h \rightarrow 0$.

For the second term, we first show Frechet differentiability of $e^{A(c)(x}P^u(c) N(U(y))$ on the exponentially weighted space 
\[
\tilde{X}_\mu = \{ f \in C^0((-\infty, 0], \R^n) : \sup_{x \in (-\infty, 0]} |e^{-\mu x} f(x)| < \infty \} 
\]
for $0 \leq \mu < \alpha_0 - \epsilon$. This is almost identical to the proof of Lemma \ref{EAPsderiv}. The Frechet differentiability of the second term then follows similarly to that of the third term.
\end{proof}
\end{lemma}

Since $H(U, c, a)$ is Frechet differentiable in $c$, this implies that the fixed point map $G(c, a)$ is as well. Since $G(c, a(c)) = Q(x + x_0(c); c)$, $Q(x + x_0(c); c)$ is Frechet differentiable in $c$ as a map from $R$ to $X_\eta$. Since $Q(x; c)$ is differentiable in $c$, the Frechet derivative must be $\partial_c Q(x + x_0(c); c)$. Since exponential decay involves only the tail behavior, we conclude that $\partial_c Q(x; c)$ is exponentially localized on $\R^+$ with decay rate $\eta$. An identical argument proves this exponential localization on $\R^-$. Thus $\partial_c Q(x; c)$ is exponentially localized on $\R$. Since $\epsilon$ is arbitrary, we conclude that for any $\epsilon > 0$, there exists $\delta_1 > 0$ such that for $c \in (c_0 - \delta_1, c_0 + \delta_1)$,
\[
|\partial_c Q(x; c)| \leq C e^{-(\alpha - \epsilon)|x|}
\] 

\subsection{Characterization of solutions to adjoint linear ODEs}

In this section, we prove a lemma relating solutions of the adjoint of an $n$-th order linear ODE to solutions of the adjoint problem when written as a first order system in the standard way.

\begin{lemma}\label{adjointlemma}
Consider the $n$-th order linear ODE 
\begin{equation}\label{linODE}
\partial_x^n u(x) + \sum_{k=0}^{n-1}g_k(x) \partial_x^k u(x) = 0
\end{equation}
which we can write as a first order system in the standard way as
\begin{equation}\label{linODEsys}
U'(x) = A(x)U(x)
\end{equation}
where
\begin{equation}\label{Axform}
A(x) = \begin{pmatrix}
0 & 1 & 0 & \dots & 0 & 0 \\
0 & 0 & 1 & \dots & 0 & 0 \\
& &  & \ddots &  & & \\
0 & 0 & 0 & \dots & 0 & 1 \\
-g_0(x) & -g_1(x) & -g_2(x) &
 \dots & -g_{n-2}(x) & -g_{n-1}(x)
\end{pmatrix}
\end{equation}
Then if $W(x) = (w_1(x), \dots, w_n(x))$ solves the adjoint system
\begin{equation}\label{adjODEsys}
W'(x) = -[A(x)]^* W(x),
\end{equation}
$w_n(x)$ solves the adjoint linear ODE
\begin{equation}\label{adjODE}
(-1)^n \partial_x^n w(x) + \sum_{k=0}^{n-1} (-1)^k \partial_x^k( g_k(x) w(x)) = 0
\end{equation}
and the remaining entries of $W(x)$ are given by
\begin{align}\label{adjWform}
w_r(x) &= (-1)^{n-r} \partial_x^{n-r}w_n(x) + \sum_{k=r}^{n-1} (-1)^{k-r} \partial_x^{k-r}(g_k(x) w_n(x)) && r = 1, \dots n-1
\end{align}
\begin{proof}
The adjoint system is given by
\begin{equation*}
\begin{pmatrix}
w_1'(x) \\ w_2'(x) \\ w_3'(x) \\ \vdots \\ w_n'(x)
\end{pmatrix} = \begin{pmatrix}
0 &  0 & 0  & \dots & 0 & g_0(x) \\
0 & -1 & 0  & \dots & 0 & g_1(x) \\
0 &  0 & -1 & \dots & 0 & g_2(x) \\
& &  & \ddots &  & & \\
0 & 0 & 0 & \dots  & -1 & g_{n-1}(x) \\
\end{pmatrix}
\begin{pmatrix}
w_1(x) \\ w_2(x) \\ w_3(x) \\ \vdots \\ w_n(x)
\end{pmatrix}
\end{equation*}
which gives us the system of $n$ equation 
\begin{align*}
w_1'(x) &= g_0(x) w_n(x) \\
w_2'(x) &= -w_1(x) + g_1(x) w_n(x) \\
\vdots \\
w_{n-1}'(x) &= -w_{n-2}(x) + g_{n-2}(x) w_n(x) \\
w_n'(x) &= -w_{n-1}(x) + g_{n-1}(x) w_n(x) \\
\end{align*}
Suppressing the dependence on $x$ for convenience of notation, we rearrange this to get
\begin{align*}
0 &= -w_1' + g_0 w_n \\
w_1 &= -w_2' + g_1 w_n \\
w_2 &= -w_3' + g_2 w_n \\
\vdots \\
w_{n-2} &= -w_{n-1}' + g_{n-2} w_n \\
w_{n-1} &= -w_n' + g_{n-1} w_n \\
\end{align*}
Differentiate the $w_{n-1}$ equation to get $w_{n-1}' = -\partial_x^2 w_n + \partial_x(g_{n-1}w_n)$ and substitite it into the $w_{n-2}$ equation to get
\begin{align*}
w_{n-2} &= \partial_x^2 w_n - \partial_x(g_{n-1} w_n) + g_{n-2} w_n
\end{align*}
Differentiate this and substitute it into the $w_{n-3}$ equation to get
\[
w_{n-3} = -\partial_x^3 w_n + \partial_x^2(g_{n-1} w_n) - \partial_x(g_{n-2} w_n) + g_{n-3} w_n
\]
Continuing this process, we have the general expression for $w_r$
\begin{align*}
w_r &= (-1)^{n-r} \partial_x^{n-r}w_n + \sum_{k=r}^{n-1} (-1)^{k-r} \partial_x^{k-r}(g_k w_n) && r = 1, \dots n-1
\end{align*}
When we reach the $w_1$ (after $n-1$ iterations), we have
\[
w_1 = (-1)^{n-1} \partial_x^{n-1} w_n + \sum_{k=1}^{n-1} (-1)^{k-1} \partial_x^{k-1}(g_k w_n)
\]
Differentiate this once more, and substitute it into the first equation $0 = -w_1' + g_0 w_n$ to get 
\begin{align*}
0 &= (-1)^{n} \partial_x^{n} w_n + \sum_{k=1}^{n-1} (-1)^{k} \partial_x^{k}(g_k w_n) + g_0 w_n \\
&= (-1)^{n} \partial_x^{n} w_n + \sum_{k=0}^{n-1} (-1)^{k} \partial_x^{k}(g_k w_n)
\end{align*}
which is identical to adjoint linear ODE \eqref{adjODE}. Thus $w_n$ is a solution to \eqref{adjODE}.
\end{proof}
\end{lemma}

\subsection{Proof of Lemma \ref{psiform}}
Since \eqref{genODE} is Hamiltonian, $\langle F(Q(x)), \nabla H(Q(x)) \rangle = 0$ for all $x$. Taking the gradient of this and using known vector calculus identities,
\begin{align*}
0 &= \nabla \langle F(Q(x)), \nabla H(Q(x)) \rangle \\
&= D F(Q(x))^* \nabla H(Q(x)) + D^2 H(Q(x))^* F(Q(x)) \\
&= D F(Q(x))^* \nabla H(Q(x)) + D^2 H(Q(x)) Q'(x) \\
&= D F(Q(x))^* \nabla H(Q(x)) + \frac{d}{dx} \nabla H(Q(x))
\end{align*}
since the Hessian matrix is self-adjoint. Rearranging this,
\begin{equation*}
\frac{d}{dx} \nabla H(Q(x)) = -D F(Q(x))^* \nabla H(Q(x)) 
\end{equation*}
thus $\nabla H(Q(x))$ is a solution to the adjoint variational equation \eqref{adjvareq1}. Since $\nabla H$ is continuous and $Q(x)$ is bounded (it decays exponentially to 0 at $\pm \infty$), $\nabla H(Q(x))$ is bounded as well. By Hypothesis \ref{nondegenhyp}, there is a unique such solution. It follows that $\Psi(x) = \nabla H(Q(x))$.

For the symmetry relation, we will show that $R \Psi(-x)$ is a also a solution to \eqref{adjvareq1}. Using \eqref{genODErevDF} and the symmetry of the primary pulse $Q(x)$, 
\begin{align*}
[R \Psi(-x)]' &= -R \Psi'(-x) \\
&= -R DF(Q(-x)) \Psi(-x) \\
&= -R DF(RQ(x)) \Psi(-x) \\
&= -R [-RDF(Q(x))R] \Psi(-x) \\
&= DF(Q(x))R \Psi(-x)
\end{align*}
Thus by uniqueness, $\Psi(x) = R \Psi(-x)$, from which it follows that $\Psi(-x) = R \Psi(x)$.

Finally, the variational equation $V'(x) = DF(Q(x)) V(x)$ is equivalent to the linear ODE 
\begin{equation}\label{var1}
\calE''(q(x))v(x) = 0.
\end{equation}
Since the differential operator $\calE''(q(x))$ has an isolated term $\partial_x^{2m}$ and all other derivative terms are lower order, equation \eqref{var1} is of the form \eqref{linODE}. By Lemma \ref{adjointlemma}, $\Psi_{2m}(x)$ solves the adjoint of \eqref{var1}. Since the operator $\calE''(q(x))$ is self-adjoint, $\Psi_{2m}(x)$ solves equation \eqref{var1}. Since \eqref{var1} has the unique solution $q'(x)$, we conclude that $\Psi_{2m}(x) = q(x)$.

\subsection{Proof of Lemma \ref{eigadjoint}}

For part (i), 
\begin{align*}
\dfrac{d}{dx}\langle V(x), W(x) \rangle &= 
\langle V'(x), W(x) \rangle + \langle V(x), W'(x) \rangle \\
&= \langle A(x)V(x), W(x) \rangle + \langle V(x), -A(x)^* W(x) \rangle \\
&= \langle A(x)V(x), W(x) \rangle - \langle A(x)V(x), W(x) \rangle \\
&= 0
\end{align*}

For part (ii), let $|W(x)| \leq K$ and $V(x) \rightarrow 0$ as $x \rightarrow \infty$, By (i), $\langle V(x), W(x) \rangle = c$, where $c$ is a constant. Taking $x \rightarrow \infty$ and using the Cauchy-Schwartz inequality and the continuity of the norm,
\begin{align*}
|c| &= \left| \lim_{x\rightarrow \infty} \langle V(x), W(x) \rangle \right| \\
&= \lim_{x\rightarrow \infty} \left| \langle V(x), W(x) \rangle \right| \\
&\leq \lim_{x\rightarrow \infty} |V(x)||W(x)| \\
&\leq K \lim_{x\rightarrow \infty} |V(x)| \\
&= 0
\end{align*}

For part (iii), take the derivative of the expression $\Phi(y, x)\Phi(x, y) = I$ with respect to $y$ to get
\begin{align*}
0 &= \left(\frac{d}{dy}\Phi(y, x)\right) \Phi(x, y) +
\Phi(y, x)\left(\frac{d}{dy}\Phi(x, y)\right) \\
&= A(y)\Phi(y, x) \Phi(x, y) +
\Phi(y, x)\left(\frac{d}{dy}\Phi(x, y)\right) \\
&= A(y) + \Phi(y, x)\left(\frac{d}{dy}\Phi(x, y)\right) 
\end{align*}
Rearrange this to get
\begin{align*}
\Phi(y, x)\left(\frac{d}{dy}\Phi(x, y)\right) &= -A(y) \\
\frac{d}{dy}\Phi(x, y) &= -\Phi(x, y) A(y) 
\end{align*}
Taking the transpose of both sides, we get
\begin{align*}
\frac{d}{dy}\Phi(x, y)^* &= -A(y)^* \Phi(x, y)^*  
\end{align*}
from which (iii) follows.

\subsection{Proof of Lemma \ref{eigA0lemma}}

Before we prove Lemma \ref{eigA0lemma}, we will prove a general result from finite dimensional linear algebra.

\begin{lemma}\label{kernelprojlemma}
Let $A$ be an $n \times n$ diagonalizable matrix with simple kernel spanned by $v$, and let $\ker A^* = \text{span}(w)$. Then 
\begin{enumerate}[(i)]
\item $\langle v, w \rangle \neq 0$.
\item Having chosen the scaling in part (i), the projection on the kernel of $A$ is given by
\begin{equation}\label{PkerA}
P_{\ker A} = \frac{ \langle w, \cdot \rangle v }{\langle w, v \rangle }
\end{equation}
\end{enumerate}
\begin{proof}
For part (i), if $\langle v, w \rangle = 0$, then $v \perp \ker A^*$, thus by the Fredholm alternative we can solve $A u = v$. This is not possible since $A$ has simple kernel.

For part (ii), Let $0, \lambda_2, \dots, \lambda_n$ be the eigenvalues (with multiplicity) of $A$ with corresponding eigenvectors $v, v_2, \dots, v_n$. Let $P$ be defined by the RHS of \eqref{PkerA}.

First, let $u \in \ker A$. Then $u = \alpha v$ for $\alpha \in \R$, thus 
\[
P u = \frac{ \langle w, \alpha v \rangle v }{\langle w, v \rangle } = \frac{ \alpha \langle w, v \rangle v}{\langle w, v \rangle } = \alpha v = u
\]

Next, let $u \in R^n$. Since $A$ is diagonalizable, the eigenfunctions form a basis for $\R^n$, write $u$ in the eigenbasis as
\[
u = \alpha v + \sum_{k=2}^n \alpha_k v_k
\]
Choose $k \in 2, \dots, n$ and note that $\lambda_k \neq 0$since the kernel of $A$ is simple and $A v_k = \lambda_k v_k$. Then we have
\begin{align*}
\langle w, v_k \rangle &= \langle w, \frac{1}{\lambda_k}\lambda_k v_k \rangle \\
&= \langle w, \frac{1}{\lambda_k} A v_k \rangle \\
&= \langle w, A \frac{1}{\lambda_k} v_k \rangle \\
&= \langle A^* w, \frac{1}{\lambda_k} v_k \rangle \\
&= 0
\end{align*}
Thus we have
\[
P u = \alpha v
\]
\end{proof}
\end{lemma}

We now turn to the proof of Lemma \ref{eigA0lemma}. Let $p_1(\nu)$ and $p_2(\nu)$ be the characteristic polynomials of $DF(0)$ and $A(0)$ (respectively). From \eqref{defAphi} and \eqref{defDF}, $A(0)$ is the block matrix
\[
A(0) = \begin{pmatrix}
DF(0) & E \\
0 & 0
\end{pmatrix}
\]
where $E$ is the $2m \times 1$ matrix $E = (0, 0, \dots, 1)^T$, and $0$ represents a block composed of zeros of the appropriate size. Expanding the determinant by minors using the bottom row, we have for $p_2(\nu)$,
\begin{align*}
p_2(\nu) &= \det(A_0 - \nu I) \\
&= -\nu \det(DF(0) - \nu I) \\
&= -\nu p_1(\nu)
\end{align*}
Thus $A(0)$ has the same eigenvalues as $DF(0)$ as well as an additional eigenvalue at 0. The eigenvalues of $DF(0)$ are characterized in Hypothesis \ref{hypeqhyp}, from which (i) follows.

For part (ii) we can verify directly from the form of $A(0)$ that 
\begin{align*}
V_0 &= (1/c, 0, \dots, 0, 1)^T \\
W_0 &= (0, 0, \dots, 0, 1)^T
\end{align*}
are eigenvectors of $A(0)$ and $-A(0)^*$ (respectively) corresponding to eigenvalue 0; these have been scaled $V_0$ so that $\langle V_0, W_0 \rangle = 1$. The expression for the projection on the kernel of $A(0)$ in part (iii) comes from Lemma \ref{kernelprojlemma}, since the kernel of $A(0)$ is simple and $\langle W_0, V_0 \rangle = 1$.

% nondegeneracy lemma
\subsection{Proof of Lemma \ref{nondegenlemma}}
Since $Q(x)$ is a homoclinic orbit in the intersection of $W^u(0)$ and $W^s(0)$, $\R Q'(0) \subset T_{Q(0)}W^s(0) \cap T_{Q(0)}W^u(0)$. If the intersection were more than one-dimensional, there would exist another exponentially localized solution $V(x) = (v_1, \dots, v_{2m}, v_{2m+1})^T$ to \eqref{vareq2}. It follows that $\tilde{V}(x) = (v_1, \dots, v_{2m})^T$ would be an exponentially localized solution to \eqref{vareq1}, which contradicts \eqref{nondegencond}.

% solutions to variational equation
\subsection{Proof of Lemma \ref{varadjsolutions}}

The proof of part (i) is found in Lemma \ref{varsolutions} in \cref{sec:centersol}.

Using 

the Gap Lemma, we can find solutions $V^\pm(x)$ to the variational equation \eqref{vareq2} on $\R^\pm$ such that
\begin{equation}\label{Vplusminus}
V^\pm(x) = V_0 + \mathcal{O}(e^{-(\alpha - \epsilon)|x|}|V_0|)
\end{equation}
for some $\epsilon > 0$, so $V^\pm(x) \rightarrow V_0$ as $x \rightarrow \pm \infty$. These will not be unique, since, for example, we can add any component in $Y^+ \oplus \R Q'(0)$ to $V^+(0)$ and keep the same decay property. Since $V^\pm(x)$ remains bounded but does not decay to 0, $V^\pm(0)$ must have a component in $Y^0$ and cannot have a component in $Y^-$. If $V^+(0)$ has any component in $Y^+ \oplus \R Q'(0)$, we can subtract it out and keep the decay property in \eqref{Vplusminus}. Thus we can take $V^+(0) \in Y^0$. Similarly, we can take $V^-(0) \in Y^0$. Since both initial conditions are in $Y^0$, $V^\pm(x)$ remain bounded for all $x$.

By reversibility, $RV^+(-x)$ is also a solution to the variational equation on $R^-$, with 
\begin{align*}
R V^+(-x) &= R V_0 + \mathcal{O}(e^{-(\alpha - \epsilon)|x|}|V_0|) \\
&= V_0 + \mathcal{O}(e^{-(\alpha - \epsilon)|x|}|V_0|)
\end{align*}
where $R V_0 = V_0$ since all components of $V_0$ are 0 except for the first. Reversing time swaps $Y^+$ and $Y^-$, while leaving $\R Q'(0)$ and $Y^0$ intact. Thus $RV^+(0) \in Y_0$, and so both $V^+(0)$ and $RV^+(0)$ are in the one-dimensional space $Y^0$; since the odd numbered components of $V^+(0)$ and $RV^+(0)$ are equal and $Y^0$ is one-dimensional, it follows that $V^+(0) = RV^+(0)$.

Since we have the same initial condition at $x = 0$ for $V^+(x)$ and $RV^+(-x)$, this implies that $V^+(-x) = RV^+(x)$. Let $V^c(x) = V^+(x)$. Then $V^c(x)$ is a bounded solution to the variational equation with is symmetric with respect to the reversor $R$, i.e. $V^c(-x) = RV^c(x)$. Furthermore, $V^c(x) \rightarrow V_0$ as $x \rightarrow \pm \infty$.

% solutions to adjoint variational equation
\subsection{Proof of Lemma \ref{adjsolutions}}

Using \eqref{defAphi}, the linear operator $A(Q(x))^*$ has the form 
\begin{equation}\label{defAphi}
A(Q(x))^* = 
\begin{pmatrix}
0 & 0 & 0 & \dots & 0 & f_{u_1}(Q(x)) - c & 0 \\
1 & 0 & 0 & \dots & 0 & f_{u_2}(Q(x)) & 0 \\
0 & 1 & 0 & \dots & 0 & f_{u_3}(Q(x)) & 0 \\
&& \ddots &&& \vdots \\
0 & 0 & 0 & \dots & 1 & f_{u_{2m}}(Q(x)) & 0 \\
0 & 0 & 0 & \dots & 0 & 1 & 0 \\
\end{pmatrix}
\end{equation}
By inspection, 
\[
\Psi^c(x) = W_0 = (0, 0, \dots, 0, 1)^T
\]
is a bounded solution. To find $\Psi(x)$, we note that from \eqref{defDF}, the adjoint variational equation takes the block form
\[
\begin{pmatrix} \tilde{W}'(x) \\ W_{2m+1}(x) \end{pmatrix}
= \begin{pmatrix }
\begin{pmatrix}DF(Q(x))^* & 0 \\ E & 0 \end{pmatrix}
\]
where $\tilde{W}'(x) = (W_1(x), \dots, W_{2m}(x)) \in \R^{2m}$, $E$ is the $1 \times 2m$ matrix $E = (0, 0, \dots, 1)$, and $0$ represents blocks of zeros of the appropriate size. This can be written as the system of equations
\begin{align}
\tilde{W}'(x) &= DF(Q(x))^* \label{tildeWeq1} \\
W_{2m+1}(x)' &= \tilde{W}_{2m}(x) \label{tildeWeq2}
\end{align}
Equation \eqref{tildeWeq1} has a solution $\tilde{W}(x) = 0$, from which it follows that $W_{2m+1}(x)$ is a constant. This is a constant multiple of $\Psi^c(x)$, so we have already taken care of it.

By Lemma \ref{psiform}, equation \eqref{tildeWeq1} has a unique nonzero solution $\tilde{W}(x) = \nabla H(Q(x))$, with $\tilde{W}_{2m}(x)=q'(x)$ and $\tilde{W}(-x) = R\tilde{W}(x)$. Then $W_{2m+1}(x) = q(x) + C$; we can without loss of generality take $C = 0$ since if $C$ is nonzero, we can subtract $C \Psi^c(x)$. Thus we have
\[
\Psi(x) = ( \nabla H(Q(x)), q(x) )
\]
which is exponentially localized since $q(x)$ is exponentially localized and $H$ is smooth. Since $q(x)$ is an even function, we have the symmetry relation $\Psi(-x) = R \Psi(x)$.

It follows from Lemma \ref{adjointlemma} that any bounded solution to \eqref{adjvareq2} must be perpendicular to $\R Q'(0) \oplus Y^+ \oplus Y^-$ at $x = 0$. In particular, this holds for $\Psi(0)$ and $\Psi^c(0)$. Since $S_1 = \R Q'(0) \oplus Y^+ \oplus Y^-$ is a $(2m-1)-$dimensional subspace of $\R^{2m+1}$ and $S_2 = \Psi(0) \oplus \Psi^c(0)$ is a $2-$dimensional subspace of $\R^{2m+1}$ which is perpendicular to $S_1$, it follows that there can be no other bounded, linearly independent solutions to \eqref{adjvareq2}.

\iffulldocument\else
	\bibliographystyle{amsalpha}
	\bibliography{thesis.bib}
\fi

\end{document}